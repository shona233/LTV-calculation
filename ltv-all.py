import streamlit as st
import os
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
import datetime
import tempfile
import zipfile
import io
import matplotlib.pyplot as plt
import matplotlib as mpl
import re
from matplotlib.font_manager import FontProperties
import seaborn as sns
from scipy.optimize import curve_fit

# ==================== åŸºç¡€é…ç½® ====================
# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl.styles.stylesheet')
warnings.filterwarnings('ignore', category=UserWarning,
                        message="Could not infer format, so each element will be parsed individually")

# è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ - æ”¹ä¸ºè‹±æ–‡æ ‡ç­¾
def setup_chart_font():
    """è®¾ç½®å›¾è¡¨å­—ä½“ - ä½¿ç”¨è‹±æ–‡é¿å…ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜"""
    try:
        plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        plt.rcParams['font.size'] = 10
        return True
    except Exception as e:
        plt.rcParams['font.family'] = ['DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        plt.rcParams['font.size'] = 10
        return False

# åˆå§‹åŒ–å­—ä½“è®¾ç½®
setup_chart_font()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="LTV Analytics Platform",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="ğŸ“Š"
)

# ==================== CSS æ ·å¼å®šä¹‰ ====================
st.markdown("""
<style>
    /* å…¨å±€æ ·å¼ */
    .main {
        background: #f8fafc;
        min-height: 100vh;
    }

    .block-container {
        padding: 1rem 1rem 3rem 1rem;
        max-width: 100%;
        background: transparent;
    }

    /* ä¸»æ ‡é¢˜åŒºåŸŸ */
    .main-header {
        background: linear-gradient(135deg, #1e40af 0%, #3b82f6 100%);
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 20px rgba(30, 64, 175, 0.3);
        margin-bottom: 1.5rem;
        text-align: center;
        color: white;
    }

    .main-title {
        font-size: 2rem;
        font-weight: 700;
        color: white;
        margin-bottom: 0.5rem;
        text-shadow: 0 2px 4px rgba(0,0,0,0.3);
    }

    .main-subtitle {
        color: rgba(255,255,255,0.9);
        font-size: 1.2rem;
        font-weight: 400;
    }

    /* å¡ç‰‡æ ·å¼ */
    .glass-card {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 12px;
        padding: 1.5rem;
        box-shadow: 0 8px 32px rgba(30, 64, 175, 0.1);
        border: 1px solid rgba(59, 130, 246, 0.2);
        margin-bottom: 1.5rem;
        backdrop-filter: blur(10px);
    }

    /* å¯¼èˆªæ­¥éª¤æ ·å¼ */
    .nav-container {
        background: linear-gradient(135deg, #1e40af 0%, #3b82f6 100%);
        border-radius: 12px;
        padding: 1.5rem;
        margin-bottom: 1rem;
        color: white;
        box-shadow: 0 4px 20px rgba(30, 64, 175, 0.3);
    }

    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #1e40af 0%, #3b82f6 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 0.6rem 2rem !important;
        font-weight: 600 !important;
        transition: all 0.3s ease !important;
        box-shadow: 0 4px 15px rgba(30, 64, 175, 0.3) !important;
    }

    .stButton > button:hover {
        background: linear-gradient(135deg, #1d4ed8 0%, #2563eb 100%) !important;
        transform: translateY(-2px) !important;
        box-shadow: 0 6px 20px rgba(29, 78, 216, 0.4) !important;
        color: white !important;
    }

    /* å­æ­¥éª¤æ ·å¼ */
    .sub-steps {
        font-size: 0.8rem;
        color: rgba(255,255,255,0.7);
        margin-top: 0.3rem;
        line-height: 1.2;
    }

    /* åŸç†è§£é‡Šæ¡†æ ·å¼ */
    .principle-box {
        background: rgba(59, 130, 246, 0.05);
        border: 1px solid rgba(59, 130, 246, 0.2);
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }

    .principle-title {
        color: #1e40af;
        font-weight: 600;
        font-size: 1rem;
        margin-bottom: 0.5rem;
    }

    .principle-content {
        color: #374151;
        font-size: 0.9rem;
        line-height: 1.5;
    }

    /* æç¤ºæ¡†æ ·å¼ */
    .step-tip {
        background: #eff6ff;
        border: 1px solid #bfdbfe;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        border-left: 4px solid #3b82f6;
    }

    .step-tip-title {
        color: #1e40af;
        font-weight: 600;
        font-size: 0.95rem;
        margin-bottom: 0.5rem;
    }

    .step-tip-content {
        color: #374151;
        font-size: 0.85rem;
        line-height: 1.4;
    }

    /* æˆåŠŸä¿¡æ¯æ ·å¼ */
    .success-info {
        background: #f0fdf4;
        border: 1px solid #bbf7d0;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        border-left: 4px solid #22c55e;
    }

    /* éšè—é»˜è®¤çš„Streamlitå…ƒç´  */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ==================== é»˜è®¤é…ç½®æ•°æ® ====================
DEFAULT_CHANNEL_MAPPING = {
    'æ€»ä½“': ['9000'],
    'æ–°åª’ä½“': ['500345', '500346', '500447', '500449', '500450', '500531', '500542'],
    'åº”ç”¨å®': ['5007XS', '500349', '500350'],
    'é¼ä¹-ç››ä¸–6': ['500285'],
    'é¼ä¹-ç››ä¸–7': ['500286'],
    'é…·æ´¾': ['5108', '5528'],
    'æ–°ç¾-åŒ—äº¬1': ['500274'],
    'æ–°ç¾-åŒ—äº¬2': ['500275'],
    'A_æ·±åœ³è›‹ä¸2': ['500316'],
    'è£è€€': ['500297'],
    'åä¸º': ['5057'],
    'vivo': ['5237'],
    'å°ç±³': ['5599'],
    'OPPO': ['5115'],
    'ç½‘æ˜“': ['500471', '500480', '500481', '500482'],
    'åä¸ºéå•†åº—-å“ä¼—': ['500337', '500338', '500343', '500445', '500383', '500444', '500441'],
    'åä¸ºéå•†åº—-å¾®åˆ›': ['500543', '500544', '500545', '500546'],
    'é­…æ—': ['5072'],
    'OPPOéå•†åº—': ['500287', '500288'],
    'vivoéå•†åº—': ['5187'],
    'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£å®‰å“': ['500398', '500400', '500404'],
    'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£ios': ['500402', '500403', '500405'],
    'ç™¾é’è—¤-å®‰å“': ['500377', '500379', '500435', '500436', '500490', '500491', '500434', '500492'],
    'ç™¾é’è—¤-ios': ['500437'],
    'å°ç±³éå•†åº—': ['500170'],
    'åä¸ºéå•†åº—-æ˜Ÿç«': ['500532', '500533', '500534', '500537', '500538', '500539', '500540', '500541'],
    'å¾®åš-èœœæ©˜': ['500504', '500505'],
    'å¾®åš-å¤®å¹¿': ['500367', '500368', '500369'],
    'å¹¿ç‚¹é€š': ['500498', '500497', '500500', '500501', '500496', '500499'],
    'ç½‘æ˜“æ˜“æ•ˆ': ['500514', '500515', '500516']
}

# åˆ›å»ºåå‘æ˜ å°„ï¼šæ¸ é“å·->æ¸ é“åç§°
def create_reverse_mapping(channel_mapping):
    reverse_mapping = {}
    for channel_name, pids in channel_mapping.items():
        for pid in pids:
            reverse_mapping[str(pid)] = channel_name
    return reverse_mapping

# ==================== å†…ç½®ARPUæ•°æ®ç®¡ç† ====================
def get_builtin_arpu_data():
    """è·å–å†…ç½®çš„ARPUåŸºç¡€æ•°æ® - ä¼˜å…ˆä½¿ç”¨ç®¡ç†å‘˜ä¸Šä¼ çš„æ•°æ®"""
    # æ£€æŸ¥æ˜¯å¦æœ‰ç®¡ç†å‘˜ä¸Šä¼ çš„é»˜è®¤æ•°æ®
    if 'admin_default_arpu_data' in st.session_state and st.session_state.admin_default_arpu_data is not None:
        return st.session_state.admin_default_arpu_data.copy()
    
    # å¦‚æœæ²¡æœ‰ç®¡ç†å‘˜æ•°æ®ï¼Œè¿”å›ç¤ºä¾‹æ•°æ®
    return get_sample_arpu_data()

def get_sample_arpu_data():
    """ç”Ÿæˆç¤ºä¾‹ARPUæ•°æ®ï¼ˆå½“æ²¡æœ‰ç®¡ç†å‘˜ä¸Šä¼ æ•°æ®æ—¶ä½¿ç”¨ï¼‰"""
    # ç”Ÿæˆ2024å¹´1æœˆåˆ°2025å¹´4æœˆçš„æ‰€æœ‰æœˆä»½
    months = []
    for year in [2024, 2025]:
        start_month = 1 if year == 2024 else 1
        end_month = 12 if year == 2024 else 4
        for month in range(start_month, end_month + 1):
            months.append(f"{year}-{month:02d}")
    
    builtin_data = []
    
    # ä¸ºä¸»è¦æ¸ é“ç”Ÿæˆç¤ºä¾‹æ•°æ®
    sample_channels = ['9000', '5057', '5599', '5237', '5115', '500285', '500286']
    
    for pid in sample_channels:
        for month in months:
            # ç”Ÿæˆç¤ºä¾‹æ•°æ®
            base_users = {
                '9000': 50000, '5057': 8000, '5599': 6000, 
                '5237': 5500, '5115': 5000, '500285': 2000, '500286': 2200
            }.get(pid, 1000)
            
            base_revenue = {
                '9000': 2000000, '5057': 320000, '5599': 240000,
                '5237': 220000, '5115': 200000, '500285': 80000, '500286': 88000
            }.get(pid, 40000)
            
            # æ·»åŠ æœˆåº¦æ³¢åŠ¨
            month_index = months.index(month)
            fluctuation = 1 + (month_index % 3 - 1) * 0.1
            
            users = int(base_users * fluctuation)
            revenue = int(base_revenue * fluctuation)
            
            builtin_data.append({
                'æœˆä»½': month,
                'pid': pid,
                'stat_date': f"{month}-15",
                'instl_user_cnt': users,
                'ad_all_rven_1d_m': revenue
            })
    
    return pd.DataFrame(builtin_data)

# ==================== æ—¥æœŸå¤„ç†å‡½æ•° ====================
def get_default_target_month():
    today = datetime.datetime.now()
    if today.month <= 2:
        target_year = today.year - 1
        target_month = today.month + 10
    else:
        target_year = today.year
        target_month = today.month - 2
    return f"{target_year}-{target_month:02d}"

# ==================== æ•°æ®ç±»å‹è½¬æ¢å‡½æ•° ====================
def safe_convert_to_numeric(value):
    """å®‰å…¨åœ°å°†å€¼è½¬æ¢ä¸ºæ•°å€¼ç±»å‹"""
    if pd.isna(value) or value == '' or value is None:
        return 0
    try:
        if isinstance(value, str):
            value = value.strip()
            if value == '' or value.lower() in ['nan', 'null', 'none']:
                return 0
        return pd.to_numeric(value, errors='coerce')
    except:
        return 0

# ==================== å¿«é€Ÿæ•°æ®é¢„è§ˆå‡½æ•° ====================
def quick_preview(df, max_rows=3):
    """å¿«é€Ÿæ•°æ®é¢„è§ˆï¼Œæœ€å¤šæ˜¾ç¤º3è¡Œ"""
    if df.empty:
        return df
    
    # åªå–å‰å‡ è¡Œï¼Œå‡å°‘å¤„ç†æ—¶é—´
    preview_df = df.head(max_rows)
    
    # ç®€å•æ’åºï¼šæŠŠæœ‰å€¼çš„åˆ—æ”¾å‰é¢
    non_empty_cols = []
    empty_cols = []
    
    for col in preview_df.columns:
        if preview_df[col].notna().any():
            non_empty_cols.append(col)
        else:
            empty_cols.append(col)
    
    # ç¡®ä¿'æ•°æ®æ¥æº'åˆ—åœ¨æœ€å‰é¢ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'æ•°æ®æ¥æº' in non_empty_cols:
        non_empty_cols.remove('æ•°æ®æ¥æº')
        non_empty_cols.insert(0, 'æ•°æ®æ¥æº')
    
    return preview_df[non_empty_cols + empty_cols]

# ==================== æ¸ é“æ˜ å°„å¤„ç†å‡½æ•° ====================
def parse_channel_mapping_from_excel(channel_file):
    """ä»ä¸Šä¼ çš„Excelæ–‡ä»¶è§£ææ¸ é“æ˜ å°„"""
    try:
        df = pd.read_excel(channel_file)
        channel_mapping = {}
        
        for _, row in df.iterrows():
            channel_name = str(row.iloc[0]).strip()
            if pd.isna(channel_name) or channel_name == '' or channel_name == 'nan':
                continue
                
            pids = []
            for col_idx in range(1, len(row)):
                pid = row.iloc[col_idx]
                if pd.isna(pid) or str(pid).strip() in ['', 'nan', 'ã€€', ' ']:
                    continue
                # ç¡®ä¿æ¸ é“å·ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œå»é™¤å°æ•°
                pid_str = str(int(float(pid))) if isinstance(pid, (int, float)) else str(pid).strip()
                if pid_str:
                    pids.append(pid_str)
            
            if pids:
                channel_mapping[channel_name] = pids
                    
        return channel_mapping
    except Exception as e:
        st.error(f"è§£ææ¸ é“æ˜ å°„æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
        return {}

# ==================== ä¼˜åŒ–çš„OCPXæ•°æ®åˆå¹¶å‡½æ•° ====================
def merge_ocpx_data_optimized(retention_data, new_users_data, target_month):
    """ä¼˜åŒ–çš„OCPXæ ¼å¼æ•°æ®åˆå¹¶å‡½æ•°"""
    try:
        # å¤„ç†æ–°å¢æ•°æ®
        new_users_clean = new_users_data.copy()
        
        # å¿«é€ŸæŸ¥æ‰¾å…³é”®åˆ—
        date_col = None
        new_users_col = None
        
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„åˆ—ååŒ¹é…
        for col in new_users_clean.columns:
            col_str = str(col).strip()
            if 'æ—¥æœŸ' in col_str:
                date_col = col
            elif 'å›ä¼ æ–°å¢æ•°' in col_str or col_str in ['æ–°å¢', 'new', 'å›ä¼ æ–°å¢']:
                new_users_col = col
        
        if date_col is None or new_users_col is None:
            return None
        
        # æ„å»ºæ–°å¢æ•°æ®å­—å…¸ï¼Œåªå¤„ç†ç›®æ ‡æœˆä»½çš„æ•°æ®
        new_users_dict = {}
        for _, row in new_users_clean.iterrows():
            date_val = row[date_col]
            if pd.isna(date_val):
                continue
            
            try:
                # å¿«é€Ÿæ—¥æœŸå¤„ç†
                if isinstance(date_val, str):
                    date_str = date_val.strip()
                    # è·³è¿‡éç›®æ ‡æœˆä»½çš„æ•°æ®
                    if target_month and not date_str.startswith(target_month):
                        continue
                else:
                    date_str = pd.to_datetime(date_val).strftime('%Y-%m-%d')
                    if target_month and not date_str.startswith(target_month):
                        continue
                
                new_users_count = safe_convert_to_numeric(row[new_users_col])
                if new_users_count > 0:
                    new_users_dict[date_str] = new_users_count
            except:
                continue
        
        # å¤„ç†ç•™å­˜æ•°æ®
        retention_clean = retention_data.copy()
        
        # å¿«é€ŸæŸ¥æ‰¾æ—¥æœŸåˆ—
        retention_date_col = None
        for col in retention_clean.columns:
            if 'æ—¥æœŸ' in str(col):
                retention_date_col = col
                break
        
        if retention_date_col is None:
            return None
        
        # åˆå¹¶æ•°æ®ï¼Œåªå¤„ç†ç›®æ ‡æœˆä»½
        merged_data = []
        
        for _, row in retention_clean.iterrows():
            date_val = row[retention_date_col]
            if pd.isna(date_val):
                continue
            
            try:
                # å¿«é€Ÿæ—¥æœŸå¤„ç†
                if isinstance(date_val, str):
                    date_str = date_val.strip()
                    if target_month and not date_str.startswith(target_month):
                        continue
                else:
                    date_str = pd.to_datetime(date_val).strftime('%Y-%m-%d')
                    if target_month and not date_str.startswith(target_month):
                        continue
                
                # æ„å»ºåˆå¹¶åçš„è¡Œæ•°æ®
                merged_row = {
                    'date': date_str,
                    'stat_date': date_str,
                    'æ—¥æœŸ': date_str,
                    'å›ä¼ æ–°å¢æ•°': new_users_dict.get(date_str, 0)
                }
                
                # åªæ·»åŠ æ•°å­—åˆ—åçš„ç•™å­˜æ•°æ®
                for col in retention_clean.columns:
                    col_str = str(col).strip()
                    if col_str.isdigit() and 1 <= int(col_str) <= 30:
                        retain_value = safe_convert_to_numeric(row[col])
                        merged_row[col_str] = retain_value
                
                merged_data.append(merged_row)
                
            except:
                continue
        
        return pd.DataFrame(merged_data) if merged_data else None
            
    except Exception as e:
        st.error(f"å¤„ç†OCPXæ•°æ®æ—¶å‡ºé”™ï¼š{str(e)}")
        return None

# ==================== ä¼˜åŒ–çš„æ–‡ä»¶æ•´åˆæ ¸å¿ƒå‡½æ•° ====================
def integrate_excel_files_optimized(uploaded_files, target_month, channel_mapping):
    """ä¼˜åŒ–ç‰ˆæœ¬çš„æ–‡ä»¶æ•´åˆå‡½æ•°ï¼Œæå‡å¤„ç†é€Ÿåº¦"""
    all_data = pd.DataFrame()
    processed_count = 0
    file_status = []  # è®°å½•æ–‡ä»¶å¤„ç†çŠ¶æ€

    for file in uploaded_files:
        # ä»æ–‡ä»¶åä¸­æå–æ¸ é“åç§°
        source_name = os.path.splitext(file.name)[0].strip()
        
        # æ¸ é“æ˜ å°„å¤„ç†
        mapped_source = source_name
        if source_name in channel_mapping:
            mapped_source = source_name
        else:
            reverse_mapping = create_reverse_mapping(channel_mapping)
            if source_name in reverse_mapping:
                mapped_source = reverse_mapping[source_name]

        try:
            # è¯»å–Excelæ–‡ä»¶
            file_content = file.read()
            xls = pd.ExcelFile(io.BytesIO(file_content))
            sheet_names = xls.sheet_names

            # æŸ¥æ‰¾OCPXæ ¼å¼çš„å·¥ä½œè¡¨
            retention_sheet = None
            new_users_sheet = None
            
            # ç²¾ç¡®åŒ¹é…sheetåç§°
            for sheet in sheet_names:
                if "ocpxç›‘æµ‹ç•™å­˜æ•°" in sheet or "ç›‘æµ‹ç•™å­˜æ•°" in sheet:
                    retention_sheet = sheet
                elif "ç›‘æµ‹æ¸ é“å›ä¼ é‡" in sheet or "å›ä¼ é‡" in sheet:
                    new_users_sheet = sheet
            
            # ä¼˜å…ˆå¤„ç†OCPXåˆ†ç¦»å¼æ ¼å¼
            if retention_sheet and new_users_sheet:
                try:
                    retention_data = pd.read_excel(io.BytesIO(file_content), sheet_name=retention_sheet)
                    new_users_data = pd.read_excel(io.BytesIO(file_content), sheet_name=new_users_sheet)
                    
                    file_data = merge_ocpx_data_optimized(retention_data, new_users_data, target_month)
                    if file_data is not None and not file_data.empty:
                        file_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)
                        all_data = pd.concat([all_data, file_data], ignore_index=True)
                        processed_count += 1
                        file_status.append(f"âœ… {file.name} - OCPXåˆ†ç¦»å¼æ ¼å¼")
                    else:
                        file_status.append(f"âš ï¸ {file.name} - OCPXæ ¼å¼æ•°æ®ä¸ºç©º")
                    continue
                except Exception as e:
                    file_status.append(f"âŒ {file.name} - OCPXæ ¼å¼å¤„ç†å¤±è´¥: {str(e)}")
                    continue
            
            # å¤„ç†å•sheetçš„ä¼ ç»Ÿæ ¼å¼æˆ–å…¶ä»–æ ¼å¼
            if retention_sheet:
                sheet_to_read = retention_sheet
            else:
                sheet_to_read = 0  # ä½¿ç”¨ç¬¬ä¸€ä¸ªsheet
            
            try:
                file_data = pd.read_excel(io.BytesIO(file_content), sheet_name=sheet_to_read)
                
                if file_data is not None and not file_data.empty:
                    # å¿«é€Ÿæ•°æ®å¤„ç†
                    file_data_copy = file_data.copy()
                    
                    # æ£€æµ‹ä¼ ç»Ÿæ ¼å¼ï¼ˆstat_date + new + new_retain_Xï¼‰
                    has_stat_date = 'stat_date' in file_data_copy.columns
                    has_new = 'new' in file_data_copy.columns
                    
                    if has_stat_date and has_new:
                        # ä¼ ç»Ÿæ ¼å¼å¤„ç†
                        standardized_data = file_data_copy.copy()
                        standardized_data['å›ä¼ æ–°å¢æ•°'] = standardized_data['new'].apply(safe_convert_to_numeric)
                        
                        # å¤„ç†ç•™å­˜æ•°æ®åˆ—ï¼šnew_retain_1 -> 1
                        for i in range(1, 31):
                            retain_col = f'new_retain_{i}'
                            if retain_col in standardized_data.columns:
                                standardized_data[str(i)] = standardized_data[retain_col].apply(safe_convert_to_numeric)
                        
                        # å¤„ç†æ—¥æœŸå’Œç­›é€‰
                        standardized_data['stat_date'] = pd.to_datetime(standardized_data['stat_date'], errors='coerce')
                        standardized_data['stat_date'] = standardized_data['stat_date'].dt.strftime('%Y-%m-%d')
                        standardized_data['æ—¥æœŸ'] = standardized_data['stat_date']
                        standardized_data['month'] = standardized_data['stat_date'].str[:7]
                        
                        filtered_data = standardized_data[standardized_data['month'] == target_month].copy()
                        
                        if not filtered_data.empty:
                            filtered_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)
                            filtered_data['date'] = filtered_data['stat_date']
                            all_data = pd.concat([all_data, filtered_data], ignore_index=True)
                            processed_count += 1
                            file_status.append(f"âœ… {file.name} - ä¼ ç»Ÿæ ¼å¼")
                        else:
                            file_status.append(f"âš ï¸ {file.name} - ç›®æ ‡æœˆä»½æ— æ•°æ®")
                    else:
                        # å…¶ä»–æ ¼å¼çš„å…¼å®¹å¤„ç†
                        file_status.append(f"âš ï¸ {file.name} - æ ¼å¼æœªè¯†åˆ«ï¼Œè·³è¿‡")
                        
            except Exception as e:
                file_status.append(f"âŒ {file.name} - å¤„ç†å¤±è´¥: {str(e)}")

        except Exception as e:
            file_status.append(f"âŒ {file.name} - è¯»å–å¤±è´¥: {str(e)}")

    return all_data, processed_count, file_status

# ==================== ç•™å­˜ç‡è®¡ç®—å‡½æ•° ====================
def calculate_retention_rates_optimized(df):
    """ä¼˜åŒ–çš„ç•™å­˜ç‡è®¡ç®—å‡½æ•°"""
    retention_results = []
    data_sources = df['æ•°æ®æ¥æº'].unique()

    for source in data_sources:
        source_data = df[df['æ•°æ®æ¥æº'] == source].copy()
        
        # è®¡ç®—å¹³å‡æ–°å¢ç”¨æˆ·æ•°
        new_users_values = source_data['å›ä¼ æ–°å¢æ•°'].apply(safe_convert_to_numeric)
        new_users_values = new_users_values[new_users_values > 0]
        
        if len(new_users_values) == 0:
            continue
        
        avg_new_users = new_users_values.mean()
        
        # è®¡ç®—å„å¤©ç•™å­˜ç‡
        retention_data = {'data_source': source, 'avg_new_users': avg_new_users}
        days = []
        rates = []
        
        for day in range(1, 31):
            day_col = str(day)
            if day_col not in source_data.columns:
                continue
            
            day_retain_values = source_data[day_col].apply(safe_convert_to_numeric)
            day_retain_values = day_retain_values[day_retain_values >= 0]
            
            if len(day_retain_values) > 0:
                avg_retain = day_retain_values.mean()
                retention_rate = avg_retain / avg_new_users if avg_new_users > 0 else 0
                
                if 0 <= retention_rate <= 1.0:
                    days.append(day)
                    rates.append(retention_rate)
        
        if days:
            retention_results.append({
                'data_source': source,
                'days': np.array(days),
                'rates': np.array(rates),
                'avg_new_users': avg_new_users
            })

    return retention_results

# ==================== æ•°å­¦å»ºæ¨¡å‡½æ•° ====================
def power_function(x, a, b):
    """å¹‚å‡½æ•°ï¼šy = a * x^b"""
    return a * np.power(x, b)

def exponential_function(x, c, d):
    """æŒ‡æ•°å‡½æ•°ï¼šy = c * exp(d * x)"""
    return c * np.exp(d * x)

def calculate_lt_advanced(retention_result, channel_name, lt_years=5, return_curve_data=False):
    """ä¼˜åŒ–çš„LTè®¡ç®—å‡½æ•°"""
    # æ¸ é“è§„åˆ™
    CHANNEL_RULES = {
        "åä¸º": {"stage_2": [30, 120], "stage_3_base": [120, 220]},
        "å°ç±³": {"stage_2": [30, 190], "stage_3_base": [190, 290]},
        "oppo": {"stage_2": [30, 160], "stage_3_base": [160, 260]},
        "vivo": {"stage_2": [30, 150], "stage_3_base": [150, 250]},
        "iphone": {"stage_2": [30, 150], "stage_3_base": [150, 250]},
        "å…¶ä»–": {"stage_2": [30, 100], "stage_3_base": [100, 200]}
    }

    # æ¸ é“è§„åˆ™åŒ¹é…
    if re.search(r'åä¸º', channel_name):
        rules = CHANNEL_RULES["åä¸º"]
    elif re.search(r'å°ç±³', channel_name):
        rules = CHANNEL_RULES["å°ç±³"]
    elif re.search(r'[oO][pP][pP][oO]', channel_name):
        rules = CHANNEL_RULES["oppo"]
    elif re.search(r'vivo', channel_name):
        rules = CHANNEL_RULES["vivo"]
    elif re.search(r'[iI][pP]hone', channel_name):
        rules = CHANNEL_RULES["iphone"]
    else:
        rules = CHANNEL_RULES["å…¶ä»–"]
        
    stage_2_start, stage_2_end = rules["stage_2"]
    stage_3_base_start, stage_3_base_end = rules["stage_3_base"]
    max_days = lt_years * 365

    days = retention_result["days"]
    rates = retention_result["rates"]

    # ç¬¬ä¸€é˜¶æ®µ - å¹‚å‡½æ•°æ‹Ÿåˆ
    try:
        popt_power, _ = curve_fit(power_function, days, rates)
        a, b = popt_power
        
        days_full = np.arange(1, 31)
        rates_full = power_function(days_full, a, b)
        lt1_to_30 = np.sum(rates_full)
    except:
        lt1_to_30 = 0.0
        a, b = 1.0, -1.0

    # ç¬¬äºŒé˜¶æ®µ
    try:
        days_stage_2 = np.arange(stage_2_start, stage_2_end + 1)
        rates_stage_2 = power_function(days_stage_2, a, b)
        lt_stage_2 = np.sum(rates_stage_2)
    except:
        lt_stage_2 = 0.0

    # ç¬¬ä¸‰é˜¶æ®µ - æŒ‡æ•°æ‹Ÿåˆ
    try:
        days_stage_3_base = np.arange(stage_3_base_start, stage_3_base_end + 1)
        rates_stage_3_base = power_function(days_stage_3_base, a, b)

        initial_c = rates_stage_3_base[0]
        initial_d = -0.001
        popt_exp, _ = curve_fit(
            exponential_function,
            days_stage_3_base,
            rates_stage_3_base,
            p0=[initial_c, initial_d],
            bounds=([0, -np.inf], [np.inf, 0])
        )
        c, d = popt_exp
        
        days_stage_3 = np.arange(stage_3_base_start, max_days + 1)
        rates_stage_3 = exponential_function(days_stage_3, c, d)
        lt_stage_3 = np.sum(rates_stage_3)
    except:
        days_stage_3 = np.arange(stage_3_base_start, max_days + 1)
        rates_stage_3 = power_function(days_stage_3, a, b) if 'a' in locals() else np.zeros(len(days_stage_3))
        lt_stage_3 = np.sum(rates_stage_3)

    total_lt = 1.0 + lt1_to_30 + lt_stage_2 + lt_stage_3

    if return_curve_data:
        # æ„å»ºå®Œæ•´æ›²çº¿æ•°æ®
        all_days = np.concatenate([days_full, days_stage_2, days_stage_3])
        all_rates = np.concatenate([rates_full, rates_stage_2, rates_stage_3])

        # æ’åºå¹¶é™åˆ¶å¤©æ•°
        sort_idx = np.argsort(all_days)
        all_days = all_days[sort_idx]
        all_rates = all_rates[sort_idx]

        max_idx = np.searchsorted(all_days, lt_years * 365, side='right')
        all_days = all_days[:max_idx]
        all_rates = all_rates[:max_idx]

        return {
            'lt_value': total_lt,
            'success': True,
            'days': all_days,
            'rates': all_rates
        }

    return total_lt

# ==================== å›¾è¡¨ç”Ÿæˆå‡½æ•° ====================
def create_channel_chart(channel_name, curve_data, original_data, max_days=100):
    """åˆ›å»ºå•ä¸ªæ¸ é“çš„æ‹Ÿåˆå›¾è¡¨"""
    plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    fig, ax = plt.subplots(figsize=(8, 6))
    
    # ç»˜åˆ¶å®é™…æ•°æ®ç‚¹
    if channel_name in original_data:
        ax.scatter(
            original_data[channel_name]["days"],
            original_data[channel_name]["rates"],
            color='#ef4444',
            s=60,
            alpha=0.8,
            label='Actual Data',
            zorder=3
        )
    
    # ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿ï¼ˆé™åˆ¶åœ¨max_dayså†…ï¼‰
    curve_days = curve_data["days"]
    curve_rates = curve_data["rates"]
    
    mask = curve_days <= max_days
    curve_days_filtered = curve_days[mask]
    curve_rates_filtered = curve_rates[mask]
    
    ax.plot(
        curve_days_filtered,
        curve_rates_filtered,
        color='#3b82f6',
        linewidth=2.5,
        label='Fitted Curve',
        zorder=2
    )
    
    # è®¾ç½®å›¾è¡¨æ ·å¼
    ax.set_xlim(0, max_days)
    ax.set_ylim(0, 0.6)
    ax.set_xlabel('Retention Days', fontsize=12)
    ax.set_ylabel('Retention Rate', fontsize=12)
    ax.set_title(f'{channel_name} ({max_days}d LT Fitting)', fontsize=14, fontweight='bold')
    ax.grid(True, linestyle='--', alpha=0.4)
    ax.legend(fontsize=10)
    
    # Yè½´ç™¾åˆ†æ¯”æ ¼å¼
    y_ticks = [0, 0.15, 0.3, 0.45, 0.6]
    y_labels = ['0%', '15%', '30%', '45%', '60%']
    ax.set_yticks(y_ticks)
    ax.set_yticklabels(y_labels)
    
    plt.tight_layout()
    return fig

# ==================== ä¸»åº”ç”¨ç¨‹åº ====================

# ä¸»æ ‡é¢˜
st.markdown("""
<div class="main-header">
    <div class="main-title">ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†æç³»ç»Ÿ - ä¼˜åŒ–ç‰ˆ</div>
    <div class="main-subtitle">åŸºäºåˆ†é˜¶æ®µæ•°å­¦å»ºæ¨¡çš„LTVé¢„æµ‹ | æå‡ä¸Šä¼ é€Ÿåº¦</div>
</div>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
session_keys = [
    'channel_mapping', 'merged_data', 'retention_data', 'lt_results_2y', 
    'lt_results_5y', 'arpu_data', 'ltv_results', 'current_step',
    'visualization_data_5y', 'original_data', 'admin_default_arpu_data'
]
for key in session_keys:
    if key not in st.session_state:
        st.session_state[key] = None

# è®¾ç½®é»˜è®¤å€¼
if st.session_state.channel_mapping is None:
    st.session_state.channel_mapping = DEFAULT_CHANNEL_MAPPING
if st.session_state.current_step is None:
    st.session_state.current_step = 0

# ==================== åˆ†ææ­¥éª¤å®šä¹‰ ====================
ANALYSIS_STEPS = [
    {"name": "LTæ¨¡å‹æ„å»º", "sub_steps": ["æ•°æ®ä¸Šä¼ æ±‡æ€»", "å¼‚å¸¸å€¼å‰”é™¤", "ç•™å­˜ç‡è®¡ç®—", "LTæ‹Ÿåˆåˆ†æ"]},
    {"name": "ARPUè®¡ç®—"},
    {"name": "LTVç»“æœæŠ¥å‘Š"}
]

# ==================== ä¾§è¾¹æ å¯¼èˆª ====================
with st.sidebar:
    st.markdown('<div class="nav-container">', unsafe_allow_html=True)
    st.markdown('<h4 style="text-align: center; margin-bottom: 1rem; color: white;">åˆ†ææµç¨‹</h4>',
                unsafe_allow_html=True)

    for i, step in enumerate(ANALYSIS_STEPS):
        button_text = f"{i + 1}. {step['name']}"
        if st.button(button_text, key=f"nav_{i}", use_container_width=True,
                     type="primary" if i == st.session_state.current_step else "secondary"):
            st.session_state.current_step = i
            st.rerun()
        
        # æ˜¾ç¤ºå­æ­¥éª¤
        if "sub_steps" in step and i == st.session_state.current_step:
            sub_steps_text = " â€¢ ".join(step["sub_steps"])
            st.markdown(f'<div class="sub-steps">{sub_steps_text}</div>', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)

# ==================== é¡µé¢è·¯ç”± ====================
current_page = ANALYSIS_STEPS[st.session_state.current_step]["name"]

# ==================== é¡µé¢å†…å®¹ ====================

if current_page == "LTæ¨¡å‹æ„å»º":
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š LTæ¨¡å‹æ„å»ºåŸç†</div>
        <div class="principle-content">
        LTæ¨¡å‹æ„å»ºåŒ…å«å››ä¸ªæ ¸å¿ƒæ­¥éª¤ï¼š<br>
        <strong>1. æ•°æ®ä¸Šä¼ æ±‡æ€»ï¼š</strong>å¿«é€Ÿæ•´åˆå¤šä¸ªExcelæ–‡ä»¶ï¼Œæ”¯æŒOCPXæ–°æ ¼å¼<br>
        <strong>2. å¼‚å¸¸å€¼å‰”é™¤ï¼š</strong>å‰”é™¤å¼‚å¸¸æ¸ é“å’Œæ—¥æœŸæ•°æ®ï¼Œæé«˜æ•°æ®è´¨é‡<br>
        <strong>3. ç•™å­˜ç‡è®¡ç®—ï¼š</strong>OCPXæ ¼å¼ï¼šå„å¤©ç•™å­˜åˆ—ï¼ˆ1ã€2ã€3...ï¼‰å¹³å‡å€¼Ã·å›ä¼ æ–°å¢æ•°å¹³å‡å€¼<br>
        <strong>4. LTæ‹Ÿåˆåˆ†æï¼š</strong>é‡‡ç”¨ä¸‰é˜¶æ®µåˆ†å±‚å»ºæ¨¡ï¼Œé¢„æµ‹ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸé•¿åº¦
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # æ­¥éª¤1ï¼šæ•°æ®ä¸Šä¼ ä¸æ±‡æ€»
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.subheader("1. æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»")
    
    # OCPXæ ¼å¼è¯´æ˜
    st.markdown("""
    <div class="step-tip">
        <div class="step-tip-title">ğŸ“‹ æ”¯æŒçš„OCPX Excelæ ¼å¼</div>
        <div class="step-tip-content">
        <strong>æ–¹å¼1ï¼šOCPXåˆ†ç¦»å¼æ ¼å¼ï¼ˆæ¨èï¼‰</strong><br>
        â€¢ Sheet: <strong>"ç›‘æµ‹æ¸ é“å›ä¼ é‡"</strong> - åˆ—ï¼šæ—¥æœŸã€å›ä¼ æ–°å¢æ•°<br>
        â€¢ Sheet: <strong>"ocpxç›‘æµ‹ç•™å­˜æ•°"</strong> - åˆ—ï¼šæ—¥æœŸã€1ã€2ã€3ã€4ã€5...ï¼ˆå¤©æ•°ï¼‰<br><br>
        <strong>æ–¹å¼2ï¼šä¼ ç»Ÿæ ¼å¼</strong><br>
        â€¢ åˆ—åï¼š<strong>stat_date</strong>ï¼ˆæ—¥æœŸï¼‰ã€<strong>new</strong>ï¼ˆæ–°å¢ï¼‰ã€<strong>new_retain_1ã€new_retain_2...</strong>ï¼ˆç•™å­˜ï¼‰<br><br>
        <strong>å‘½åè§„åˆ™ï¼š</strong>è¯·æŒ‰æ¸ é“åç§°å‘½åæ–‡ä»¶ï¼Œå¦‚ï¼šåä¸º.xlsxã€å°ç±³.xlsx
        </div>
    </div>
    """, unsafe_allow_html=True)

    # æ¸ é“æ˜ å°„æ‘˜è¦
    with st.expander("ğŸ” æŸ¥çœ‹æ¸ é“æ˜ å°„æ‘˜è¦", expanded=False):
        current_channels = list(st.session_state.channel_mapping.keys())
        st.markdown(f"**å½“å‰å…±æœ‰ {len(current_channels)} ä¸ªæ¸ é“**")
        channels_text = "ã€".join(current_channels[:10])
        if len(current_channels) > 10:
            channels_text += f"...ç­‰{len(current_channels)}ä¸ªæ¸ é“"
        st.text(channels_text)

    # è‡ªå®šä¹‰æ¸ é“æ˜ å°„ï¼ˆå¯é€‰ï¼‰
    if st.checkbox("éœ€è¦ä¸Šä¼ è‡ªå®šä¹‰æ¸ é“æ˜ å°„"):
        channel_mapping_file = st.file_uploader(
            "é€‰æ‹©æ¸ é“æ˜ å°„Excelæ–‡ä»¶",
            type=['xlsx', 'xls'],
            help="æ ¼å¼ï¼šç¬¬ä¸€åˆ—ä¸ºæ¸ é“åç§°ï¼Œåç»­åˆ—ä¸ºå¯¹åº”çš„æ¸ é“å·"
        )
        
        if channel_mapping_file:
            custom_mapping = parse_channel_mapping_from_excel(channel_mapping_file)
            if custom_mapping:
                st.session_state.channel_mapping = custom_mapping
                st.success(f"âœ… è‡ªå®šä¹‰æ¸ é“æ˜ å°„åŠ è½½æˆåŠŸï¼å…± {len(custom_mapping)} ä¸ªæ¸ é“")

    # æ•°æ®æ–‡ä»¶ä¸Šä¼ 
    st.markdown("### ğŸ“¤ æ•°æ®æ–‡ä»¶ä¸Šä¼ ")
    
    uploaded_files = st.file_uploader(
        "é€‰æ‹©Excelæ•°æ®æ–‡ä»¶",
        type=['xlsx', 'xls'],
        accept_multiple_files=True,
        help="æ”¯æŒOCPXåˆ†ç¦»å¼æ ¼å¼å’Œä¼ ç»Ÿæ ¼å¼"
    )
    
    default_month = get_default_target_month()
    target_month = st.text_input("ç›®æ ‡æœˆä»½ (YYYY-MM)", value=default_month)

    if uploaded_files:
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")

        if st.button("ğŸš€ å¿«é€Ÿå¤„ç†æ•°æ®", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨å¿«é€Ÿå¤„ç†æ•°æ®æ–‡ä»¶..."):
                try:
                    merged_data, processed_count, file_status = integrate_excel_files_optimized(
                        uploaded_files, target_month, st.session_state.channel_mapping
                    )

                    if merged_data is not None and not merged_data.empty:
                        st.session_state.merged_data = merged_data
                        
                        # æ˜¾ç¤ºå¤„ç†ç»“æœ
                        st.markdown("""
                        <div class="success-info">
                            <strong>âœ… æ•°æ®å¤„ç†å®Œæˆï¼</strong>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("å¤„ç†æˆåŠŸ", f"{processed_count} ä¸ªæ–‡ä»¶")
                        with col2:
                            st.metric("æ€»è®°å½•æ•°", f"{len(merged_data):,}")
                        with col3:
                            st.metric("æ¸ é“æ•°", merged_data['æ•°æ®æ¥æº'].nunique())

                        # æ˜¾ç¤ºæ–‡ä»¶å¤„ç†çŠ¶æ€
                        with st.expander("ğŸ“‹ æ–‡ä»¶å¤„ç†çŠ¶æ€", expanded=True):
                            for status in file_status:
                                if "âœ…" in status:
                                    st.success(status)
                                elif "âš ï¸" in status:
                                    st.warning(status)
                                else:
                                    st.error(status)

                        # ç®€åŒ–çš„æ•°æ®é¢„è§ˆ
                        st.subheader("æ•°æ®é¢„è§ˆ")
                        for source in merged_data['æ•°æ®æ¥æº'].unique():
                            source_data = merged_data[merged_data['æ•°æ®æ¥æº'] == source]
                            with st.expander(f"ğŸ“Š {source} ({len(source_data)} æ¡è®°å½•)", expanded=False):
                                preview = quick_preview(source_data, max_rows=3)
                                st.dataframe(preview, use_container_width=True)
                                
                    else:
                        st.error("æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
                except Exception as e:
                    st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")
    
    st.markdown('</div>', unsafe_allow_html=True)


    # æ­¥éª¤2ï¼šå¼‚å¸¸å€¼å‰”é™¤
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.subheader("2. å¼‚å¸¸å€¼å‰”é™¤")
    
    if st.session_state.merged_data is not None:
        working_data = st.session_state.merged_data
        data_sources = working_data['æ•°æ®æ¥æº'].unique()
        date_columns = [col for col in working_data.columns if 'æ—¥æœŸ' in col or 'date' in col.lower()]
        
        # å¼‚å¸¸å€¼å‰”é™¤é€‰æ‹©
        col1, col2 = st.columns(2)
        with col1:
            excluded_channels = st.multiselect(
                "é€‰æ‹©è¦å‰”é™¤çš„æ¸ é“",
                options=data_sources,
                help="é€‰ä¸­çš„æ¸ é“å°†åœ¨åç»­è®¡ç®—ä¸­è¢«å‰”é™¤"
            )
        with col2:
            excluded_dates = st.multiselect(
                "é€‰æ‹©è¦å‰”é™¤çš„æ—¥æœŸ",
                options=date_columns if date_columns else ['æ— æ—¥æœŸåˆ—'],
                help="é€‰ä¸­çš„æ—¥æœŸåˆ—çš„æ•°æ®å°†åœ¨åç»­è®¡ç®—ä¸­è¢«å‰”é™¤"
            )
        
        # æ˜¾ç¤ºå‰”é™¤è§„åˆ™
        if excluded_channels or (excluded_dates and excluded_dates != ['æ— æ—¥æœŸåˆ—']):
            st.info(f"ğŸ“‹ å‰”é™¤è§„åˆ™ï¼šæ¸ é“ {excluded_channels} ä¸”æ—¥æœŸ {excluded_dates} çš„æ•°æ®å°†è¢«å‰”é™¤")
            
            # ä¿å­˜å‰”é™¤è§„åˆ™åˆ°session_state
            st.session_state.excluded_channels = excluded_channels
            st.session_state.excluded_dates = excluded_dates
        else:
            st.session_state.excluded_channels = []
            st.session_state.excluded_dates = []
            
    else:
        st.info("è¯·å…ˆå®Œæˆæ•°æ®ä¸Šä¼ ä¸æ±‡æ€»")
    
    st.markdown('</div>', unsafe_allow_html=True)

    # æ­¥éª¤3ï¼šç•™å­˜ç‡è®¡ç®—ï¼ˆé»˜è®¤æ˜¾ç¤ºï¼Œä¸éœ€è¦æ¡ä»¶åˆ¤æ–­ï¼‰
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.subheader("3. ç•™å­˜ç‡è®¡ç®—")
    
    if st.session_state.merged_data is not None:
        working_data = st.session_state.merged_data
        data_sources = working_data['æ•°æ®æ¥æº'].unique()
        selected_sources = st.multiselect("é€‰æ‹©è¦åˆ†æçš„æ•°æ®æ¥æº", options=data_sources, default=data_sources)

        if st.button("ğŸ’¡ å¿«é€Ÿè®¡ç®—ç•™å­˜ç‡", type="primary", use_container_width=True):
            if selected_sources:
                with st.spinner("æ­£åœ¨è®¡ç®—ç•™å­˜ç‡..."):
                    filtered_data = working_data[working_data['æ•°æ®æ¥æº'].isin(selected_sources)]
                    retention_results = calculate_retention_rates_optimized(filtered_data)
                    st.session_state.retention_data = retention_results

                    st.success("ç•™å­˜ç‡è®¡ç®—å®Œæˆï¼")
                    
                    # æ˜¾ç¤ºç®€åŒ–çš„ç»“æœæ‘˜è¦
                    if retention_results:
                        summary_data = []
                        for result in retention_results:
                            summary_data.append({
                                'æ¸ é“': result['data_source'],
                                'æœ‰æ•ˆå¤©æ•°': len(result['days']),
                                'å¹³å‡æ–°å¢': f"{result['avg_new_users']:,.0f}",
                                '1å¤©ç•™å­˜ç‡': f"{result['rates'][0]:.3f}" if len(result['rates']) > 0 else "-"
                            })
                        
                        summary_df = pd.DataFrame(summary_data)
                        st.dataframe(summary_df, use_container_width=True)
            else:
                st.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ•°æ®æ¥æº")
    else:
        st.info("è¯·å…ˆå®Œæˆæ•°æ®ä¸Šä¼ ä¸æ±‡æ€»")

    st.markdown('</div>', unsafe_allow_html=True)

    # æ­¥éª¤3ï¼šLTæ‹Ÿåˆåˆ†æï¼ˆé»˜è®¤æ˜¾ç¤ºï¼Œä¸éœ€è¦æ¡ä»¶åˆ¤æ–­ï¼‰
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.subheader("3. LTæ‹Ÿåˆåˆ†æ")
    
    st.markdown("""
    <div class="step-tip">
        <div class="step-tip-title">ğŸ“‹ ä¸‰é˜¶æ®µæ‹Ÿåˆè§„åˆ™</div>
        <div class="step-tip-content">
        <strong>ç¬¬ä¸€é˜¶æ®µï¼š</strong>1-30å¤©ï¼Œå¹‚å‡½æ•°æ‹Ÿåˆå®é™…æ•°æ®<br>
        <strong>ç¬¬äºŒé˜¶æ®µï¼š</strong>31-Xå¤©ï¼Œå»¶ç»­å¹‚å‡½æ•°æ¨¡å‹<br>
        <strong>ç¬¬ä¸‰é˜¶æ®µï¼š</strong>Yå¤©åï¼ŒæŒ‡æ•°å‡½æ•°å»ºæ¨¡é•¿æœŸè¡°å‡
        </div>
    </div>
    """, unsafe_allow_html=True)

    if st.session_state.retention_data is not None:
        if st.button("âš¡ å¿«é€ŸLTæ‹Ÿåˆåˆ†æ", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨è¿›è¡Œæ‹Ÿåˆè®¡ç®—..."):
                lt_results_2y = []
                lt_results_5y = []
                visualization_data_5y = {}
                original_data = {}

                for retention_result in st.session_state.retention_data:
                    channel_name = retention_result['data_source']
                    
                    # è®¡ç®—2å¹´å’Œ5å¹´LT
                    lt_result_2y = calculate_lt_advanced(retention_result, channel_name, 2, return_curve_data=True)
                    lt_result_5y = calculate_lt_advanced(retention_result, channel_name, 5, return_curve_data=True)

                    lt_results_2y.append({
                        'data_source': channel_name,
                        'lt_value': lt_result_2y['lt_value'],
                        'fit_success': lt_result_2y['success']
                    })
                    
                    lt_results_5y.append({
                        'data_source': channel_name,
                        'lt_value': lt_result_5y['lt_value'],
                        'fit_success': lt_result_5y['success']
                    })

                    # ä¿å­˜å¯è§†åŒ–æ•°æ®
                    visualization_data_5y[channel_name] = {
                        "days": lt_result_5y['days'],
                        "rates": lt_result_5y['rates'],
                        "lt": lt_result_5y['lt_value']
                    }

                    # ä¿å­˜åŸå§‹æ•°æ®
                    original_data[channel_name] = {
                        "days": retention_result['days'],
                        "rates": retention_result['rates']
                    }

                st.session_state.lt_results_2y = lt_results_2y
                st.session_state.lt_results_5y = lt_results_5y
                st.session_state.visualization_data_5y = visualization_data_5y
                st.session_state.original_data = original_data
                
                st.success("LTæ‹Ÿåˆåˆ†æå®Œæˆï¼")

                # æ˜¾ç¤ºLTå€¼è¡¨æ ¼
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### 2å¹´LTç»“æœ")
                    results_2y_df = pd.DataFrame([
                        {'æ¸ é“åç§°': r['data_source'], '2å¹´LT': round(r['lt_value'], 2)}
                        for r in lt_results_2y
                    ])
                    st.dataframe(results_2y_df, use_container_width=True)
                
                with col2:
                    st.markdown("#### 5å¹´LTç»“æœ")
                    results_5y_df = pd.DataFrame([
                        {'æ¸ é“åç§°': r['data_source'], '5å¹´LT': round(r['lt_value'], 2)}
                        for r in lt_results_5y
                    ])
                    st.dataframe(results_5y_df, use_container_width=True)
    else:
        st.info("è¯·å…ˆå®Œæˆç•™å­˜ç‡è®¡ç®—")

    st.markdown('</div>', unsafe_allow_html=True)

elif current_page == "ARPUè®¡ç®—":
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š ARPUè®¡ç®—åŸç†</div>
        <div class="principle-content">
        ARPUï¼ˆAverage Revenue Per Userï¼‰= æ€»æ”¶å…¥ Ã· æ€»æ–°å¢ç”¨æˆ·æ•°ã€‚
        æ”¯æŒç®¡ç†å‘˜è®¾ç½®é»˜è®¤æ•°æ®å’Œç”¨æˆ·ä¸Šä¼ æœ€æ–°æ•°æ®åˆå¹¶è®¡ç®—ã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)

    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.subheader("ARPUæ•°æ®å¤„ç†")

    # æ•°æ®æºé€‰æ‹©ï¼ˆé»˜è®¤æŠ˜å ï¼‰
    with st.expander("ğŸ“‹ é€‰æ‹©ARPUæ•°æ®æ¥æº", expanded=False):
        data_source_option = st.radio(
            "é€‰æ‹©æ•°æ®æ¥æºï¼š",
            options=[
                "ğŸ”§ ç®¡ç†å‘˜æ¨¡å¼:ç®¡ç†é»˜è®¤ARPUæ•°æ®",
                "ğŸ“Š ä½¿ç”¨é»˜è®¤æ•°æ® + ä¸Šä¼ æ–°æ•°æ®(2025.5+)"
            ],
            index=1  # é»˜è®¤å€¼æ˜¯ç¬¬äºŒä¸ª
        )

    # ç®¡ç†å‘˜åŠŸèƒ½ï¼ˆé»˜è®¤æŠ˜å ï¼‰
    if data_source_option == "ğŸ”§ ç®¡ç†å‘˜æ¨¡å¼:ç®¡ç†é»˜è®¤ARPUæ•°æ®":
        with st.expander("ğŸ”§ ç®¡ç†å‘˜åŠŸèƒ½ï¼šè®¾ç½®é»˜è®¤ARPUæ•°æ®", expanded=False):
            st.markdown("### ğŸ”§ ç®¡ç†å‘˜åŠŸèƒ½ï¼šè®¾ç½®é»˜è®¤ARPUæ•°æ®")
            
            admin_arpu_file = st.file_uploader(
                "ä¸Šä¼ å®Œæ•´çš„ARPUå†å²æ•°æ®æ–‡ä»¶",
                type=['xlsx', 'xls'],
                help="å¿…é¡»åŒ…å«åˆ—ï¼šæœˆä»½ã€pidã€stat_dateã€instl_user_cntã€ad_all_rven_1d_m"
            )
            
            if admin_arpu_file:
                try:
                    admin_df = pd.read_excel(admin_arpu_file)
                    required_cols = ['æœˆä»½', 'pid', 'stat_date', 'instl_user_cnt', 'ad_all_rven_1d_m']
                    missing_cols = [col for col in required_cols if col not in admin_df.columns]
                    
                    if missing_cols:
                        st.error(f"âŒ æ–‡ä»¶ç¼ºå°‘å¿…éœ€åˆ—: {', '.join(missing_cols)}")
                    else:
                        st.success(f"âœ… ç®¡ç†å‘˜æ•°æ®è¯»å–æˆåŠŸï¼{len(admin_df):,} æ¡è®°å½•")
                        
                        if st.button("è®¾ç½®ä¸ºé»˜è®¤æ•°æ®", type="primary"):
                            st.session_state.admin_default_arpu_data = admin_df.copy()
                            st.success("ğŸ‰ é»˜è®¤ARPUæ•°æ®å·²æ›´æ–°ï¼")
                except Exception as e:
                    st.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
        
        # ä½¿ç”¨é»˜è®¤æ•°æ®è¿›è¡Œå¤„ç†
        arpu_df = get_builtin_arpu_data()
        st.info(f"ğŸ“Š å½“å‰é»˜è®¤æ•°æ®ï¼š{len(arpu_df):,} æ¡è®°å½•ï¼Œè¦†ç›– {arpu_df['æœˆä»½'].nunique()} ä¸ªæœˆä»½")
        process_arpu = True
    
    else:  # ä½¿ç”¨é»˜è®¤æ•°æ® + ä¸Šä¼ æ–°æ•°æ®(2025.5+)
        # æ˜¾ç¤ºé»˜è®¤æ•°æ®ä¿¡æ¯
        builtin_df = get_builtin_arpu_data()
        st.info(f"ğŸ“Š é»˜è®¤æ•°æ®ï¼š{len(builtin_df):,} æ¡è®°å½•ï¼Œè¦†ç›– {builtin_df['æœˆä»½'].nunique()} ä¸ªæœˆä»½")
        
        # ä¸Šä¼ æ–°æ•°æ®
        new_arpu_file = st.file_uploader("ä¸Šä¼ 2025å¹´5æœˆåçš„ARPUæ•°æ®", type=['xlsx', 'xls'])
        
        if new_arpu_file:
            try:
                new_df = pd.read_excel(new_arpu_file)
                # åˆå¹¶æ•°æ®é€»è¾‘
                combined_df = pd.concat([builtin_df, new_df], ignore_index=True)
                st.success(f"æ•°æ®åˆå¹¶æˆåŠŸï¼æ€»è®¡ {len(combined_df):,} æ¡è®°å½•")
                arpu_df = combined_df
                process_arpu = True
            except Exception as e:
                st.error(f"å¤„ç†æ–°æ•°æ®å¤±è´¥ï¼š{str(e)}")
                process_arpu = False
        else:
            arpu_df = builtin_df
            process_arpu = True

    # ARPUè®¡ç®—
    if 'process_arpu' in locals() and process_arpu and 'arpu_df' in locals():
        if st.button("ğŸš€ å¿«é€Ÿè®¡ç®—ARPU", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨è®¡ç®—ARPU..."):
                try:
                    # ç¡®ä¿pidä¸ºå­—ç¬¦ä¸²æ ¼å¼
                    arpu_df['pid'] = arpu_df['pid'].astype(str).str.replace('.0', '', regex=False)
                    
                    # åˆ›å»ºåå‘æ¸ é“æ˜ å°„
                    reverse_mapping = create_reverse_mapping(st.session_state.channel_mapping)
                    
                    # æŒ‰æ¸ é“è®¡ç®—ARPU
                    arpu_results = []
                    
                    for pid, group in arpu_df.groupby('pid'):
                        if pid in reverse_mapping:
                            channel_name = reverse_mapping[pid]
                            total_users = group['instl_user_cnt'].sum()
                            total_revenue = group['ad_all_rven_1d_m'].sum()
                            
                            if total_users > 0:
                                arpu_value = total_revenue / total_users
                                arpu_results.append({
                                    'data_source': channel_name,
                                    'total_users': total_users,
                                    'total_revenue': total_revenue,
                                    'arpu_value': arpu_value
                                })

                    if arpu_results:
                        # åˆå¹¶ç›¸åŒæ¸ é“çš„æ•°æ®
                        final_arpu = {}
                        for result in arpu_results:
                            channel = result['data_source']
                            if channel in final_arpu:
                                final_arpu[channel]['total_users'] += result['total_users']
                                final_arpu[channel]['total_revenue'] += result['total_revenue']
                            else:
                                final_arpu[channel] = result.copy()
                        
                        # é‡æ–°è®¡ç®—ARPU
                        arpu_summary = []
                        for channel, data in final_arpu.items():
                            arpu_value = data['total_revenue'] / data['total_users'] if data['total_users'] > 0 else 0
                            arpu_summary.append({
                                'data_source': channel,
                                'arpu_value': arpu_value
                            })
                        
                        arpu_summary_df = pd.DataFrame(arpu_summary)
                        st.session_state.arpu_data = arpu_summary_df
                        st.success("ARPUè®¡ç®—å®Œæˆï¼")
                        
                        # æ˜¾ç¤ºç»“æœ
                        display_df = arpu_summary_df.copy()
                        display_df['ARPU'] = display_df['arpu_value'].round(4)
                        display_df = display_df[['data_source', 'ARPU']]
                        display_df.columns = ['æ¸ é“åç§°', 'ARPUå€¼']
                        st.dataframe(display_df, use_container_width=True)
                    else:
                        st.error("æœªæ‰¾åˆ°åŒ¹é…çš„æ¸ é“æ•°æ®")

                except Exception as e:
                    st.error(f"ARPUè®¡ç®—å¤±è´¥ï¼š{str(e)}")

    st.markdown('</div>', unsafe_allow_html=True)

elif current_page == "LTVç»“æœæŠ¥å‘Š":
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š LTVç»“æœæŠ¥å‘Š</div>
        <div class="principle-content">
        LTVç»“æœæŠ¥å‘Šæ•´åˆLTæ‹Ÿåˆåˆ†æå’ŒARPUè®¡ç®—ç»“æœï¼Œé€šè¿‡LTV = LT Ã— ARPUå…¬å¼è®¡ç®—ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼ã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.lt_results_5y is not None and st.session_state.arpu_data is not None:
        lt_results_2y = st.session_state.lt_results_2y
        lt_results_5y = st.session_state.lt_results_5y
        arpu_data = st.session_state.arpu_data

        # è®¡ç®—LTVç»“æœ
        ltv_results = []
        
        for lt_result_5y in lt_results_5y:
            source = lt_result_5y['data_source']
            
            # æŸ¥æ‰¾å¯¹åº”çš„2å¹´LTæ•°æ®
            lt_result_2y = next((r for r in lt_results_2y if r['data_source'] == source), None)
            
            # æŸ¥æ‰¾ARPUæ•°æ®
            arpu_row = arpu_data[arpu_data['data_source'] == source]
            if not arpu_row.empty:
                arpu_value = arpu_row.iloc[0]['arpu_value']
            else:
                arpu_value = 0

            ltv_5y = lt_result_5y['lt_value'] * arpu_value
            ltv_2y = lt_result_2y['lt_value'] * arpu_value if lt_result_2y else 0

            ltv_results.append({
                'data_source': source,
                'lt_2y': lt_result_2y['lt_value'] if lt_result_2y else 0,
                'lt_5y': lt_result_5y['lt_value'],
                'arpu_value': arpu_value,
                'ltv_2y': ltv_2y,
                'ltv_5y': ltv_5y
            })

        st.session_state.ltv_results = ltv_results

        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("LTVç»¼åˆè®¡ç®—ç»“æœ")

        # åˆ›å»ºç»“æœè¡¨æ ¼
        display_data = []
        for result in ltv_results:
            display_data.append({
                'æ¸ é“åç§°': result['data_source'],
                '5å¹´LT': round(result['lt_5y'], 2),
                '5å¹´ARPU': round(result['arpu_value'], 4),
                '5å¹´LTV': round(result['ltv_5y'], 2),
                '2å¹´LT': round(result['lt_2y'], 2),
                '2å¹´LTV': round(result['ltv_2y'], 2)
            })

        results_df = pd.DataFrame(display_data)
        st.dataframe(results_df, use_container_width=True, height=400)
        st.markdown('</div>', unsafe_allow_html=True)

        # æ˜¾ç¤ºæ‹Ÿåˆæ›²çº¿å›¾è¡¨
        if st.session_state.visualization_data_5y and st.session_state.original_data:
            st.markdown('<div class="glass-card">', unsafe_allow_html=True)
            st.subheader("æ¸ é“æ‹Ÿåˆæ›²çº¿ï¼ˆ100å¤©ï¼‰")
            
            visualization_data_5y = st.session_state.visualization_data_5y
            original_data = st.session_state.original_data
            
            # æŒ‰LTå€¼æ’åºæ˜¾ç¤º
            sorted_channels = sorted(visualization_data_5y.items(), key=lambda x: x[1]['lt'])
            
            # æ¯è¡Œæ˜¾ç¤º2ä¸ªå›¾è¡¨
            for i in range(0, len(sorted_channels), 2):
                cols = st.columns(2)
                for j, col in enumerate(cols):
                    if i + j < len(sorted_channels):
                        channel_name, curve_data = sorted_channels[i + j]
                        with col:
                            fig = create_channel_chart(
                                channel_name, curve_data, original_data, max_days=100
                            )
                            st.pyplot(fig, use_container_width=True)
                            plt.close(fig)
            
            st.markdown('</div>', unsafe_allow_html=True)

        # æ•°æ®å¯¼å‡º
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("åˆ†æç»“æœå¯¼å‡º")

        col1, col2 = st.columns(2)

        with col1:
            # CSVå¯¼å‡º
            csv_data = results_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½LTVç»“æœ (CSV)",
                data=csv_data.encode('utf-8-sig'),
                file_name=f"LTV_Results_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv",
                use_container_width=True
            )

        with col2:
            # è¯¦ç»†æŠ¥å‘Š
            report_text = f"""
LTVç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†ææŠ¥å‘Š
===========================================
ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ‰§è¡Œæ‘˜è¦
-----------
åˆ†ææ¸ é“æ•°é‡: {len(results_df)}
5å¹´å¹³å‡LTV: {results_df['5å¹´LTV'].mean():.2f}
5å¹´æœ€é«˜LTV: {results_df['5å¹´LTV'].max():.2f}
2å¹´å¹³å‡LTV: {results_df['2å¹´LTV'].mean():.2f}

è¯¦ç»†ç»“æœ
-----------
{results_df.to_string(index=False)}

æŠ¥å‘Šç”Ÿæˆ: LTVæ™ºèƒ½åˆ†æå¹³å° v4.0 (ä¼˜åŒ–ç‰ˆ)
"""

            st.download_button(
                label="ğŸ“‹ ä¸‹è½½è¯¦ç»†æŠ¥å‘Š (TXT)",
                data=report_text.encode('utf-8'),
                file_name=f"LTV_Report_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                mime="text/plain",
                use_container_width=True
            )

        st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        missing_components = []
        if st.session_state.lt_results_5y is None:
            missing_components.append("LTæ‹Ÿåˆåˆ†æ")
        if st.session_state.arpu_data is None:
            missing_components.append("ARPUè®¡ç®—")
        
        st.info(f"è¯·å…ˆå®Œæˆï¼š{', '.join(missing_components)}")
        st.markdown('</div>', unsafe_allow_html=True)

# ==================== åº•éƒ¨ä¿¡æ¯ ====================
with st.sidebar:
    st.markdown("---")
    st.markdown("""
    <div class="nav-container">
        <h4 style="text-align: center; color: white;">ä¼˜åŒ–è¯´æ˜</h4>
        <p style="font-size: 0.9rem; color: rgba(255,255,255,0.9); text-align: center;">
        âš¡ ä¼˜åŒ–ä¸Šä¼ é€Ÿåº¦<br>
        ğŸ“Š ç®€åŒ–æ•°æ®é¢„è§ˆ<br>
        ğŸš€ å¿«é€Ÿå¤„ç†æµç¨‹
        </p>
        <p style="font-size: 0.8rem; color: rgba(255,255,255,0.7); text-align: center;">
        <strong>OCPXæ ¼å¼æ”¯æŒï¼š</strong><br>
        â€¢ ç›‘æµ‹æ¸ é“å›ä¼ é‡: æ—¥æœŸã€å›ä¼ æ–°å¢æ•°<br>
        â€¢ ocpxç›‘æµ‹ç•™å­˜æ•°: æ—¥æœŸã€1ã€2ã€3...
        </p>
        <p style="font-size: 0.8rem; color: rgba(255,255,255,0.7); text-align: center;">
        LTVæ™ºèƒ½åˆ†æå¹³å° v4.0<br>
        ä¼˜åŒ–ç‰ˆ - æå‡æ€§èƒ½
        </p>
    </div>
    """, unsafe_allow_html=True)
