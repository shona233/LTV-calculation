import streamlit as st
import os
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
import datetime
import tempfile
import zipfile
import io
import matplotlib.pyplot as plt
import matplotlib as mpl
import re
from matplotlib.font_manager import FontProperties
import seaborn as sns
from scipy.optimize import curve_fit

# ==================== åŸºç¡€é…ç½® ====================
# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl.styles.stylesheet')
warnings.filterwarnings('ignore', category=UserWarning,
                        message="Could not infer format, so each element will be parsed individually")

# è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ - å¢å¼ºç‰ˆæœ¬
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    try:
        import matplotlib.font_manager as fm
        
        # ç³»ç»Ÿä¸­æ–‡å­—ä½“åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        chinese_fonts = [
            'SimHei',           # é»‘ä½“
            'Microsoft YaHei',  # å¾®è½¯é›…é»‘
            'SimSun',          # å®‹ä½“
            'KaiTi',           # æ¥·ä½“
            'FangSong',        # ä»¿å®‹
            'STSong',          # åæ–‡å®‹ä½“
            'STHeiti',         # åæ–‡é»‘ä½“
            'Arial Unicode MS', # Arial Unicode MS
            'DejaVu Sans',     # å¤‡ç”¨å­—ä½“
        ]
        
        # è·å–ç³»ç»Ÿæ‰€æœ‰å¯ç”¨å­—ä½“
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“
        selected_font = None
        for font in chinese_fonts:
            if font in available_fonts:
                selected_font = font
                break
        
        if selected_font:
            # è®¾ç½®matplotlibä¸­æ–‡å­—ä½“ - å‚è€ƒç¬¬äºŒæ®µä»£ç çš„è®¾ç½®æ–¹å¼
            plt.rcParams['font.sans-serif'] = [selected_font, 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS']
            plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
            st.success(f"å·²è®¾ç½®ä¸­æ–‡å­—ä½“: {selected_font}")
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS']
            plt.rcParams['axes.unicode_minus'] = False
            st.warning("ä½¿ç”¨é»˜è®¤ä¸­æ–‡å­—ä½“è®¾ç½®")
        
        # è®¾ç½®å­—ä½“å¤§å°
        plt.rcParams['font.size'] = 10
        
        return True
        
    except Exception as e:
        st.warning(f"å­—ä½“è®¾ç½®å¤±è´¥: {e}")
        # ä½¿ç”¨ç¬¬äºŒæ®µä»£ç çš„è®¾ç½®æ–¹å¼ä½œä¸ºå¤‡ç”¨
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS']
        plt.rcParams['axes.unicode_minus'] = False
        return False

# åˆå§‹åŒ–å­—ä½“è®¾ç½®
setup_chinese_font()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="LTV Analytics Platform",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="ğŸ“Š"
)

# ==================== CSS æ ·å¼å®šä¹‰ ====================
# å•†ä¸šè“è‰²ç³»é…è‰²æ ·å¼
st.markdown("""
<style>
    /* å…¨å±€æ ·å¼ */
    .main {
        background: #f8fafc;
        min-height: 100vh;
    }

    .block-container {
        padding: 1rem 1rem 3rem 1rem;
        max-width: 100%;
        background: transparent;
    }

    /* ä¸»æ ‡é¢˜åŒºåŸŸ */
    .main-header {
        background: linear-gradient(135deg, #1e40af 0%, #3b82f6 100%);
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 20px rgba(30, 64, 175, 0.3);
        margin-bottom: 1.5rem;
        text-align: center;
        color: white;
    }

    .main-title {
        font-size: 2rem;
        font-weight: 700;
        color: white;
        margin-bottom: 0.5rem;
        text-shadow: 0 2px 4px rgba(0,0,0,0.3);
    }

    .main-subtitle {
        color: rgba(255,255,255,0.9);
        font-size: 1.2rem;
        font-weight: 400;
    }

    /* å¡ç‰‡æ ·å¼ */
    .glass-card {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 12px;
        padding: 1.5rem;
        box-shadow: 0 8px 32px rgba(30, 64, 175, 0.1);
        border: 1px solid rgba(59, 130, 246, 0.2);
        margin-bottom: 1.5rem;
        backdrop-filter: blur(10px);
    }

    /* åˆ†ç•Œçº¿ */
    .section-divider {
        height: 2px;
        background: linear-gradient(90deg, #1e40af, #3b82f6);
        margin: 1.5rem 0;
    }

    /* æŒ‡æ ‡å¡ç‰‡ */
    .metric-card {
        background: linear-gradient(135deg, #2563eb 0%, #1d4ed8 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 12px;
        text-align: center;
        margin-bottom: 1rem;
        box-shadow: 0 4px 15px rgba(37, 99, 235, 0.3);
    }

    .metric-value {
        font-size: 2.2rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        color: white;
        text-shadow: 0 2px 4px rgba(0,0,0,0.3);
    }

    .metric-label {
        font-size: 0.95rem;
        color: rgba(255,255,255,0.9);
    }

    /* çŠ¶æ€å¡ç‰‡ */
    .status-card {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        border-left: 4px solid #1e40af;
        box-shadow: 0 4px 15px rgba(30, 64, 175, 0.1);
        margin-bottom: 1rem;
    }

    /* å¯¼èˆªæ­¥éª¤æ ·å¼ */
    .nav-container {
        background: linear-gradient(135deg, #1e40af 0%, #3b82f6 100%);
        border-radius: 12px;
        padding: 1.5rem;
        margin-bottom: 1rem;
        color: white;
        box-shadow: 0 4px 20px rgba(30, 64, 175, 0.3);
    }

    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #1e40af 0%, #3b82f6 100%);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.6rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(30, 64, 175, 0.3);
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(30, 64, 175, 0.4);
    }

    /* é€‰æ‹©æ¡†æ ·å¼ */
    .stSelectbox label, .stMultiselect label, .stFileUploader label {
        font-weight: 600;
        color: #1e40af;
        margin-bottom: 0.5rem;
    }

    /* æ ‡é¢˜æ ·å¼ */
    h1, h2, h3, h4 {
        color: #1e40af;
        font-weight: 600;
        font-size: 1.2rem !important;
    }

    /* è¯´æ˜æ–‡å­—æ ·å¼ */
    .step-explanation {
        background: linear-gradient(135deg, rgba(30, 64, 175, 0.1) 0%, rgba(59, 130, 246, 0.1) 100%);
        border-left: 4px solid #1e40af;
        padding: 1.5rem;
        margin-top: 2rem;
        border-radius: 0 12px 12px 0;
    }

    .step-explanation h4 {
        color: #1e40af;
        margin-bottom: 0.8rem;
        font-size: 1.2rem;
        font-weight: 700;
    }

    .step-explanation ul {
        margin: 0.5rem 0;
        padding-left: 1.5rem;
        list-style-type: disc;
    }

    .step-explanation li {
        margin-bottom: 0.5rem;
        color: #1e40af;
        line-height: 1.6;
    }

    .step-explanation strong {
        color: #1e40af;
        font-weight: 600;
    }

    /* åŸç†è§£é‡Šæ¡†æ ·å¼ */
    .principle-box {
        background: rgba(59, 130, 246, 0.05);
        border: 1px solid rgba(59, 130, 246, 0.2);
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }

    .principle-title {
        color: #1e40af;
        font-weight: 600;
        font-size: 1rem;
        margin-bottom: 0.5rem;
    }

    .principle-content {
        color: #374151;
        font-size: 0.9rem;
        line-height: 1.5;
    }

    /* æç¤ºæ¡†æ ·å¼ */
    .step-tip {
        background: #eff6ff;
        border: 1px solid #bfdbfe;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        border-left: 4px solid #3b82f6;
    }

    .step-tip-title {
        color: #1e40af;
        font-weight: 600;
        font-size: 0.95rem;
        margin-bottom: 0.5rem;
    }

    .step-tip-content {
        color: #374151;
        font-size: 0.85rem;
        line-height: 1.4;
    }

    /* å‰”é™¤ä¿¡æ¯æ ·å¼ */
    .exclusion-info {
        background: #fef2f2;
        border: 1px solid #fecaca;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        border-left: 4px solid #ef4444;
    }

    .exclusion-info-title {
        color: #dc2626;
        font-weight: 600;
        font-size: 0.95rem;
        margin-bottom: 0.5rem;
    }

    .exclusion-info-content {
        color: #374151;
        font-size: 0.85rem;
        line-height: 1.4;
    }

    /* æ•°æ®æ¥æºæç¤ºæ ·å¼ */
    .data-source-info {
        background: #f0fdf4;
        border: 1px solid #bbf7d0;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        border-left: 4px solid #22c55e;
    }

    .data-source-info-title {
        color: #16a34a;
        font-weight: 600;
        font-size: 0.95rem;
        margin-bottom: 0.5rem;
    }

    .data-source-info-content {
        color: #374151;
        font-size: 0.85rem;
        line-height: 1.4;
    }

    /* éšè—é»˜è®¤çš„Streamlitå…ƒç´  */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ==================== é»˜è®¤é…ç½®æ•°æ® ====================
# é»˜è®¤æ¸ é“æ˜ å°„æ•°æ®
DEFAULT_CHANNEL_MAPPING = {
    '9000': 'æ€»ä½“',
    '500345': 'æ–°åª’ä½“', '500346': 'æ–°åª’ä½“', '500447': 'æ–°åª’ä½“', '500449': 'æ–°åª’ä½“',
    '500450': 'æ–°åª’ä½“', '500531': 'æ–°åª’ä½“', '500542': 'æ–°åª’ä½“',
    '5007XS': 'åº”ç”¨å®', '500349': 'åº”ç”¨å®', '500350': 'åº”ç”¨å®',
    '500285': 'é¼ä¹-ç››ä¸–6', '500286': 'é¼ä¹-ç››ä¸–7',
    '5108': 'é…·æ´¾', '5528': 'é…·æ´¾',
    '500275': 'æ–°ç¾-åŒ—äº¬2', '500274': 'æ–°ç¾-åŒ—äº¬1',
    '500316': 'A_æ·±åœ³è›‹ä¸2',
    '500297': 'è£è€€', '5057': 'åä¸º', '5237': 'vivo', '5599': 'å°ç±³', '5115': 'OPPO',
    '500471': 'ç½‘æ˜“', '500480': 'ç½‘æ˜“', '500481': 'ç½‘æ˜“', '500482': 'ç½‘æ˜“',
    '500337': 'åä¸ºéå•†åº—-å“ä¼—', '500338': 'åä¸ºéå•†åº—-å“ä¼—', '500343': 'åä¸ºéå•†åº—-å“ä¼—', 
    '500445': 'åä¸ºéå•†åº—-å“ä¼—', '500383': 'åä¸ºéå•†åº—-å“ä¼—', '500444': 'åä¸ºéå•†åº—-å“ä¼—', '500441': 'åä¸ºéå•†åº—-å“ä¼—',
    '5072': 'é­…æ—',
    '500287': 'OPPOéå•†åº—', '500288': 'OPPOéå•†åº—',
    '5187': 'vivoéå•†åº—',
    '500398': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£å®‰å“', '500400': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£å®‰å“', '500404': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£å®‰å“',
    '500402': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£ios', '500403': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£ios', '500405': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£ios',
    '500377': 'ç™¾é’è—¤-å®‰å“', '500379': 'ç™¾é’è—¤-å®‰å“', '500435': 'ç™¾é’è—¤-å®‰å“', '500436': 'ç™¾é’è—¤-å®‰å“', 
    '500490': 'ç™¾é’è—¤-å®‰å“', '500491': 'ç™¾é’è—¤-å®‰å“', '500434': 'ç™¾é’è—¤-å®‰å“', '500492': 'ç™¾é’è—¤-å®‰å“',
    '500437': 'ç™¾é’è—¤-ios',
    '500170': 'å°ç±³éå•†åº—',
    '500532': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500533': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500534': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500537': 'åä¸ºéå•†åº—-æ˜Ÿç«',
    '500538': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500539': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500540': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500541': 'åä¸ºéå•†åº—-æ˜Ÿç«',
    '500504': 'å¾®åš-èœœæ©˜', '500505': 'å¾®åš-èœœæ©˜',
    '500367': 'å¾®åš-å¤®å¹¿', '500368': 'å¾®åš-å¤®å¹¿', '500369': 'å¾®åš-å¤®å¹¿',
    '500498': 'å¹¿ç‚¹é€š', '500497': 'å¹¿ç‚¹é€š', '500500': 'å¹¿ç‚¹é€š', 
    '500501': 'å¹¿ç‚¹é€š', '500496': 'å¹¿ç‚¹é€š', '500499': 'å¹¿ç‚¹é€š',
    '500514': 'ç½‘æ˜“æ˜“æ•ˆ', '500515': 'ç½‘æ˜“æ˜“æ•ˆ', '500516': 'ç½‘æ˜“æ˜“æ•ˆ'
}

# ==================== æ—¥æœŸå¤„ç†å‡½æ•° ====================
# è®¡ç®—é»˜è®¤ç›®æ ‡æœˆä»½ï¼ˆ2ä¸ªæœˆå‰ï¼‰
def get_default_target_month():
    today = datetime.datetime.now()
    if today.month <= 2:
        target_year = today.year - 1
        target_month = today.month + 10
    else:
        target_year = today.year
        target_month = today.month - 2
    return f"{target_year}-{target_month:02d}"

# ==================== æ•°æ®ç±»å‹è½¬æ¢å‡½æ•° ====================
def safe_convert_to_numeric(value):
    """
    å®‰å…¨åœ°å°†å€¼è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
    """
    if pd.isna(value) or value == '' or value is None:
        return 0
    try:
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå…ˆå»é™¤ç©ºæ ¼
        if isinstance(value, str):
            value = value.strip()
            if value == '' or value.lower() in ['nan', 'null', 'none']:
                return 0
        return pd.to_numeric(value, errors='coerce')
    except:
        return 0

# ==================== æ•°æ®ç»“æ„æ ‡å‡†åŒ–å‡½æ•° ====================
def standardize_output_columns(df):
    """
    æ ‡å‡†åŒ–è¾“å‡ºåˆ—ç»“æ„ï¼Œç¡®ä¿åŒ…å«æŒ‡å®šçš„åˆ—é¡ºåºï¼Œå¹¶æ­£ç¡®å¤„ç†æ•°æ®ç±»å‹
    """
    print("æ­£åœ¨æ ‡å‡†åŒ–è¾“å‡ºåˆ—ç»“æ„...")

    # å®šä¹‰ç›®æ ‡åˆ—é¡ºåº
    target_columns = [
        'æ•°æ®æ¥æº', 'date', 'æ•°æ®æ¥æº_date',
        '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',
        '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',
        '21', '22', '23', '24', '25', '26', '27', '28', '29', '30',
        'æ•°æ®æ¥æº_æ—¥æœŸ', 'æ—¥æœŸ', 'å›ä¼ æ–°å¢æ•°', 'is_target_month', 'month', 'stat_date'
    ]

    # æŒ‰ç›®æ ‡åˆ—é¡ºåºåˆ›å»ºç»“æœDataFrame
    result_df = pd.DataFrame()

    # æŒ‰ç²¾ç¡®é¡ºåºæ·»åŠ æ¯ä¸€åˆ—
    for col_name in target_columns:
        if col_name == 'æ•°æ®æ¥æº':
            result_df[col_name] = df[col_name].astype(str) if col_name in df.columns else ''
        elif col_name == 'date':
            if col_name in df.columns:
                result_df[col_name] = df[col_name].astype(str)
            elif 'stat_date' in df.columns:
                result_df[col_name] = df['stat_date'].astype(str)
            else:
                result_df[col_name] = ''
        elif col_name == 'æ•°æ®æ¥æº_date':
            # åˆ›å»ºæ•°æ®æ¥æº_dateåˆ—
            data_source = df['æ•°æ®æ¥æº'].astype(str) if 'æ•°æ®æ¥æº' in df.columns else pd.Series([''] * len(df))
            
            if 'date' in df.columns:
                date_col_str = df['date'].astype(str)
            elif 'stat_date' in df.columns:
                date_col_str = df['stat_date'].astype(str)
            else:
                date_col_str = pd.Series([''] * len(df))

            result_df[col_name] = data_source + date_col_str
        elif col_name == 'æ•°æ®æ¥æº_æ—¥æœŸ':
            # åˆ›å»ºæ•°æ®æ¥æº_æ—¥æœŸåˆ—
            data_source = df['æ•°æ®æ¥æº'].astype(str) if 'æ•°æ®æ¥æº' in df.columns else pd.Series([''] * len(df))

            if 'æ—¥æœŸ' in df.columns:
                date_col_str = df['æ—¥æœŸ'].astype(str)
            elif 'date' in df.columns:
                date_col_str = df['date'].astype(str)
            elif 'stat_date' in df.columns:
                date_col_str = df['stat_date'].astype(str)
            else:
                date_col_str = pd.Series([''] * len(df))

            result_df[col_name] = data_source + date_col_str
        elif col_name in ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10',
                          '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',
                          '21', '22', '23', '24', '25', '26', '27', '28', '29', '30']:
            # æ•°å­—åˆ—ï¼šç¡®ä¿è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
            if col_name in df.columns:
                result_df[col_name] = df[col_name].apply(safe_convert_to_numeric)
            else:
                result_df[col_name] = 0
        elif col_name == 'å›ä¼ æ–°å¢æ•°':
            # å›ä¼ æ–°å¢æ•°åˆ—ï¼šç¡®ä¿è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
            if col_name in df.columns:
                result_df[col_name] = df[col_name].apply(safe_convert_to_numeric)
            else:
                result_df[col_name] = 0
        else:
            # å…¶ä»–åˆ—ç›´æ¥å¤åˆ¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å¡«ç©º
            if col_name in df.columns:
                result_df[col_name] = df[col_name]
            else:
                result_df[col_name] = ''

    # æ·»åŠ åŸæ•°æ®ä¸­å­˜åœ¨ä½†ä¸åœ¨ç›®æ ‡åˆ—è¡¨ä¸­çš„å…¶ä»–åˆ—ï¼ˆä¿æŒåœ¨æœ€åï¼‰
    for col in df.columns:
        if col not in target_columns:
            result_df[col] = df[col]

    print(f"å·²æ ‡å‡†åŒ–è¾“å‡ºåˆ—ç»“æ„ï¼Œå…± {len(result_df.columns)} åˆ—ï¼ŒæŒ‰æŒ‡å®šé¡ºåºæ’åˆ—")
    return result_df

# ==================== æ¸ é“æ˜ å°„å¤„ç†å‡½æ•° ====================
def parse_channel_mapping_from_excel(channel_file):
    """
    ä»ä¸Šä¼ çš„Excelæ–‡ä»¶è§£ææ¸ é“æ˜ å°„
    """
    try:
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(channel_file)
        
        pid_to_channel = {}
        
        # éå†æ¯ä¸€è¡Œ
        for _, row in df.iterrows():
            # ç¬¬ä¸€åˆ—æ˜¯æ¸ é“åç§°
            channel_name = str(row.iloc[0]).strip()
            if pd.isna(channel_name) or channel_name == '' or channel_name == 'nan':
                continue
                
            # ä»ç¬¬äºŒåˆ—å¼€å§‹æ˜¯æ¸ é“å·
            for col_idx in range(1, len(row)):
                pid = row.iloc[col_idx]
                if pd.isna(pid) or str(pid).strip() in ['', 'nan', 'ã€€', ' ']:
                    continue
                pid_str = str(pid).strip()
                if pid_str:
                    pid_to_channel[pid_str] = channel_name
                    
        return pid_to_channel
    except Exception as e:
        st.error(f"è§£ææ¸ é“æ˜ å°„æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
        return {}

# ==================== æ–‡ä»¶æ•´åˆæ ¸å¿ƒå‡½æ•° ====================
def integrate_excel_files_streamlit(uploaded_files, target_month=None, channel_mapping=None):
    """
    æ•´åˆä¸Šä¼ çš„Excelæ–‡ä»¶ï¼Œæ”¯æŒæ–°æ ¼å¼è¡¨å’Œä¼ ç»Ÿæ ¼å¼è¡¨
    """
    if target_month is None:
        target_month = get_default_target_month()

    all_data = pd.DataFrame()
    processed_count = 0
    mapping_warnings = []

    for uploaded_file in uploaded_files:
        source_name = os.path.splitext(uploaded_file.name)[0]

        # æ¸ é“æ˜ å°„å¤„ç†
        if channel_mapping and source_name in channel_mapping:
            mapped_source = channel_mapping[source_name]
        else:
            mapped_source = source_name
            if channel_mapping:
                mapping_warnings.append(f"æ–‡ä»¶ '{source_name}' æœªåœ¨æ¸ é“æ˜ å°„è¡¨ä¸­æ‰¾åˆ°å¯¹åº”é¡¹")

        try:
            # è¯»å–Excelæ–‡ä»¶
            xls = pd.ExcelFile(uploaded_file)
            sheet_names = xls.sheet_names

            # æŸ¥æ‰¾ç›®æ ‡å·¥ä½œè¡¨
            ocpx_sheet = None
            for sheet in sheet_names:
                if "ocpxç›‘æµ‹ç•™å­˜æ•°" in sheet:
                    ocpx_sheet = sheet
                    break

            if ocpx_sheet:
                file_data = pd.read_excel(uploaded_file, sheet_name=ocpx_sheet)
            else:
                file_data = pd.read_excel(uploaded_file, sheet_name=0)

            if file_data is not None and not file_data.empty:
                file_data_copy = file_data.copy()

                # ========== æ£€æµ‹æ–‡ä»¶æ ¼å¼ç±»å‹ ==========
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ ¼å¼è¡¨ï¼ˆåŒ…å«stat_dateå’Œç•™å­˜åˆ—ï¼‰
                is_new_format = False
                has_stat_date = 'stat_date' in file_data_copy.columns
                retain_columns = [f'new_retain_{i}' for i in range(1, 31)]
                has_retain_columns = any(col in file_data_copy.columns for col in retain_columns)

                # ========== å¤„ç†æ–°æ ¼å¼è¡¨ ==========
                if has_stat_date and has_retain_columns:
                    is_new_format = True
                    print(f"æ£€æµ‹åˆ° {uploaded_file.name} æ˜¯æ–°æ ¼å¼è¡¨ï¼ˆå«stat_dateå’Œç•™å­˜åˆ—ï¼‰")

                    # åˆ›å»ºæ ‡å‡†çš„è¾“å‡ºç»“æ„
                    standardized_data = file_data_copy.copy()

                    # å°†newåˆ—çš„å€¼æ˜ å°„åˆ°"å›ä¼ æ–°å¢æ•°"åˆ—ï¼Œç¡®ä¿æ˜¯æ•°å€¼ç±»å‹
                    if 'new' in standardized_data.columns:
                        standardized_data['å›ä¼ æ–°å¢æ•°'] = standardized_data['new'].apply(safe_convert_to_numeric)

                    # å°†new_retain_1åˆ°new_retain_30çš„å€¼åˆ†åˆ«æ˜ å°„åˆ°æ•°å­—åˆ—å(1åˆ°30)ï¼Œç¡®ä¿æ˜¯æ•°å€¼ç±»å‹
                    for i in range(1, 31):
                        retain_col = f'new_retain_{i}'
                        if retain_col in standardized_data.columns:
                            standardized_data[str(i)] = standardized_data[retain_col].apply(safe_convert_to_numeric)

                    # ç¡®ä¿stat_dateè¢«è§†ä¸ºæ—¥æœŸåˆ—
                    date_col = 'stat_date'
                    standardized_data[date_col] = pd.to_datetime(standardized_data[date_col], errors='coerce')
                    # å°†æ—¥æœŸè½¬ä¸ºå­—ç¬¦ä¸²æ ¼å¼
                    standardized_data[date_col] = standardized_data[date_col].dt.strftime('%Y-%m-%d')
                    # æ·»åŠ "æ—¥æœŸ"åˆ—ï¼Œä¸stat_dateç›¸åŒ
                    standardized_data['æ—¥æœŸ'] = standardized_data[date_col]
                    # æ·»åŠ æœˆä»½åˆ—
                    standardized_data['month'] = standardized_data[date_col].str[:7]

                    # ç­›é€‰ç›®æ ‡æœˆä»½çš„æ•°æ®
                    filtered_data = standardized_data[standardized_data['month'] == target_month].copy()

                    # å¦‚æœå­˜åœ¨ç•™å­˜å¤©æ•°åˆ—ï¼Œè¿˜è¦ä¿ç•™ç‰¹æ®Šè¡Œ
                    retention_col = None
                    for col in standardized_data.columns:
                        if 'ç•™å­˜å¤©æ•°' in str(col):
                            retention_col = col
                            break

                    if retention_col is not None:
                        # æ‰¾å‡ºç•™å­˜å¤©æ•°ä¸ºç‰¹å®šå€¼çš„è¡Œ
                        special_rows = standardized_data[(standardized_data[retention_col] == "2025-02-01") |
                                                         (standardized_data[retention_col] == "åˆè®¡") |
                                                         (standardized_data[retention_col].astype(
                                                             str) == "2025-02-01") |
                                                         (standardized_data[retention_col].astype(str) == "åˆè®¡")]

                        # åˆå¹¶æ•°æ®æ¡†ï¼šç›®æ ‡æœˆä»½çš„æ•°æ®å’Œç‰¹æ®Šè¡Œ
                        if not special_rows.empty:
                            filtered_data = pd.concat([filtered_data, special_rows]).drop_duplicates()

                    if not filtered_data.empty:
                        # æ·»åŠ æ•°æ®æ¥æºåˆ—
                        filtered_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)

                        # å¤„ç†dateåˆ—
                        if retention_col is not None:
                            filtered_data.rename(columns={retention_col: 'date'}, inplace=True)
                        elif 'stat_date' in filtered_data.columns:
                            filtered_data['date'] = filtered_data['stat_date']

                        # å°†ç­›é€‰åçš„æ•°æ®æ·»åŠ åˆ°æ€»æ•°æ®æ¡†
                        all_data = pd.concat([all_data, filtered_data], ignore_index=True)
                        processed_count += 1

                # ========== å¤„ç†ä¼ ç»Ÿæ ¼å¼è¡¨ ==========
                else:
                    # æŸ¥æ‰¾ç•™å­˜å¤©æ•°åˆ—
                    retention_col = None
                    for col in file_data_copy.columns:
                        if 'ç•™å­˜å¤©æ•°' in str(col):
                            retention_col = col
                            break

                    # æŸ¥æ‰¾å›ä¼ æ–°å¢æ•°åˆ—æˆ–total_new_usersåˆ—
                    report_users_col = None
                    for col in file_data_copy.columns:
                        if 'å›ä¼ æ–°å¢æ•°' in str(col):
                            report_users_col = col
                            break
                        if 'total_new_users' in str(col).lower():
                            report_users_col = col
                            break

                    # è·å–ç¬¬äºŒåˆ—ä½œä¸ºå¤‡é€‰
                    column_b = file_data_copy.columns[1] if len(file_data_copy.columns) > 1 else None

                    # æ£€æŸ¥æ˜¯å¦æœ‰æ—¥æœŸåˆ—
                    date_col = None
                    for col in file_data_copy.columns:
                        if 'æ—¥æœŸ' in str(col):
                            date_col = col
                            break

                    # ========== å¤„ç†å›ä¼ æ–°å¢æ•°åˆ—æ˜ å°„ ==========
                    if report_users_col and report_users_col != 'å›ä¼ æ–°å¢æ•°':
                        file_data_copy['å›ä¼ æ–°å¢æ•°'] = file_data_copy[report_users_col].apply(safe_convert_to_numeric)
                    elif not report_users_col and column_b:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³åˆ—ï¼Œä½¿ç”¨ç¬¬äºŒåˆ—ä½œä¸º"å›ä¼ æ–°å¢æ•°"
                        file_data_copy['å›ä¼ æ–°å¢æ•°'] = file_data_copy[column_b].apply(safe_convert_to_numeric)

                    # ========== å¤„ç†æ•°å­—åˆ—ï¼ˆ1-30å¤©ç•™å­˜æ•°æ®ï¼‰==========
                    for i in range(1, 31):
                        col_name = str(i)
                        if col_name in file_data_copy.columns:
                            file_data_copy[col_name] = file_data_copy[col_name].apply(safe_convert_to_numeric)

                    # ========== å¤„ç†æ—¥æœŸåˆ—æ•°æ®å’Œç­›é€‰ ==========
                    if date_col:
                        # å°†æ—¥æœŸåˆ—è½¬æ¢ä¸ºæ—¥æœŸç±»å‹ä»¥ä¾¿è®¡ç®—å‰åèŒƒå›´
                        try:
                            if not pd.api.types.is_datetime64_dtype(file_data_copy[date_col]):
                                temp_dates = pd.to_datetime(file_data_copy[date_col], errors='coerce')
                                file_data_copy[date_col] = temp_dates

                            # æå–ç›®æ ‡æœˆä»½çš„ç¬¬ä¸€å¤©å’Œæœ€åä¸€å¤©
                            target_year, target_month_num = map(int, target_month.split('-'))
                            first_day_of_month = pd.Timestamp(year=target_year, month=target_month_num, day=1)

                            # è®¡ç®—ä¸‹ä¸€ä¸ªæœˆçš„ç¬¬ä¸€å¤©
                            if target_month_num == 12:
                                next_month = pd.Timestamp(year=target_year + 1, month=1, day=1)
                            else:
                                next_month = pd.Timestamp(year=target_year, month=target_month_num + 1, day=1)

                            # æœ€åä¸€å¤©æ˜¯ä¸‹ä¸€ä¸ªæœˆçš„ç¬¬ä¸€å¤©å‡ä¸€å¤©
                            last_day_of_month = next_month - pd.Timedelta(days=1)

                            # è®¡ç®—ç›®æ ‡èŒƒå›´ï¼ˆæœˆä»½å‰å5å¤©ï¼‰
                            start_date = first_day_of_month - pd.Timedelta(days=5)
                            end_date = last_day_of_month + pd.Timedelta(days=5)

                            # ç­›é€‰æ—¥æœŸåœ¨èŒƒå›´å†…çš„æ•°æ®
                            mask = (file_data_copy[date_col] >= start_date) & (file_data_copy[date_col] <= end_date)

                            # å¦‚æœå­˜åœ¨ç•™å­˜å¤©æ•°åˆ—ï¼Œè¿˜è¦ä¿ç•™ç‰¹æ®Šå€¼çš„è¡Œ
                            if retention_col is not None:
                                # ç”ŸæˆæŒ‡å®šæœˆä»½çš„æ‰€æœ‰æ—¥æœŸå€¼çš„åˆ—è¡¨
                                all_month_dates = []
                                current_date = first_day_of_month
                                while current_date <= last_day_of_month:
                                    date_str = current_date.strftime('%Y-%m-%d')
                                    all_month_dates.append(date_str)
                                    current_date += pd.Timedelta(days=1)

                                # æ·»åŠ "åˆè®¡"ä½œä¸ºç‰¹æ®Šå€¼
                                all_month_dates.append("åˆè®¡")

                                # æ‰¾å‡ºç•™å­˜å¤©æ•°ä¸ºç‰¹å®šå€¼çš„è¡Œ
                                retention_col_str = file_data_copy[retention_col].astype(str)
                                special_rows_mask = np.zeros(len(file_data_copy), dtype=bool)

                                for date_val in all_month_dates:
                                    special_rows_mask = special_rows_mask | (retention_col_str == date_val)

                                # åˆå¹¶ç­›é€‰æ¡ä»¶ï¼šæ—¥æœŸåœ¨èŒƒå›´å†…ï¼Œæˆ–ç•™å­˜å¤©æ•°ä¸ºç‰¹å®šå€¼
                                mask = mask | special_rows_mask

                            filtered_data = file_data_copy[mask].copy()

                            # æ·»åŠ æ ‡è®°åˆ—å’Œæœˆä»½ä¿¡æ¯åˆ—
                            filtered_data['is_target_month'] = (filtered_data[date_col] >= first_day_of_month) & (
                                    filtered_data[date_col] <= last_day_of_month)
                            filtered_data['month'] = filtered_data[date_col].dt.strftime('%Y-%m')

                            # å°†æ—¥æœŸè½¬å›å­—ç¬¦ä¸²æ ¼å¼
                            filtered_data[date_col] = filtered_data[date_col].dt.strftime('%Y-%m-%d')

                            if not filtered_data.empty:
                                # æ·»åŠ æ•°æ®æ¥æºåˆ—
                                filtered_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)

                                # å°†"ç•™å­˜å¤©æ•°"åˆ—é‡å‘½åä¸º"date"
                                if retention_col is not None:
                                    filtered_data.rename(columns={retention_col: 'date'}, inplace=True)
                                elif date_col != 'date':
                                    filtered_data['date'] = filtered_data[date_col]

                                # å°†ç­›é€‰åçš„æ•°æ®æ·»åŠ åˆ°æ€»æ•°æ®æ¡†
                                all_data = pd.concat([all_data, filtered_data], ignore_index=True)
                                processed_count += 1

                        except Exception as e:
                            print(f"å¤„ç†æ—¥æœŸèŒƒå›´æ—¶å‡ºé”™: {str(e)}")
                            # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œé€€å›åˆ°ä»…ç­›é€‰æœˆä»½çš„æ–¹æ³•
                            file_data_copy['month'] = file_data_copy[date_col].apply(
                                lambda x: x[:7] if isinstance(x, str) else None
                            )

                            # ç­›é€‰ç›®æ ‡æœˆä»½çš„æ•°æ®
                            filtered_data = file_data_copy[file_data_copy['month'] == target_month].copy()

                            if 'month' in filtered_data.columns:
                                filtered_data.drop('month', axis=1, inplace=True)

                            if not filtered_data.empty:
                                # æ·»åŠ æ•°æ®æ¥æºåˆ—
                                filtered_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)

                                # å¤„ç†dateåˆ—
                                if retention_col is not None:
                                    filtered_data.rename(columns={retention_col: 'date'}, inplace=True)
                                elif date_col != 'date':
                                    filtered_data['date'] = filtered_data[date_col]

                                # å°†ç­›é€‰åçš„æ•°æ®æ·»åŠ åˆ°æ€»æ•°æ®æ¡†
                                all_data = pd.concat([all_data, filtered_data], ignore_index=True)
                                processed_count += 1

                    else:
                        # å¦‚æœæ²¡æœ‰æ—¥æœŸåˆ—ï¼Œä¿ç•™æ‰€æœ‰æ•°æ®
                        # æ·»åŠ æ•°æ®æ¥æºåˆ—
                        file_data_copy.insert(0, 'æ•°æ®æ¥æº', mapped_source)

                        # å°†"ç•™å­˜å¤©æ•°"åˆ—é‡å‘½åä¸º"date"ï¼Œå¦‚æœæœ‰çš„è¯
                        if retention_col is not None:
                            file_data_copy.rename(columns={retention_col: 'date'}, inplace=True)

                        # å°†æ‰€æœ‰æ•°æ®æ·»åŠ åˆ°æ€»æ•°æ®æ¡†
                        all_data = pd.concat([all_data, file_data_copy], ignore_index=True)
                        processed_count += 1

        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} æ—¶å‡ºé”™: {str(e)}")

    # ========== å¤„ç†åˆå¹¶åçš„æ•°æ® ==========
    if not all_data.empty:
        # æŸ¥æ‰¾dateåˆ—
        date_col = None
        for col in all_data.columns:
            if col == 'date':
                date_col = col
                break

        # ä¸ºæ–°æ ¼å¼è¡¨åˆ›å»ºdateåˆ—
        if date_col is None and 'stat_date' in all_data.columns:
            all_data['date'] = all_data['stat_date']
            date_col = 'date'

        # æ’åºå¤„ç†
        sort_columns = []
        if 'æ•°æ®æ¥æº' in all_data.columns:
            sort_columns.append('æ•°æ®æ¥æº')

        if date_col:
            try:
                all_data[date_col] = pd.to_datetime(all_data[date_col], errors='coerce')
                sort_columns.append(date_col)
            except:
                sort_columns.append(date_col)

        # æ‰§è¡Œæ’åº
        if sort_columns:
            all_data = all_data.sort_values(by=sort_columns)
            # å°†æ—¥æœŸåˆ—è½¬å›å­—ç¬¦ä¸²æ ¼å¼
            if date_col and pd.api.types.is_datetime64_dtype(all_data[date_col]):
                all_data[date_col] = all_data[date_col].dt.strftime('%Y-%m-%d')

        # æ ‡å‡†åŒ–è¾“å‡ºåˆ—ç»“æ„
        standardized_df = standardize_output_columns(all_data)
        return standardized_df, processed_count, mapping_warnings
    else:
        return None, 0, mapping_warnings

# ==================== æ•°å­¦å»ºæ¨¡å‡½æ•°ï¼ˆå‚è€ƒç¬¬äºŒæ®µä»£ç ï¼‰====================
# å®šä¹‰æ•°å­¦å‡½æ•°
def power_function(x, a, b):
    """å¹‚å‡½æ•°ï¼šy = a * x^b"""
    return a * np.power(x, b)

def exponential_function(x, c, d):
    """æŒ‡æ•°å‡½æ•°ï¼šy = c * exp(d * x)"""
    return c * np.exp(d * x)

# ==================== ç•™å­˜ç‡è®¡ç®—å‡½æ•° ====================
# ç•™å­˜ç‡è®¡ç®—
def calculate_retention_rates_advanced(df):
    retention_results = []
    data_sources = df['æ•°æ®æ¥æº'].unique()

    for source in data_sources:
        source_data = df[df['æ•°æ®æ¥æº'] == source].copy()
        all_days = []
        all_rates = []

        for _, row in source_data.iterrows():
            new_users = safe_convert_to_numeric(row.get('å›ä¼ æ–°å¢æ•°', 0))
            if pd.isna(new_users) or new_users <= 0:
                continue

            for day in range(1, 31):
                day_col = str(day)
                if day_col in row and not pd.isna(row[day_col]):
                    retain_count = safe_convert_to_numeric(row[day_col])
                    if retain_count > 0:
                        retention_rate = retain_count / new_users
                        if 0 < retention_rate <= 1.5:
                            all_days.append(day)
                            all_rates.append(retention_rate)

        if all_days:
            df_temp = pd.DataFrame({'day': all_days, 'rate': all_rates})
            df_avg = df_temp.groupby('day')['rate'].mean().reset_index()

            retention_data = {
                'data_source': source,
                'days': df_avg['day'].values,
                'rates': df_avg['rate'].values
            }
            retention_results.append(retention_data)

    return retention_results

# ==================== è®¡ç®—æŒ‡å®šå¤©æ•°çš„ç´¯ç§¯LTå€¼å‡½æ•°ï¼ˆå‚è€ƒç¬¬äºŒæ®µä»£ç ï¼‰====================
def calculate_cumulative_lt(days_array, rates_array, target_days):
    """è®¡ç®—æŒ‡å®šå¤©æ•°çš„ç´¯ç§¯LTå€¼"""
    result = {}
    for day in target_days:
        idx = np.searchsorted(days_array, day, side='right')
        if idx > 0:
            # è®¡ç®—åˆ°æŒ‡å®šå¤©æ•°çš„ç´¯ç§¯LTå€¼ï¼ˆåŒ…æ‹¬ç¬¬0å¤©çš„1.0ï¼‰
            cumulative_lt = 1.0 + np.sum(rates_array[1:idx])
            result[day] = cumulative_lt
    return result

# ==================== LTæ‹Ÿåˆåˆ†æå‡½æ•° - å®Œå…¨å‚è€ƒç¬¬äºŒæ®µä»£ç é€»è¾‘ ====================
def calculate_lt_advanced(retention_result, channel_name, lt_years=5, return_curve_data=False, key_days=None):
    """
    æŒ‰æ¸ é“è§„åˆ™è®¡ç®— LTï¼Œå…è®¸ 1-30 å¤©æ•°æ®ä¸è¿ç»­ã€‚
    å®Œå…¨å‚è€ƒç¬¬äºŒæ®µä»£ç é€»è¾‘
    """
    # æ¸ é“è§„åˆ™ - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´
    CHANNEL_RULES = {
        "åä¸º": {"stage_2": [30, 120], "stage_3_base": [120, 220]},
        "å°ç±³": {"stage_2": [30, 190], "stage_3_base": [190, 290]},
        "oppo": {"stage_2": [30, 160], "stage_3_base": [160, 260]},
        "vivo": {"stage_2": [30, 150], "stage_3_base": [150, 250]},
        "iphone": {"stage_2": [30, 150], "stage_3_base": [150, 250], "stage_2_func": "log"},
        "å…¶ä»–": {"stage_2": [30, 100], "stage_3_base": [100, 200]}
    }

    # æ¸ é“è§„åˆ™åŒ¹é… - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´
    if re.search(r'\d+æœˆåä¸º$', channel_name):
        rules = CHANNEL_RULES["åä¸º"]
    elif re.search(r'\d+æœˆå°ç±³$', channel_name):
        rules = CHANNEL_RULES["å°ç±³"]
    elif re.search(r'\d+æœˆoppo$', channel_name) or re.search(r'\d+æœˆOPPO$', channel_name):
        rules = CHANNEL_RULES["oppo"]
    elif re.search(r'\d+æœˆvivo$', channel_name):
        rules = CHANNEL_RULES["vivo"]
    elif re.search(r'\d+æœˆ[iI][pP]hone$', channel_name):
        rules = CHANNEL_RULES["iphone"]
    else:
        rules = CHANNEL_RULES["å…¶ä»–"]
        
    stage_2_start, stage_2_end = rules["stage_2"]
    stage_3_base_start, stage_3_base_end = rules["stage_3_base"]

    # è®¡ç®—æœ€å¤§å¤©æ•°ï¼ˆæ ¹æ®æŒ‡å®šå¹´æ•°ï¼‰
    max_days = lt_years * 365

    days = retention_result["days"]
    rates = retention_result["rates"]

    # å­˜å‚¨æ‹Ÿåˆå‚æ•°ï¼Œç”¨äºåç»­åˆ†æ
    fit_params = {}

    # ----- ç¬¬ä¸€é˜¶æ®µ - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´ -----
    try:
        # ç”¨å·²æœ‰æ•°æ®å¯¹ 1-30 å¤©çš„ç•™å­˜ç‡è¿›è¡Œæ‹Ÿåˆ
        popt_power, _ = curve_fit(power_function, days, rates)
        a, b = popt_power
        fit_params["power"] = {"a": a, "b": b}

        # ç”¨æ‹Ÿåˆå‡½æ•°ç”Ÿæˆå®Œæ•´çš„ 1-30 å¤©ç•™å­˜ç‡
        days_full = np.arange(1, 31)  # è¿ç»­çš„ 1-30 å¤©
        rates_full = power_function(days_full, a, b)

        # ç¬¬ä¸€é˜¶æ®µçš„ LT ç´¯åŠ å€¼
        lt1_to_30 = np.sum(rates_full)
    except Exception as e:
        lt1_to_30 = 0.0
        a, b = 1.0, -1.0  # é»˜è®¤å‚æ•°

    # ----- ç¬¬äºŒé˜¶æ®µ - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´ -----
    try:
        days_stage_2 = np.arange(stage_2_start, stage_2_end + 1)
        rates_stage_2 = power_function(days_stage_2, a, b)
        lt_stage_2 = np.sum(rates_stage_2)
    except Exception as e:
        lt_stage_2 = 0.0
        rates_stage_2 = np.array([])

    # ----- ç¬¬ä¸‰é˜¶æ®µ - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´ -----
    try:
        days_stage_3_base = np.arange(stage_3_base_start, stage_3_base_end + 1)
        rates_stage_3_base = power_function(days_stage_3_base, a, b)

        # æŒ‡æ•°æ‹Ÿåˆ
        initial_c = rates_stage_3_base[0]
        initial_d = -0.001
        popt_exp, _ = curve_fit(
            exponential_function,
            days_stage_3_base,
            rates_stage_3_base,
            p0=[initial_c, initial_d],
            bounds=([0, -np.inf], [np.inf, 0])  # é™åˆ¶ d < 0
        )
        c, d = popt_exp
        fit_params["exponential"] = {"c": c, "d": d}
        days_stage_3 = np.arange(stage_3_base_start, max_days + 1)  # ä½¿ç”¨å¯å˜çš„æœ€å¤§å¤©æ•°
        rates_stage_3 = exponential_function(days_stage_3, c, d)
        lt_stage_3 = np.sum(rates_stage_3)
    except Exception as e:
        days_stage_3 = np.arange(stage_3_base_start, max_days + 1)  # ä½¿ç”¨å¯å˜çš„æœ€å¤§å¤©æ•°
        rates_stage_3 = power_function(days_stage_3, a, b) if 'a' in locals() else np.zeros(len(days_stage_3))
        lt_stage_3 = np.sum(rates_stage_3)

    # ----- æ€» LT è®¡ç®— - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´ -----
    total_lt = 1.0 + lt1_to_30 + lt_stage_2 + lt_stage_3

    # è®¡ç®—RÂ²ç”¨äºè¯„ä¼°æ‹Ÿåˆè´¨é‡
    try:
        predicted_rates = power_function(days, a, b)
        r2_score = 1 - np.sum((rates - predicted_rates) ** 2) / np.sum((rates - np.mean(rates)) ** 2)
    except:
        r2_score = 0.0

    if return_curve_data:
        # è¿”å›ä¸åŒ…å«ç¬¬0å¤©çš„æ›²çº¿æ•°æ®ç”¨äºå¯è§†åŒ– - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´
        all_days = np.concatenate([
            days_full,      # ç¬¬1-30å¤©
            days_stage_2,   # ç¬¬äºŒé˜¶æ®µ
            days_stage_3    # ç¬¬ä¸‰é˜¶æ®µ
        ])
        
        if 'rates_stage_2' not in locals():
            rates_stage_2 = power_function(days_stage_2, a, b)
        
        all_rates = np.concatenate([
            rates_full,                # ç¬¬1-30å¤©
            rates_stage_2,             # ç¬¬äºŒé˜¶æ®µ
            rates_stage_3              # ç¬¬ä¸‰é˜¶æ®µ
        ])

        # æŒ‰å¤©æ•°æ’åº
        sort_idx = np.argsort(all_days)
        all_days = all_days[sort_idx]
        all_rates = all_rates[sort_idx]

        # åªè¿”å›åˆ°æŒ‡å®šå¹´æ•°çš„æ•°æ®
        max_idx = np.searchsorted(all_days, lt_years * 365, side='right')
        all_days = all_days[:max_idx]
        all_rates = all_rates[:max_idx]

        # è®¡ç®—å…³é”®æ—¶é—´ç‚¹çš„ç´¯ç§¯LTå€¼
        key_days_lt = {}
        if key_days:
            key_days_lt = calculate_cumulative_lt(all_days, all_rates, key_days)

        return {
            'lt_value': total_lt,
            'fit_params': fit_params,
            'power_r2': max(0, min(1, r2_score)),
            'success': True,
            'model_used': 'power+exponential',
            'curve_days': all_days,
            'curve_rates': all_rates,
            'key_days_lt': key_days_lt
        }

    return total_lt

# ==================== é«˜è´¨é‡å¯è§†åŒ–å‡½æ•°ï¼ˆå‚è€ƒç¬¬äºŒæ®µä»£ç é£æ ¼ï¼‰====================
def create_professional_charts(visualization_data_2y, visualization_data_5y, original_data):
    """
    åˆ›å»ºä¸“ä¸šçš„å¯è§†åŒ–å›¾è¡¨ï¼Œå‚è€ƒç¬¬äºŒæ®µä»£ç é£æ ¼
    """
    # ç¡®ä¿ä¸­æ–‡å­—ä½“è®¾ç½® - ä½¿ç”¨ç¬¬äºŒæ®µä»£ç çš„æ–¹å¼
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False
    
    # é¢œè‰²é…ç½® - ä½¿ç”¨ç¬¬äºŒæ®µä»£ç çš„é…è‰²
    colors = plt.cm.tab10.colors
    
    # æŒ‰LTå€¼ä»ä½åˆ°é«˜æ’åºæ¸ é“ - å‚è€ƒç¬¬äºŒæ®µä»£ç 
    sorted_channels = sorted(visualization_data_2y.items(), key=lambda x: x[1]['lt'])
    
    chart_figures = []
    
    # ========== åˆ›å»ºå•æ¸ é“å›¾è¡¨ (å‚è€ƒç¬¬äºŒæ®µä»£ç çš„visualize_fitting_comparisonå‡½æ•°é£æ ¼) ==========
    for idx, (channel_name, data_2y) in enumerate(sorted_channels):
        if channel_name not in visualization_data_5y:
            continue
            
        data_5y = visualization_data_5y[channel_name]
        color = colors[idx % len(colors)]
        
        # åˆ›å»º100å¤©å›¾è¡¨
        fig_100d = plt.figure(figsize=(6, 4))
        ax = fig_100d.add_subplot(111)
        
        # ç»˜åˆ¶å®é™…æ•°æ®ç‚¹
        if channel_name in original_data:
            ax.scatter(
                original_data[channel_name]["days"],
                original_data[channel_name]["rates"],
                color='red',
                s=50,
                alpha=0.7,
                label='å®é™…æ•°æ®',
                zorder=3
            )
        
        # ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿ï¼ˆåªæ˜¾ç¤º100å¤©å†…çš„æ•°æ®ï¼‰
        days_100 = data_2y["days"][data_2y["days"] <= 100]
        rates_100 = data_2y["rates"][:len(days_100)]
        
        ax.plot(
            days_100,
            rates_100,
            color='blue',
            linewidth=2,
            label='æ‹Ÿåˆæ›²çº¿',
            zorder=2
        )
        
        # è®¾ç½®å›¾è¡¨æ ·å¼ - å‚è€ƒç¬¬äºŒæ®µä»£ç 
        ax.set_xlim(0, 100)
        ax.set_ylim(0, 0.6)
        ax.set_xlabel('ç•™å­˜å¤©æ•°', fontsize=10)
        ax.set_ylabel('ç•™å­˜ç‡', fontsize=10)
        ax.set_title(f'{channel_name} (LT={data_2y["lt"]:.2f})', fontsize=11, fontweight='bold')
        ax.grid(True, linestyle='--', alpha=0.3)
        ax.legend(fontsize=8)
        
        # è®¾ç½®Yè½´åˆ»åº¦ä¸ºç™¾åˆ†æ¯” - å‚è€ƒç¬¬äºŒæ®µä»£ç 
        y_ticks = [0, 0.15, 0.3, 0.45, 0.6]
        y_labels = ['0%', '15%', '30%', '45%', '60%']
        ax.set_yticks(y_ticks)
        ax.set_yticklabels(y_labels)
        
        plt.tight_layout()
        
        chart_figures.append({
            'channel': channel_name,
            'fig_100d': fig_100d,
            'lt_value': data_2y["lt"]
        })
    
    # ========== åˆ›å»ºç»¼åˆå¯¹æ¯”å›¾è¡¨ (å‚è€ƒç¬¬äºŒæ®µä»£ç çš„visualize_lt_curveså‡½æ•°é£æ ¼) ==========
    # 2å¹´ç»¼åˆå›¾è¡¨
    fig_2y_combined = plt.figure(figsize=(14, 8))
    ax_2y = fig_2y_combined.add_subplot(111)
    
    for idx, (channel_name, data) in enumerate(sorted_channels):
        if channel_name not in visualization_data_2y:
            continue
            
        color = colors[idx % len(colors)]
        data_2y = visualization_data_2y[channel_name]
        
        # ç»˜åˆ¶2å¹´æ‹Ÿåˆæ›²çº¿
        ax_2y.plot(
            data_2y["days"],
            data_2y["rates"],
            color=color,
            linewidth=2,
            label=f'{channel_name} (LT={data_2y["lt"]:.2f})'
        )
    
    # è®¾ç½®å›¾è¡¨æ ·å¼ - å‚è€ƒç¬¬äºŒæ®µä»£ç 
    ax_2y.set_xlim(0, 730)  # 2å¹´
    ax_2y.set_ylim(0, 0.6)
    ax_2y.set_xlabel('ç•™å­˜å¤©æ•°', fontsize=12)
    ax_2y.set_ylabel('ç•™å­˜ç‡', fontsize=12)
    ax_2y.set_title('å„æ¸ é“2å¹´LTç•™å­˜æ›²çº¿æ‹Ÿåˆå¯¹æ¯” (æŒ‰LTå€¼ä»ä½åˆ°é«˜æ’åº)', fontsize=14, fontweight='bold')
    ax_2y.grid(True, linestyle='--', alpha=0.5)
    
    # è®¾ç½®Yè½´åˆ»åº¦ä¸ºç™¾åˆ†æ¯” - å‚è€ƒç¬¬äºŒæ®µä»£ç 
    y_ticks = [0, 0.15, 0.3, 0.45, 0.6]
    y_labels = ['0%', '15%', '30%', '45%', '60%']
    ax_2y.set_yticks(y_ticks)
    ax_2y.set_yticklabels(y_labels)
    
    # è®¾ç½®å›¾ä¾‹
    ax_2y.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
    plt.tight_layout()
    
    # 5å¹´ç»¼åˆå›¾è¡¨
    fig_5y_combined = plt.figure(figsize=(14, 8))
    ax_5y = fig_5y_combined.add_subplot(111)
    
    for idx, (channel_name, data) in enumerate(sorted_channels):
        if channel_name not in visualization_data_5y:
            continue
            
        color = colors[idx % len(colors)]
        data_5y = visualization_data_5y[channel_name]
        
        # ç»˜åˆ¶5å¹´æ‹Ÿåˆæ›²çº¿
        ax_5y.plot(
            data_5y["days"],
            data_5y["rates"],
            color=color,
            linewidth=2,
            label=f'{channel_name} (LT={data_5y["lt"]:.2f})'
        )
    
    # è®¾ç½®å›¾è¡¨æ ·å¼ - å‚è€ƒç¬¬äºŒæ®µä»£ç 
    ax_5y.set_xlim(0, 1825)  # 5å¹´
    ax_5y.set_ylim(0, 0.6)
    ax_5y.set_xlabel('ç•™å­˜å¤©æ•°', fontsize=12)
    ax_5y.set_ylabel('ç•™å­˜ç‡', fontsize=12)
    ax_5y.set_title('å„æ¸ é“5å¹´LTç•™å­˜æ›²çº¿æ‹Ÿåˆå¯¹æ¯” (æŒ‰LTå€¼ä»ä½åˆ°é«˜æ’åº)', fontsize=14, fontweight='bold')
    ax_5y.grid(True, linestyle='--', alpha=0.5)
    
    # è®¾ç½®Yè½´åˆ»åº¦ä¸ºç™¾åˆ†æ¯”
    ax_5y.set_yticks(y_ticks)
    ax_5y.set_yticklabels(y_labels)
    
    # è®¾ç½®å›¾ä¾‹
    ax_5y.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
    plt.tight_layout()
    
    return chart_figures, fig_2y_combined, fig_5y_combined

# ==================== é¡µé¢åˆå§‹åŒ– ====================
# ä¸»æ ‡é¢˜
st.markdown("""
<div class="main-header">
    <div class="main-title">ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†æç³»ç»Ÿ</div>
    <div class="main-subtitle">åŸºäºåˆ†é˜¶æ®µæ•°å­¦å»ºæ¨¡çš„LTVé¢„æµ‹</div>
</div>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
session_keys = [
    'channel_mapping', 'merged_data', 'cleaned_data', 'retention_data',
    'lt_results', 'arpu_data', 'ltv_results', 'current_step', 'excluded_data',
    'excluded_dates_info'  # æ–°å¢ï¼šè®°å½•å…·ä½“å‰”é™¤çš„æ—¥æœŸä¿¡æ¯
]
for key in session_keys:
    if key not in st.session_state:
        st.session_state[key] = None

# è®¾ç½®é»˜è®¤å€¼
if st.session_state.channel_mapping is None:
    st.session_state.channel_mapping = DEFAULT_CHANNEL_MAPPING
if st.session_state.current_step is None:
    st.session_state.current_step = 0
if st.session_state.excluded_data is None:
    st.session_state.excluded_data = []
if st.session_state.excluded_dates_info is None:
    st.session_state.excluded_dates_info = []

# ==================== åˆ†ææ­¥éª¤å®šä¹‰ ====================
# åˆ†ææ­¥éª¤å®šä¹‰
ANALYSIS_STEPS = [
    {"name": "æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»"},
    {"name": "å¼‚å¸¸æ•°æ®å‰”é™¤"},
    {"name": "ç•™å­˜ç‡è®¡ç®—"},
    {"name": "LTæ‹Ÿåˆåˆ†æ"},
    {"name": "ARPUè®¡ç®—"},
    {"name": "LTVç»“æœæŠ¥å‘Š"}
]

# ==================== æ­¥éª¤çŠ¶æ€æ£€æŸ¥å‡½æ•° ====================
# æ£€æŸ¥æ­¥éª¤å®ŒæˆçŠ¶æ€
def get_step_status(step_index):
    if step_index == st.session_state.current_step:
        return "active"
    if step_index == 0 and st.session_state.merged_data is not None:
        return "completed"
    elif step_index == 1 and st.session_state.cleaned_data is not None:
        return "completed"
    elif step_index == 2 and st.session_state.retention_data is not None:
        return "completed"
    elif step_index == 3 and st.session_state.lt_results is not None:
        return "completed"
    elif step_index == 4 and st.session_state.arpu_data is not None:
        return "completed"
    elif step_index == 5 and st.session_state.ltv_results is not None:
        return "completed"
    return "normal"

# ==================== ä¾§è¾¹æ å¯¼èˆª ====================
# ä¾§è¾¹æ å¯¼èˆª
with st.sidebar:
    st.markdown('<div class="nav-container">', unsafe_allow_html=True)
    st.markdown('<h4 style="text-align: center; margin-bottom: 1rem; color: white;">åˆ†ææµç¨‹</h4>',
                unsafe_allow_html=True)

    for i, step in enumerate(ANALYSIS_STEPS):
        if st.button(f"{i + 1}. {step['name']}", key=f"nav_{i}",
                     use_container_width=True,
                     type="primary" if get_step_status(i) == "active" else "secondary"):
            st.session_state.current_step = i
            st.rerun()

    st.markdown('</div>', unsafe_allow_html=True)

# ==================== è¾…åŠ©å‡½æ•° ====================
def show_dependency_tip(required_step):
    """æ˜¾ç¤ºä¾èµ–æç¤ºï¼Œä½†ä¸é˜»æ­¢ç»§ç»­æ“ä½œ"""
    st.markdown(f"""
    <div class="step-tip">
        <div class="step-tip-title">ğŸ’¡ å»ºè®®</div>
        <div class="step-tip-content">å»ºè®®å…ˆå®Œæˆã€Œ{required_step}ã€æ­¥éª¤ï¼Œä»¥è·å¾—æ›´å¥½çš„åˆ†ææ•ˆæœã€‚æ‚¨ä¹Ÿå¯ä»¥ç»§ç»­å½“å‰æ­¥éª¤çš„æ“ä½œã€‚</div>
    </div>
    """, unsafe_allow_html=True)

# ==================== é¡µé¢è·¯ç”± ====================
# è·å–å½“å‰é¡µé¢
current_page = ANALYSIS_STEPS[st.session_state.current_step]["name"]

# ==================== é¡µé¢å†…å®¹ ====================

if current_page == "æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»":
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š æ•°æ®å¤„ç†ä¸LTå»ºæ¨¡åŸç†</div>
        <div class="principle-content">
        é›†æˆå¤šæºExcelç•™å­˜æ•°æ®ï¼Œæ”¯æŒHUE/ocpxåŒæ ¼å¼è§£æï¼Œç»å¼‚å¸¸æ¸…æ´—ã€ç•™å­˜è®¡ç®—ã€LTæ‹Ÿåˆåç”Ÿæˆç”Ÿå‘½å‘¨æœŸæ¨¡å‹ã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.subheader("æ¸ é“æ˜ å°„æ–‡ä»¶è®¾ç½®")
    
    # æ–‡ä»¶æ ¼å¼è¯´æ˜
    st.markdown("""
    <div class="step-tip">
        <div class="step-tip-title">ğŸ“‹ æ¸ é“æ˜ å°„æ–‡ä»¶æ ¼å¼è¦æ±‚</div>
        <div class="step-tip-content">
        â€¢ Excelç¬¬ä¸€åˆ—ï¼šæ¸ é“åç§°<br>
        â€¢ åç»­åˆ—ï¼šæ¸ é“å·(ä¸€ä¸ªæ¸ é“å¯å¯¹åº”å¤šä¸ªæ¸ é“å·)
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # æ¸ é“æ˜ å°„æ–‡ä»¶ä¸Šä¼ 
    channel_mapping_file = st.file_uploader(
        "ä¸Šä¼ æ¸ é“æ˜ å°„æ–‡ä»¶ (Excelæ ¼å¼ï¼Œå¯é€‰)",
        type=['xlsx', 'xls'],
        help="æ ¼å¼ï¼šç¬¬ä¸€åˆ—ä¸ºæ¸ é“åç§°ï¼Œåç»­åˆ—ä¸ºå¯¹åº”çš„æ¸ é“å·"
    )
    
    if channel_mapping_file:
        try:
            custom_mapping = parse_channel_mapping_from_excel(channel_mapping_file)
            if custom_mapping and isinstance(custom_mapping, dict) and len(custom_mapping) > 0:
                st.session_state.channel_mapping = custom_mapping
                st.success(f"æ¸ é“æ˜ å°„æ–‡ä»¶åŠ è½½æˆåŠŸï¼å…±åŒ…å« {len(custom_mapping)} ä¸ªæ˜ å°„å…³ç³»")
                
                # æ˜¾ç¤ºæ˜ å°„é¢„è§ˆ
                with st.expander("æŸ¥çœ‹æ¸ é“æ˜ å°„è¯¦æƒ…"):
                    mapping_df = pd.DataFrame([
                        {'æ¸ é“å·': pid, 'æ¸ é“åç§°': channel}
                        for pid, channel in sorted(custom_mapping.items())
                    ])
                    st.dataframe(mapping_df, use_container_width=True)
            else:
                st.error("æ¸ é“æ˜ å°„æ–‡ä»¶è§£æå¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤æ˜ å°„")
        except Exception as e:
            st.error(f"è¯»å–æ¸ é“æ˜ å°„æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")
    else:
        st.info("æœªä¸Šä¼ æ¸ é“æ˜ å°„æ–‡ä»¶ï¼Œå°†ä½¿ç”¨é»˜è®¤æ˜ å°„å…³ç³»")
        
        # æ˜¾ç¤ºé»˜è®¤æ˜ å°„
        with st.expander("æŸ¥çœ‹é»˜è®¤æ¸ é“æ˜ å°„"):
            default_mapping_df = pd.DataFrame([
                {'æ¸ é“å·': pid, 'æ¸ é“åç§°': channel}
                for pid, channel in sorted(DEFAULT_CHANNEL_MAPPING.items())
            ])
            st.dataframe(default_mapping_df, use_container_width=True)
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.subheader("æ•°æ®æ–‡ä»¶å¤„ç†")

    # æ•°æ®æ–‡ä»¶æ ¼å¼è¯´æ˜
    st.markdown("""
    <div class="step-tip">
        <div class="step-tip-title">ğŸ“‹ æ•°æ®æ–‡ä»¶æ ¼å¼è¦æ±‚</div>
        <div class="step-tip-content">
        <strong>HUEå¯¼å‡ºè¡¨ï¼š</strong><br>
        â€¢ åŒ…å«stat_dateåˆ—ï¼ˆæ—¥æœŸï¼‰<br>
        â€¢ åŒ…å«newåˆ—ï¼ˆæ–°å¢ç”¨æˆ·æ•°ï¼‰<br>
        â€¢ åŒ…å«new_retain_1åˆ°new_retain_30åˆ—ï¼ˆå„å¤©ç•™å­˜æ•°ï¼‰<br><br>
        <strong>ocpxå¯¼å‡ºè¡¨ï¼š</strong><br>
        â€¢ åŒ…å«ç•™å­˜å¤©æ•°åˆ—<br>
        â€¢ åŒ…å«å›ä¼ æ–°å¢æ•°åˆ—<br>
        â€¢ åŒ…å«1-30æ•°å­—åˆ—ï¼ˆå„å¤©ç•™å­˜æ•°ï¼‰<br>
        â€¢ æ”¯æŒExcelå·¥ä½œè¡¨ååŒ…å«"ocpxç›‘æµ‹ç•™å­˜æ•°"çš„ç‰¹æ®Šè¡¨æ ¼
        </div>
    </div>
    """, unsafe_allow_html=True)

    uploaded_files = st.file_uploader(
        "é€‰æ‹©Excelæ•°æ®æ–‡ä»¶",
        type=['xlsx', 'xls'],
        accept_multiple_files=True,
        help="æ”¯æŒä¸Šä¼ å¤šä¸ªExcelæ–‡ä»¶"
    )

    default_month = get_default_target_month()
    target_month = st.text_input("ç›®æ ‡æœˆä»½ (YYYY-MM)", value=default_month)

    if uploaded_files:
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")

        if st.button("å¼€å§‹å¤„ç†æ•°æ®", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®æ–‡ä»¶..."):
                try:
                    merged_data, processed_count, mapping_warnings = integrate_excel_files_streamlit(
                        uploaded_files, target_month, st.session_state.channel_mapping
                    )

                    if merged_data is not None and not merged_data.empty:
                        st.session_state.merged_data = merged_data
                        st.success(f"æ•°æ®å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {processed_count} ä¸ªæ–‡ä»¶")

                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æ€»è®°å½•æ•°", f"{len(merged_data):,}")
                        with col2:
                            st.metric("æ•°æ®æ¥æºæ•°", merged_data['æ•°æ®æ¥æº'].nunique())
                        with col3:
                            if 'å›ä¼ æ–°å¢æ•°' in merged_data.columns:
                                total_users = merged_data['å›ä¼ æ–°å¢æ•°'].sum()
                                st.metric("æ€»æ–°å¢ç”¨æˆ·", f"{total_users:,.0f}")

                        # æ˜¾ç¤ºæ˜ å°„è­¦å‘Š
                        if mapping_warnings:
                            st.warning("ä»¥ä¸‹æ–‡ä»¶æœªåœ¨æ¸ é“æ˜ å°„ä¸­æ‰¾åˆ°å¯¹åº”å…³ç³»ï¼š")
                            for warning in mapping_warnings:
                                st.text(f"â€¢ {warning}")

                        st.subheader("æ•°æ®é¢„è§ˆ")
                        st.dataframe(merged_data.head(10), use_container_width=True)
                    else:
                        st.error("æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
                except Exception as e:
                    st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")
    else:
        st.info("è¯·é€‰æ‹©Excelæ–‡ä»¶å¼€å§‹æ•°æ®å¤„ç†")

    st.markdown('</div>', unsafe_allow_html=True)

elif current_page == "å¼‚å¸¸æ•°æ®å‰”é™¤":
    # ä¾èµ–æ€§æç¤º
    if st.session_state.merged_data is None:
        show_dependency_tip("æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»")
    
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š æ­¥éª¤åŸç†</div>
        <div class="principle-content">
        å¼‚å¸¸æ•°æ®å‰”é™¤ç”¨äºæ¸…ç†å¯èƒ½å½±å“åˆ†æç»“æœçš„å¼‚å¸¸è®°å½•ã€‚é€šè¿‡è®¾ç½®å¤šé‡ç­›é€‰æ¡ä»¶ï¼Œå¯ä»¥å‰”é™¤ç‰¹å®šæ•°æ®æ¥æºæˆ–æ—¥æœŸçš„æ•°æ®ã€‚æ‰€æœ‰å‰”é™¤æ¡ä»¶é‡‡ç”¨"ä¸”"å…³ç³»ï¼Œå³æ•°æ®å¿…é¡»åŒæ—¶æ»¡è¶³æ‰€æœ‰æ¡ä»¶æ‰ä¼šè¢«å‰”é™¤ï¼Œç¡®ä¿æ•°æ®æ¸…ç†çš„ç²¾å‡†æ€§ã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.merged_data is not None:
        merged_data = st.session_state.merged_data

        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("å¼‚å¸¸æ•°æ®å‰”é™¤é…ç½®")
        st.info("æ³¨æ„ï¼šæ‰€æœ‰å‰”é™¤æ¡ä»¶å¿…é¡»åŒæ—¶æ»¡è¶³æ‰ä¼šè¢«å‰”é™¤ï¼ˆä¸”å…³ç³»ï¼‰")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("### æŒ‰æ•°æ®æ¥æºå‰”é™¤")
            all_sources = merged_data['æ•°æ®æ¥æº'].unique().tolist()
            excluded_sources = st.multiselect("é€‰æ‹©è¦å‰”é™¤çš„æ•°æ®æ¥æº", options=all_sources)

        with col2:
            st.markdown("### æŒ‰æ—¥æœŸå‰”é™¤")
            if 'date' in merged_data.columns:
                all_dates = sorted(merged_data['date'].unique().tolist())
                excluded_dates = st.multiselect("é€‰æ‹©è¦å‰”é™¤çš„æ—¥æœŸ", options=all_dates)
            else:
                st.info("æ•°æ®ä¸­æ— æ—¥æœŸå­—æ®µ")
                excluded_dates = []

        try:
            exclusion_mask = pd.Series([True] * len(merged_data), index=merged_data.index)

            if excluded_sources:
                source_mask = merged_data['æ•°æ®æ¥æº'].isin(excluded_sources)
                exclusion_mask &= source_mask

            if 'date' in merged_data.columns and excluded_dates:
                date_mask = merged_data['date'].isin(excluded_dates)
                exclusion_mask &= date_mask

            if not excluded_sources and not excluded_dates:
                exclusion_mask = pd.Series([False] * len(merged_data), index=merged_data.index)

            to_exclude = merged_data[exclusion_mask]
            to_keep = merged_data[~exclusion_mask]

        except Exception as e:
            st.error(f"è®¡ç®—å‰”é™¤æ¡ä»¶æ—¶å‡ºé”™: {str(e)}")
            to_exclude = pd.DataFrame()
            to_keep = merged_data.copy()

        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"### å°†è¢«å‰”é™¤çš„æ•°æ® ({len(to_exclude)} æ¡)")
            if len(to_exclude) > 0:
                st.dataframe(to_exclude.head(5), use_container_width=True)

        with col2:
            st.markdown(f"### ä¿ç•™çš„æ•°æ® ({len(to_keep)} æ¡)")
            if len(to_keep) > 0:
                st.dataframe(to_keep.head(5), use_container_width=True)

        if st.button("ç¡®è®¤å‰”é™¤å¼‚å¸¸æ•°æ®", type="primary", use_container_width=True):
            try:
                if len(to_exclude) > 0:
                    # è®°å½•å…·ä½“å‰”é™¤çš„æ—¥æœŸä¿¡æ¯
                    excluded_dates_info = []
                    for _, row in to_exclude.iterrows():
                        source = row.get('æ•°æ®æ¥æº', 'Unknown')
                        date = row.get('date', 'Unknown')
                        excluded_dates_info.append(f"{source}-{date}")
                    
                    st.session_state.excluded_data = excluded_dates_info
                    st.session_state.excluded_dates_info = excluded_dates
                    st.session_state.cleaned_data = to_keep.copy()
                    st.success(f"æˆåŠŸå‰”é™¤ {len(to_exclude)} æ¡å¼‚å¸¸æ•°æ®")
                else:
                    st.session_state.cleaned_data = merged_data.copy()
                    st.session_state.excluded_dates_info = []
                    st.info("æœªå‘ç°éœ€è¦å‰”é™¤çš„å¼‚å¸¸æ•°æ®")
            except Exception as e:
                st.error(f"å‰”é™¤æ•°æ®æ—¶å‡ºé”™: {str(e)}")

        st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.info("æš‚æ— æ•°æ®å¯ä¾›åˆ†æã€‚æ‚¨å¯ä»¥ç»§ç»­é…ç½®å‰”é™¤è§„åˆ™ï¼Œæˆ–å…ˆå®Œæˆæ•°æ®ä¸Šä¼ ã€‚")
        st.markdown('</div>', unsafe_allow_html=True)

elif current_page == "ç•™å­˜ç‡è®¡ç®—":
    # ä¾èµ–æ€§æç¤º
    if st.session_state.cleaned_data is None and st.session_state.merged_data is None:
        show_dependency_tip("æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»")
    
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š æ­¥éª¤åŸç†</div>
        <div class="principle-content">
        ç•™å­˜ç‡è®¡ç®—æ˜¯LTVå»ºæ¨¡çš„æ ¸å¿ƒæ­¥éª¤ã€‚ç³»ç»Ÿé€šè¿‡è®¡ç®—æ¯å¤©ç•™å­˜ç”¨æˆ·æ•°ä¸æ–°å¢ç”¨æˆ·æ•°çš„æ¯”å€¼ï¼Œå¾—å‡º1-30å¤©çš„æ—¥ç•™å­˜ç‡ã€‚å¯¹äºæ¯ä¸ªæ¸ é“ï¼Œç³»ç»Ÿä¼šæ±‡æ€»æ‰€æœ‰æœ‰æ•ˆè®°å½•çš„ç•™å­˜æ•°æ®ï¼Œå¹¶è®¡ç®—å¹³å‡ç•™å­˜ç‡ã€‚ç•™å­˜ç‡æ•°æ®è´¨é‡ç›´æ¥å½±å“åç»­LTæ‹Ÿåˆçš„å‡†ç¡®æ€§ã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.cleaned_data is not None:
        working_data = st.session_state.cleaned_data
        data_source_info = "ä½¿ç”¨æ¸…ç†åçš„æ•°æ®"
        
        # æ˜¾ç¤ºå‰”é™¤ä¿¡æ¯ - æ˜¾ç¤ºå…·ä½“å‰”é™¤çš„æ—¥æœŸ
        if st.session_state.excluded_dates_info and len(st.session_state.excluded_dates_info) > 0:
            excluded_dates_str = ", ".join(st.session_state.excluded_dates_info)
            st.markdown(f"""
            <div class="exclusion-info">
                <div class="exclusion-info-title">âš ï¸ æ•°æ®å‰”é™¤ä¿¡æ¯</div>
                <div class="exclusion-info-content">
                å·²å‰”é™¤ä»¥ä¸‹æ—¥æœŸçš„æ•°æ®ï¼š{excluded_dates_str}
                </div>
            </div>
            """, unsafe_allow_html=True)
        elif st.session_state.excluded_data and len(st.session_state.excluded_data) > 0:
            # å…¼å®¹ä¹‹å‰çš„æ ¼å¼
            st.markdown(f"""
            <div class="exclusion-info">
                <div class="exclusion-info-title">âš ï¸ æ•°æ®å‰”é™¤ä¿¡æ¯</div>
                <div class="exclusion-info-content">
                å·²å‰”é™¤ {len(st.session_state.excluded_data)} æ¡å¼‚å¸¸æ•°æ®
                </div>
            </div>
            """, unsafe_allow_html=True)
            
    elif st.session_state.merged_data is not None:
        working_data = st.session_state.merged_data
        data_source_info = "ä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆæœªç»å‰”é™¤å¤„ç†ï¼‰"
    else:
        working_data = None
        data_source_info = "æ— å¯ç”¨æ•°æ®"

    if working_data is not None:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("ç•™å­˜ç‡è®¡ç®—é…ç½®")
        
        # æ•°æ®æ¥æºä¿¡æ¯
        st.markdown(f"""
        <div class="data-source-info">
            <div class="data-source-info-title">ğŸ“Š æ•°æ®æ¥æº</div>
            <div class="data-source-info-content">{data_source_info}</div>
        </div>
        """, unsafe_allow_html=True)

        # æ•°æ®è´¨é‡è¦æ±‚è¯´æ˜
        st.markdown("""
        <div class="step-tip">
            <div class="step-tip-title">ğŸ“‹ æ•°æ®è´¨é‡è¦æ±‚</div>
            <div class="step-tip-content">
            â€¢ æ–°å¢ç”¨æˆ·æ•°å¿…é¡»å¤§äº0<br>
            â€¢ ç•™å­˜ç‡èŒƒå›´ï¼š0 < ç•™å­˜ç‡ â‰¤ 1.5<br>
            â€¢ ç³»ç»Ÿè‡ªåŠ¨æ±‡æ€»å¤šæ¡è®°å½•å¹¶è®¡ç®—å¹³å‡ç•™å­˜ç‡<br>
            â€¢ æ”¯æŒ1-30å¤©ç•™å­˜æ•°æ®çš„éè¿ç»­è¾“å…¥
            </div>
        </div>
        """, unsafe_allow_html=True)

        data_sources = working_data['æ•°æ®æ¥æº'].unique()
        selected_sources = st.multiselect("é€‰æ‹©è¦åˆ†æçš„æ•°æ®æ¥æº", options=data_sources, default=data_sources)

        if st.button("è®¡ç®—ç•™å­˜ç‡", type="primary", use_container_width=True):
            if selected_sources:
                with st.spinner("æ­£åœ¨è®¡ç®—ç•™å­˜ç‡..."):
                    filtered_data = working_data[working_data['æ•°æ®æ¥æº'].isin(selected_sources)]
                    retention_results = calculate_retention_rates_advanced(filtered_data)
                    st.session_state.retention_data = retention_results

                    st.success("ç•™å­˜ç‡è®¡ç®—å®Œæˆï¼")

                    # æ˜¾ç¤ºç®€å•ç»Ÿè®¡ä¿¡æ¯ï¼Œä¸æ˜¾ç¤ºå›¾è¡¨
                    for result in retention_results:
                        with st.expander(f"{result['data_source']} - ç•™å­˜ç‡è¯¦æƒ…"):
                            days = result['days']
                            rates = result['rates']
                            
                            if len(days) > 0:
                                st.write(f"æ•°æ®å¤©æ•°èŒƒå›´: {min(days)} - {max(days)} å¤©")
                                st.write(f"æ•°æ®ç‚¹æ•°é‡: {len(days)} ä¸ª")
                                st.write(f"å¹³å‡ç•™å­˜ç‡: {np.mean(rates):.4f}")
                                st.write(f"æœ€é«˜ç•™å­˜ç‡: {max(rates):.4f}")
                                st.write(f"æœ€ä½ç•™å­˜ç‡: {min(rates):.4f}")
                                
                                # æ˜¾ç¤ºå…·ä½“çš„å¤©æ•°å’Œç•™å­˜ç‡æ•°æ®
                                retention_df = pd.DataFrame({
                                    'å¤©æ•°': days,
                                    'ç•™å­˜ç‡': [f"{rate:.4f}" for rate in rates]
                                })
                                st.dataframe(retention_df, use_container_width=True)
            else:
                st.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ•°æ®æ¥æº")

        st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.info("æš‚æ— æ•°æ®å¯ä¾›åˆ†æã€‚æ‚¨å¯ä»¥ç»§ç»­é…ç½®ç•™å­˜ç‡è®¡ç®—ï¼Œæˆ–å…ˆå®Œæˆæ•°æ®ä¸Šä¼ ã€‚")
        st.markdown('</div>', unsafe_allow_html=True)

elif current_page == "LTæ‹Ÿåˆåˆ†æ":
    # ä¾èµ–æ€§æç¤º
    if st.session_state.retention_data is None:
        show_dependency_tip("ç•™å­˜ç‡è®¡ç®—")
    
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š æ­¥éª¤åŸç†</div>
        <div class="principle-content">
        LTæ‹Ÿåˆåˆ†æé‡‡ç”¨ä¸‰é˜¶æ®µåˆ†å±‚å»ºæ¨¡æ–¹æ³•ï¼š<br>
        <strong>ç¬¬ä¸€é˜¶æ®µ(1-30å¤©)ï¼š</strong>ä½¿ç”¨å¹‚å‡½æ•°æ‹Ÿåˆå®é™…ç•™å­˜æ•°æ®ï¼Œç”Ÿæˆå®Œæ•´çš„1-30å¤©ç•™å­˜ç‡<br>
        <strong>ç¬¬äºŒé˜¶æ®µ(31-Xå¤©)ï¼š</strong>æ ¹æ®æ¸ é“ç±»å‹å»¶é•¿å¹‚å‡½æ•°é¢„æµ‹èŒƒå›´<br>
        <strong>ç¬¬ä¸‰é˜¶æ®µ(Y-Nå¹´)ï¼š</strong>ä½¿ç”¨æŒ‡æ•°å‡½æ•°å»ºæ¨¡é•¿æœŸç•™å­˜è¡°å‡è¶‹åŠ¿<br>
        ä¸åŒæ¸ é“é‡‡ç”¨ä¸åŒçš„é˜¶æ®µåˆ’åˆ†è§„åˆ™ï¼Œç¡®ä¿æ‹Ÿåˆç»“æœç¬¦åˆå„æ¸ é“çš„ç”¨æˆ·è¡Œä¸ºç‰¹å¾ã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.retention_data is not None:
        retention_data = st.session_state.retention_data

        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("åˆ†é˜¶æ®µæ‹Ÿåˆå‚æ•°é…ç½®")

        # æ¸ é“è§„åˆ™è¯´æ˜
        st.markdown("""
        <div class="step-tip">
            <div class="step-tip-title">ğŸ“‹ æ¸ é“æ‹Ÿåˆè§„åˆ™</div>
            <div class="step-tip-content">
            <strong>åä¸ºæ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-120å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ120-220å¤©<br>
            <strong>å°ç±³æ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-190å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ190-290å¤©<br>
            <strong>oppoæ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-160å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ160-260å¤©<br>
            <strong>vivoæ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-150å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ150-250å¤©<br>
            <strong>iPhoneæ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-150å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ150-250å¤©<br>
            <strong>å…¶ä»–æ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-100å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ100-200å¤©
            </div>
        </div>
        """, unsafe_allow_html=True)

        lt_years = st.number_input("LTè®¡ç®—å¹´é™", min_value=1, max_value=10, value=5)
        st.info("ç³»ç»Ÿå°†é‡‡ç”¨ä¸‰é˜¶æ®µåˆ†å±‚å»ºæ¨¡")

        if st.button("å¼€å§‹LTæ‹Ÿåˆåˆ†æ", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨è¿›è¡Œæ‹Ÿåˆè®¡ç®—..."):
                lt_results = []
                visualization_data_2y = {}
                visualization_data_5y = {}
                original_data = {}
                
                # å…³é”®æ—¶é—´ç‚¹åˆ—è¡¨
                key_days = [1, 7, 30, 60, 90, 100, 150, 200, 300]

                for retention_result in retention_data:
                    channel_name = retention_result['data_source']
                    
                    # è®¡ç®—5å¹´LT
                    lt_result = calculate_lt_advanced(retention_result, channel_name, lt_years, 
                                                    return_curve_data=True, key_days=key_days)

                    # è®¡ç®—2å¹´LT
                    lt_result_2y = calculate_lt_advanced(retention_result, channel_name, 2, 
                                                       return_curve_data=True, key_days=key_days)

                    lt_results.append({
                        'data_source': channel_name,
                        'lt_value': lt_result['lt_value'],
                        'fit_success': lt_result['success'],
                        'fit_params': lt_result['fit_params'],
                        'power_r2': lt_result['power_r2'],
                        'model_used': lt_result['model_used']
                    })

                    # ä¿å­˜å¯è§†åŒ–æ•°æ®
                    visualization_data_5y[channel_name] = {
                        "days": lt_result['curve_days'],
                        "rates": lt_result['curve_rates'],
                        "lt": lt_result['lt_value']
                    }
                    
                    visualization_data_2y[channel_name] = {
                        "days": lt_result_2y['curve_days'],
                        "rates": lt_result_2y['curve_rates'],
                        "lt": lt_result_2y['lt_value']
                    }

                    # ä¿å­˜åŸå§‹æ•°æ®
                    original_data[channel_name] = {
                        "days": retention_result['days'],
                        "rates": retention_result['rates']
                    }

                st.session_state.lt_results = lt_results
                st.success("LTæ‹Ÿåˆåˆ†æå®Œæˆï¼")

                # æ˜¾ç¤ºLTå€¼è¡¨æ ¼
                if lt_results:
                    st.subheader("LTåˆ†æç»“æœ")
                    results_df = pd.DataFrame([
                        {
                            'æ¸ é“åç§°': r['data_source'],
                            f'{lt_years}å¹´LT': round(r['lt_value'], 2),
                            'æ‹ŸåˆçŠ¶æ€': 'æˆåŠŸ' if r['fit_success'] else 'å¤±è´¥',
                            'RÂ²å¾—åˆ†': round(r['power_r2'], 3),
                            'ä½¿ç”¨æ¨¡å‹': r['model_used']
                        }
                        for r in lt_results
                    ])
                    st.dataframe(results_df, use_container_width=True)

                # åˆ›å»ºä¸“ä¸šçš„å¯è§†åŒ–å›¾è¡¨
                if visualization_data_2y and visualization_data_5y and original_data:
                    st.subheader("LTæ‹Ÿåˆåˆ†æå›¾è¡¨")
                    
                    with st.spinner("æ­£åœ¨ç”Ÿæˆä¸“ä¸šå›¾è¡¨..."):
                        chart_figures, fig_2y_combined, fig_5y_combined = create_professional_charts(
                            visualization_data_2y, visualization_data_5y, original_data
                        )
                    
                    # æ˜¾ç¤ºç»¼åˆå¯¹æ¯”å›¾è¡¨
                    st.markdown("### å„æ¸ é“æ‹Ÿåˆæ›²çº¿ç»¼åˆå¯¹æ¯”")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("#### 2å¹´LTå¯¹æ¯”")
                        st.pyplot(fig_2y_combined, use_container_width=True)
                        plt.close(fig_2y_combined)
                    
                    with col2:
                        st.markdown("#### 5å¹´LTå¯¹æ¯”")
                        st.pyplot(fig_5y_combined, use_container_width=True)
                        plt.close(fig_5y_combined)
                    
                    # æ˜¾ç¤ºå•æ¸ é“å›¾è¡¨ï¼ˆæŒ‰LTå€¼æ’åºï¼‰
                    st.markdown("### å„æ¸ é“å•ç‹¬åˆ†æå›¾è¡¨ï¼ˆæŒ‰LTå€¼ä»ä½åˆ°é«˜æ’åºï¼‰")
                    
                    # æ¯è¡Œæ˜¾ç¤º3ä¸ªå›¾è¡¨
                    for i in range(0, len(chart_figures), 3):
                        cols = st.columns(3)
                        for j, col in enumerate(cols):
                            if i + j < len(chart_figures):
                                chart_data = chart_figures[i + j]
                                with col:
                                    st.pyplot(chart_data['fig_100d'], use_container_width=True)
                                    plt.close(chart_data['fig_100d'])

        st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.info("æš‚æ— ç•™å­˜ç‡æ•°æ®å¯ä¾›åˆ†æã€‚æ‚¨å¯ä»¥ç»§ç»­é…ç½®æ‹Ÿåˆå‚æ•°ï¼Œæˆ–å…ˆå®Œæˆç•™å­˜ç‡è®¡ç®—ã€‚")
        st.markdown('</div>', unsafe_allow_html=True)

elif current_page == "ARPUè®¡ç®—":
    # ä¾èµ–æ€§æç¤º
    if st.session_state.lt_results is None:
        show_dependency_tip("LTæ‹Ÿåˆåˆ†æ")
    
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š æ­¥éª¤åŸç†</div>
        <div class="principle-content">
        ARPUï¼ˆAverage Revenue Per Userï¼‰æ˜¯è®¡ç®—LTVçš„å…³é”®å‚æ•°ã€‚ç³»ç»Ÿæ”¯æŒä¸¤ç§ARPUè¾“å…¥æ–¹å¼ï¼šExcelæ–‡ä»¶ä¸Šä¼ å’Œæ‰‹åŠ¨è®¾ç½®ã€‚ARPUæ•°æ®å°†ä¸LTå€¼ç›¸ä¹˜å¾—åˆ°æœ€ç»ˆçš„LTVã€‚ç¡®ä¿ARPUæ•°æ®çš„å‡†ç¡®æ€§å¯¹äºLTVåˆ†æè‡³å…³é‡è¦ã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)

    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.subheader("ARPUæ•°æ®å¤„ç†")

    # ARPUæ–‡ä»¶æ ¼å¼è¯´æ˜
    st.markdown("""
    <div class="step-tip">
        <div class="step-tip-title">ğŸ“‹ ARPUæ–‡ä»¶æ ¼å¼è¦æ±‚</div>
        <div class="step-tip-content">
        â€¢ Excelæ ¼å¼(.xlsx/.xls)<br>
        â€¢ åŒ…å«æ•°æ®æ¥æºåˆ—ï¼ˆæ¸ é“åç§°ï¼‰<br>
        â€¢ åŒ…å«ARPUå€¼åˆ—ï¼ˆæ•°å€¼å‹ï¼‰<br>
        â€¢ ç³»ç»Ÿä¼šè‡ªåŠ¨æŒ‰æ¸ é“åˆ†ç»„å¹¶è®¡ç®—å¹³å‡ARPU<br>
        â€¢ æ”¯æŒä¸€ä¸ªæ¸ é“å¤šæ¡è®°å½•
        </div>
    </div>
    """, unsafe_allow_html=True)

    arpu_file = st.file_uploader("é€‰æ‹©ARPUæ•°æ®æ–‡ä»¶ (Excelæ ¼å¼)", type=['xlsx', 'xls'])

    if arpu_file:
        try:
            arpu_df = pd.read_excel(arpu_file)
            st.success("ARPUæ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
            st.dataframe(arpu_df.head(10), use_container_width=True)

            col1, col2 = st.columns(2)
            with col1:
                source_col = st.selectbox("æ•°æ®æ¥æºåˆ—", options=arpu_df.columns)
                arpu_col = st.selectbox("ARPUå€¼åˆ—", options=arpu_df.columns)

            with col2:
                if arpu_col in arpu_df.columns:
                    arpu_values = pd.to_numeric(arpu_df[arpu_col], errors='coerce')
                    st.metric("å¹³å‡ARPU", f"{arpu_values.mean():.2f}")
                    st.metric("æœ‰æ•ˆè®°å½•æ•°", f"{arpu_values.notna().sum():,}")

            if st.button("å¤„ç†å¹¶ä¿å­˜ARPUæ•°æ®", type="primary", use_container_width=True):
                try:
                    processed_arpu = arpu_df.copy()
                    processed_arpu['data_source'] = processed_arpu[source_col].astype(str).str.strip()
                    processed_arpu['arpu_value'] = pd.to_numeric(processed_arpu[arpu_col], errors='coerce')

                    valid_data = processed_arpu[
                        processed_arpu['arpu_value'].notna() & (processed_arpu['arpu_value'] > 0)]
                    arpu_summary = valid_data.groupby('data_source')['arpu_value'].agg(['mean', 'count']).reset_index()
                    arpu_summary.columns = ['data_source', 'arpu_value', 'record_count']

                    st.session_state.arpu_data = arpu_summary
                    st.success("ARPUæ•°æ®å¤„ç†å®Œæˆï¼")
                    st.dataframe(arpu_summary, use_container_width=True)

                except Exception as e:
                    st.error(f"ARPUæ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")

        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")

    else:
        st.info("è¯·ä¸Šä¼ ARPUæ•°æ®æ–‡ä»¶ï¼Œæˆ–ä½¿ç”¨æ‰‹åŠ¨è®¾ç½®åŠŸèƒ½")

        if st.session_state.lt_results:
            st.subheader("æ‰‹åŠ¨è®¾ç½®ARPUå€¼")
            
            # æ‰‹åŠ¨è®¾ç½®è¯´æ˜
            st.markdown("""
            <div class="step-tip">
                <div class="step-tip-title">ğŸ“‹ æ‰‹åŠ¨è®¾ç½®è¯´æ˜</div>
                <div class="step-tip-content">
                ä¸ºæ¯ä¸ªæ¸ é“è®¾ç½®å¯¹åº”çš„ARPUå€¼ï¼Œå»ºè®®åŸºäºå†å²æ•°æ®æˆ–ä¸šåŠ¡é¢„æœŸè¿›è¡Œè®¾ç½®ã€‚
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            arpu_inputs = {}

            col1, col2 = st.columns(2)
            for i, result in enumerate(st.session_state.lt_results):
                source = result['data_source']
                with col1 if i % 2 == 0 else col2:
                    arpu_value = st.number_input(
                        f"{source}", min_value=0.0, value=10.0, step=0.01,
                        format="%.2f", key=f"arpu_{source}"
                    )
                    arpu_inputs[source] = arpu_value

            if st.button("ä¿å­˜æ‰‹åŠ¨ARPUè®¾ç½®", type="primary", use_container_width=True):
                arpu_df = pd.DataFrame([
                    {'data_source': source, 'arpu_value': value, 'record_count': 1}
                    for source, value in arpu_inputs.items()
                ])
                st.session_state.arpu_data = arpu_df
                st.success("ARPUè®¾ç½®å·²ä¿å­˜ï¼")
                st.dataframe(arpu_df, use_container_width=True)
        else:
            st.info("è¯·å…ˆå®ŒæˆLTæ‹Ÿåˆåˆ†æä»¥è·å–æ¸ é“åˆ—è¡¨")

    st.markdown('</div>', unsafe_allow_html=True)

elif current_page == "LTVç»“æœæŠ¥å‘Š":
    # ä¾èµ–æ€§æç¤º
    if st.session_state.lt_results is None:
        show_dependency_tip("LTæ‹Ÿåˆåˆ†æ")
    elif st.session_state.arpu_data is None:
        show_dependency_tip("ARPUè®¡ç®—")
    
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š æ­¥éª¤åŸç†</div>
        <div class="principle-content">
        LTVç»“æœæŠ¥å‘Šæ˜¯æ•´ä¸ªåˆ†ææµç¨‹çš„æœ€ç»ˆè¾“å‡ºã€‚ç³»ç»Ÿé€šè¿‡LTV = LT Ã— ARPUçš„å…¬å¼è®¡ç®—æ¯ä¸ªæ¸ é“çš„ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šã€‚æŠ¥å‘ŠåŒ…å«å„æ¸ é“çš„LTå€¼ã€ARPUã€LTVè®¡ç®—ç»“æœä»¥åŠæ‹Ÿåˆè´¨é‡è¯„ä¼°ï¼Œä¸ºæ¸ é“æŠ•æ”¾å†³ç­–æä¾›æ•°æ®æ”¯æŒã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.lt_results is not None and st.session_state.arpu_data is not None:
        lt_results = st.session_state.lt_results
        arpu_data = st.session_state.arpu_data

        ltv_results = []

        for lt_result in lt_results:
            source = lt_result['data_source']
            lt_value = lt_result['lt_value']

            arpu_row = arpu_data[arpu_data['data_source'] == source]
            if not arpu_row.empty:
                arpu_value = arpu_row.iloc[0]['arpu_value']
            else:
                arpu_value = 0
                st.warning(f"æ¸ é“ '{source}' æœªæ‰¾åˆ°ARPUæ•°æ®")

            ltv_value = lt_value * arpu_value

            ltv_results.append({
                'data_source': source,
                'lt_value': lt_value,
                'arpu_value': arpu_value,
                'ltv_value': ltv_value,
                'fit_success': lt_result['fit_success'],
                'model_used': lt_result.get('model_used', 'unknown')
            })

        st.session_state.ltv_results = ltv_results

        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("LTVç»¼åˆè®¡ç®—ç»“æœ")

        # è®¡ç®—å…¬å¼è¯´æ˜
        st.markdown("""
        <div class="step-tip">
            <div class="step-tip-title">ğŸ“‹ è®¡ç®—å…¬å¼</div>
            <div class="step-tip-content">
            <strong>LTV = LT Ã— ARPU</strong><br>
            LTï¼šç”¨æˆ·ç”Ÿå‘½å‘¨æœŸé•¿åº¦ï¼ˆå¤©æ•°ï¼‰<br>
            ARPUï¼šå•ç”¨æˆ·å¹³å‡æ”¶å…¥<br>
            LTVï¼šç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼
            </div>
        </div>
        """, unsafe_allow_html=True)

        ltv_df = pd.DataFrame(ltv_results)
        display_df = ltv_df.rename(columns={
            'data_source': 'æ¸ é“åç§°',
            'lt_value': 'LT',
            'arpu_value': 'ARPU',
            'ltv_value': 'LTV',
            'fit_success': 'æ‹ŸåˆçŠ¶æ€',
            'model_used': 'ä½¿ç”¨æ¨¡å‹'
        })

        # æ•°å€¼æ ¼å¼åŒ–
        display_df['LT'] = display_df['LT'].round(2)
        display_df['ARPU'] = display_df['ARPU'].round(2)
        display_df['LTV'] = display_df['LTV'].round(2)
        display_df['æ‹ŸåˆçŠ¶æ€'] = display_df['æ‹ŸåˆçŠ¶æ€'].map({True: 'æˆåŠŸ', False: 'å¤±è´¥'})

        st.dataframe(display_df, use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)

        # æ•°æ®å¯¼å‡º
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("åˆ†æç»“æœå¯¼å‡º")

        col1, col2 = st.columns(2)

        with col1:
            # åˆ›å»ºæ ‡å‡†æ ¼å¼çš„CSVå¯¼å‡ºæ•°æ®ï¼ˆæŒ‰ç”¨æˆ·è¦æ±‚çš„åˆ—é¡ºåºï¼šæ¸ é“åç§° LT ARPU LTVï¼‰
            export_df = display_df[['æ¸ é“åç§°', 'LT', 'ARPU', 'LTV']].copy()
            
            # ä¿®å¤CSVå¯¼å‡ºçš„ä¸­æ–‡ç¼–ç é—®é¢˜
            csv_data = export_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ä¸‹è½½LTVåˆ†æç»“æœ (CSV)",
                data=csv_data.encode('utf-8-sig'),
                file_name=f"LTV_Analysis_Results_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv",
                use_container_width=True
            )

        with col2:
            # ç”Ÿæˆè¯¦ç»†æ•°æ®æ¥æºä¿¡æ¯
            data_source_desc = ""
            if st.session_state.excluded_dates_info and len(st.session_state.excluded_dates_info) > 0:
                excluded_dates_str = ", ".join(st.session_state.excluded_dates_info)
                data_source_desc = f"å·²å‰”é™¤ä»¥ä¸‹æ—¥æœŸæ•°æ®ï¼š{excluded_dates_str}"
            elif st.session_state.cleaned_data is not None:
                data_source_desc = "ä½¿ç”¨æ¸…ç†åæ•°æ®"
            else:
                data_source_desc = "ä½¿ç”¨åŸå§‹æ•°æ®"
            
            report_text = f"""
LTVç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†ææŠ¥å‘Š
===========================================
ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ‰§è¡Œæ‘˜è¦
-----------
æœ¬æŠ¥å‘ŠåŸºäºåˆ†é˜¶æ®µæ•°å­¦å»ºæ¨¡æ–¹æ³•ï¼Œå¯¹ {len(display_df)} ä¸ªæ•°æ®æ¥æºè¿›è¡Œäº†ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†æã€‚

æ ¸å¿ƒæŒ‡æ ‡æ±‡æ€»
-----------
â€¢ å‚ä¸åˆ†æçš„æ¸ é“æ•°é‡: {len(display_df)}
â€¢ å¹³å‡LTV: {display_df['LTV'].mean():.2f}
â€¢ æœ€é«˜LTV: {display_df['LTV'].max():.2f}
â€¢ æœ€ä½LTV: {display_df['LTV'].min():.2f}
â€¢ å¹³å‡LTå€¼: {display_df['LT'].mean():.2f} å¤©
â€¢ å¹³å‡ARPU: {display_df['ARPU'].mean():.2f}

è¯¦ç»†ç»“æœ
-----------
{export_df.to_string(index=False)}

æ•°æ®æ¥æºè¯´æ˜
-----------
{data_source_desc}

è®¡ç®—æ–¹æ³•
-----------
â€¢ LTæ‹Ÿåˆ: ä¸‰é˜¶æ®µåˆ†å±‚å»ºæ¨¡ï¼ˆå¹‚å‡½æ•°+æŒ‡æ•°å‡½æ•°ï¼‰
â€¢ LTVå…¬å¼: LTV = LT Ã— ARPU
â€¢ æ¸ é“è§„åˆ™: æŒ‰åä¸ºã€å°ç±³ã€oppoã€vivoã€iPhoneåˆ†ç±»è®¾å®šä¸åŒæ‹Ÿåˆå‚æ•°

æŠ¥å‘Šç”Ÿæˆ: LTVæ™ºèƒ½åˆ†æå¹³å° v2.0
"""

            st.download_button(
                label="ä¸‹è½½è¯¦ç»†åˆ†ææŠ¥å‘Š (TXT)",
                data=report_text.encode('utf-8'),
                file_name=f"LTV_Detailed_Report_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                mime="text/plain",
                use_container_width=True
            )

        st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.info("è¯·å…ˆå®ŒæˆLTæ‹Ÿåˆåˆ†æå’ŒARPUè®¡ç®—ä»¥ç”ŸæˆLTVæŠ¥å‘Šã€‚")
        st.markdown('</div>', unsafe_allow_html=True)

# ==================== åº•éƒ¨ä¿¡æ¯ ====================
# åº•éƒ¨ä¿¡æ¯
with st.sidebar:
    st.markdown("---")
    st.markdown("""
    <div class="nav-container">
        <h4 style="text-align: center; color: white;">ä½¿ç”¨æŒ‡å—</h4>
        <p style="font-size: 0.9rem; color: rgba(255,255,255,0.9); text-align: center;">
        ç‚¹å‡»ä¸Šæ–¹æ­¥éª¤å¯ç›´æ¥è·³è½¬ï¼Œç³»ç»Ÿä¼šæä¾›ç›¸åº”çš„æ“ä½œæŒ‡å¯¼ã€‚
        </p>
        <p style="font-size: 0.8rem; color: rgba(255,255,255,0.7); text-align: center;">
        LTVæ™ºèƒ½åˆ†æå¹³å° v2.0<br>
        åŸºäºåˆ†é˜¶æ®µæ•°å­¦å»ºæ¨¡
        </p>
    </div>
    """, unsafe_allow_html=True)
