import streamlit as st
import os
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
import datetime
import tempfile
import zipfile
import io
import matplotlib.pyplot as plt
import matplotlib as mpl
import re
from matplotlib.font_manager import FontProperties
import seaborn as sns
from scipy.optimize import curve_fit

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl.styles.stylesheet')
warnings.filterwarnings('ignore', category=UserWarning,
                        message="Could not infer format, so each element will be parsed individually")

# è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="LTV Analytics Platform",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="ğŸ“Š"
)

# è“è‰²ç³»CSSæ ·å¼
st.markdown("""
<style>
    /* å…¨å±€æ ·å¼ */
    .main {
        background: linear-gradient(135deg, #0f172a 0%, #1e293b 30%, #334155 100%);
        min-height: 100vh;
    }
    
    .block-container {
        padding: 1rem 1rem 3rem 1rem;
        max-width: 100%;
        background: transparent;
    }
    
    /* ä¸»æ ‡é¢˜åŒºåŸŸ */
    .main-header {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(10px);
        padding: 1.2rem;
        border-radius: 12px;
        box-shadow: 0 4px 20px rgba(15, 23, 42, 0.3);
        border: 1px solid rgba(255, 255, 255, 0.18);
        margin-bottom: 1.5rem;
        text-align: center;
    }
    
    .main-title {
        font-size: 1.8rem;
        font-weight: 700;
        background: linear-gradient(135deg, #1e293b 0%, #475569 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 0.3rem;
    }
    
    .main-subtitle {
        color: #64748b;
        font-size: 1.1rem;
        font-weight: 400;
    }
    
    /* å¡ç‰‡æ ·å¼ */
    .glass-card {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(10px);
        border-radius: 12px;
        padding: 1rem;
        box-shadow: 0 4px 20px rgba(15, 23, 42, 0.2);
        border: 1px solid rgba(255, 255, 255, 0.18);
        margin-bottom: 1rem;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
    }
    
    .glass-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 12px 40px rgba(15, 23, 42, 0.4);
    }
    
    /* æŒ‡æ ‡å¡ç‰‡ */
    .metric-card {
        background: linear-gradient(135deg, #1e40af 0%, #2563eb 50%, #3b82f6 100%);
        color: white;
        padding: 1rem;
        border-radius: 8px;
        text-align: center;
        box-shadow: 0 2px 12px rgba(37, 99, 235, 0.3);
        margin-bottom: 0.8rem;
    }
    
    .metric-value {
        font-size: 2rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
    }
    
    .metric-label {
        font-size: 0.9rem;
        opacity: 0.9;
    }
    
    /* çŠ¶æ€å¡ç‰‡ */
    .status-card {
        background: rgba(255, 255, 255, 0.9);
        border-radius: 8px;
        padding: 1rem;
        border-left: 4px solid #2563eb;
        box-shadow: 0 2px 8px rgba(37, 99, 235, 0.1);
        margin-bottom: 0.8rem;
    }
    
    /* è¿›åº¦æŒ‡ç¤ºå™¨ */
    .progress-container {
        background: rgba(255, 255, 255, 0.9);
        border-radius: 12px;
        padding: 1rem;
        margin-bottom: 1rem;
    }
    
    .progress-step {
        display: flex;
        align-items: center;
        margin-bottom: 1rem;
        padding: 0.5rem;
        border-radius: 8px;
        transition: background-color 0.3s ease;
        cursor: pointer;
    }
    
    .progress-step.active {
        background: linear-gradient(135deg, #1e40af 0%, #2563eb 100%);
        color: white;
    }
    
    .progress-step.completed {
        background: linear-gradient(135deg, #059669 0%, #10b981 100%);
        color: white;
    }
    
    .step-number {
        width: 30px;
        height: 30px;
        border-radius: 50%;
        background: rgba(255, 255, 255, 0.2);
        display: flex;
        align-items: center;
        justify-content: center;
        margin-right: 1rem;
        font-weight: 600;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #1e40af 0%, #2563eb 100%);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.5rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(37, 99, 235, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(37, 99, 235, 0.5);
        background: linear-gradient(135deg, #1d4ed8 0%, #2563eb 100%);
    }
    
    /* ä¾§è¾¹æ æ ·å¼ */
    .css-1d391kg {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(10px);
    }
    
    /* æ•°æ®è¡¨æ ¼æ ·å¼ */
    .dataframe {
        border-radius: 8px;
        overflow: hidden;
        box-shadow: 0 4px 12px rgba(37, 99, 235, 0.1);
    }
    
    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ */
    .uploadedfile {
        border: 2px dashed #2563eb;
        border-radius: 8px;
        padding: 2rem;
        text-align: center;
        background: rgba(37, 99, 235, 0.05);
    }
    
    /* é€‰æ‹©æ¡†æ ·å¼ */
    .stSelectbox label, .stMultiselect label, .stFileUploader label {
        font-weight: 600;
        color: #1e293b;
        margin-bottom: 0.5rem;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    h1, h2, h3 {
        color: #1e293b;
        font-weight: 600;
    }
    
    /* æˆåŠŸ/è­¦å‘Š/é”™è¯¯æ¶ˆæ¯ */
    .stSuccess {
        background: linear-gradient(135deg, #059669 0%, #10b981 100%);
        color: white;
        border-radius: 8px;
    }
    
    .stWarning {
        background: linear-gradient(135deg, #d97706 0%, #f59e0b 100%);
        color: white;
        border-radius: 8px;
    }
    
    .stError {
        background: linear-gradient(135deg, #dc2626 0%, #ef4444 100%);
        color: white;
        border-radius: 8px;
    }
    
    /* éšè—é»˜è®¤çš„Streamlitå…ƒç´  */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 768px) {
        .main-title {
            font-size: 2rem;
        }
        
        .glass-card {
            padding: 1rem;
        }
        
        .metric-card {
            padding: 1rem;
        }
    }
</style>
""", unsafe_allow_html=True)

# é»˜è®¤æ¸ é“æ˜ å°„æ•°æ®
DEFAULT_CHANNEL_MAPPING = {
    # æ€»ä½“
    '9000': 'æ€»ä½“',
    
    # æ–°åª’ä½“
    '500345': 'æ–°åª’ä½“', '500346': 'æ–°åª’ä½“', '500447': 'æ–°åª’ä½“', '500449': 'æ–°åª’ä½“', 
    '500450': 'æ–°åª’ä½“', '500531': 'æ–°åª’ä½“', '500542': 'æ–°åª’ä½“',
    
    # åº”ç”¨å®
    '5007XS': 'åº”ç”¨å®', '500349': 'åº”ç”¨å®', '500350': 'åº”ç”¨å®',
    
    # é¼ä¹ç³»åˆ—
    '500285': 'é¼ä¹-ç››ä¸–6',
    '500286': 'é¼ä¹-ç››ä¸–7',
    
    # é…·æ´¾
    '5108': 'é…·æ´¾', '5528': 'é…·æ´¾',
    
    # æ–°ç¾ç³»åˆ—
    '500275': 'æ–°ç¾-åŒ—äº¬2',
    '500274': 'æ–°ç¾-åŒ—äº¬1',
    
    # A_æ·±åœ³è›‹ä¸2
    '500316': 'A_æ·±åœ³è›‹ä¸2',
    
    # ä¸»æµå‚å•†
    '500297': 'è£è€€',
    '5057': 'åä¸º',
    '5237': 'vivo',
    '5599': 'å°ç±³',
    '5115': 'OPPO',
    
    # ç½‘æ˜“
    '500471': 'ç½‘æ˜“', '500480': 'ç½‘æ˜“', '500481': 'ç½‘æ˜“', '500482': 'ç½‘æ˜“',
    
    # åä¸ºéå•†åº—-å“ä¼—
    '500337': 'åä¸ºéå•†åº—-å“ä¼—', '500338': 'åä¸ºéå•†åº—-å“ä¼—', '500343': 'åä¸ºéå•†åº—-å“ä¼—',
    '500445': 'åä¸ºéå•†åº—-å“ä¼—', '500383': 'åä¸ºéå•†åº—-å“ä¼—', '500444': 'åä¸ºéå•†åº—-å“ä¼—',
    '500441': 'åä¸ºéå•†åº—-å“ä¼—',
    
    # é­…æ—
    '5072': 'é­…æ—',
    
    # OPPOéå•†åº—
    '500287': 'OPPOéå•†åº—', '500288': 'OPPOéå•†åº—',
    
    # vivoéå•†åº—
    '5187': 'vivoéå•†åº—',
    
    # ç™¾åº¦semç³»åˆ—
    '500398': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£å®‰å“', '500400': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£å®‰å“', '500404': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£å®‰å“',
    '500402': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£ios', '500403': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£ios', '500405': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£ios',
    
    # ç™¾é’è—¤
    '500377': 'ç™¾é’è—¤-å®‰å“', '500379': 'ç™¾é’è—¤-å®‰å“', '500435': 'ç™¾é’è—¤-å®‰å“', '500436': 'ç™¾é’è—¤-å®‰å“',
    '500490': 'ç™¾é’è—¤-å®‰å“', '500491': 'ç™¾é’è—¤-å®‰å“', '500434': 'ç™¾é’è—¤-å®‰å“', '500492': 'ç™¾é’è—¤-å®‰å“',
    '500437': 'ç™¾é’è—¤-ios',
    
    # å°ç±³éå•†åº—
    '500170': 'å°ç±³éå•†åº—',
    
    # åä¸ºéå•†åº—-æ˜Ÿç«
    '500532': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500533': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500534': 'åä¸ºéå•†åº—-æ˜Ÿç«',
    '500537': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500538': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500539': 'åä¸ºéå•†åº—-æ˜Ÿç«',
    '500540': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500541': 'åä¸ºéå•†åº—-æ˜Ÿç«',
    
    # å¾®åšç³»åˆ—
    '500504': 'å¾®åš-èœœæ©˜', '500505': 'å¾®åš-èœœæ©˜',
    '500367': 'å¾®åš-å¤®å¹¿', '500368': 'å¾®åš-å¤®å¹¿', '500369': 'å¾®åš-å¤®å¹¿',
    
    # å¹¿ç‚¹é€š
    '500498': 'å¹¿ç‚¹é€š', '500497': 'å¹¿ç‚¹é€š', '500500': 'å¹¿ç‚¹é€š',
    '500501': 'å¹¿ç‚¹é€š', '500496': 'å¹¿ç‚¹é€š', '500499': 'å¹¿ç‚¹é€š',
    
    # ç½‘æ˜“æ˜“æ•ˆ
    '500514': 'ç½‘æ˜“æ˜“æ•ˆ', '500515': 'ç½‘æ˜“æ˜“æ•ˆ', '500516': 'ç½‘æ˜“æ˜“æ•ˆ'
}

# è®¡ç®—é»˜è®¤ç›®æ ‡æœˆä»½ï¼ˆ2ä¸ªæœˆå‰ï¼‰
def get_default_target_month():
    today = datetime.datetime.now()
    # è®¡ç®—2ä¸ªæœˆå‰
    if today.month <= 2:
        target_year = today.year - 1
        target_month = today.month + 10
    else:
        target_year = today.year
        target_month = today.month - 2
    
    return f"{target_year}-{target_month:02d}"

# ä¸»æ ‡é¢˜
st.markdown("""
<div class="main-header">
    <div class="main-title">æ™ºèƒ½ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†æç³»ç»Ÿ</div>
</div>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
session_keys = [
    'channel_mapping', 'merged_data', 'cleaned_data', 'retention_data', 
    'lt_results', 'arpu_data', 'ltv_results', 'current_step', 'excluded_data'
]
for key in session_keys:
    if key not in st.session_state:
        st.session_state[key] = None

# è®¾ç½®é»˜è®¤å€¼
if st.session_state.channel_mapping is None:
    st.session_state.channel_mapping = DEFAULT_CHANNEL_MAPPING
if st.session_state.current_step is None:
    st.session_state.current_step = 0
if st.session_state.excluded_data is None:
    st.session_state.excluded_data = []

# åˆ†ææ­¥éª¤å®šä¹‰ï¼ˆæ–°å¢å¼‚å¸¸æ•°æ®å‰”é™¤æ­¥éª¤ï¼‰
ANALYSIS_STEPS = [
    {"name": "æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»", "icon": "01", "desc": "ä¸Šä¼ åŸå§‹æ•°æ®æ–‡ä»¶"},
    {"name": "å¼‚å¸¸æ•°æ®å‰”é™¤", "icon": "02", "desc": "å‰”é™¤å¼‚å¸¸æ•°æ®ç‚¹"},
    {"name": "ç•™å­˜ç‡è®¡ç®—", "icon": "03", "desc": "è®¡ç®—ç”¨æˆ·ç•™å­˜ç‡"},
    {"name": "LTæ‹Ÿåˆåˆ†æ", "icon": "04", "desc": "æ‹Ÿåˆç”Ÿå‘½å‘¨æœŸæ›²çº¿"},
    {"name": "ARPUè®¡ç®—", "icon": "05", "desc": "è®¾ç½®/è®¡ç®—ç”¨æˆ·ä»·å€¼"},
    {"name": "LTVç»“æœæŠ¥å‘Š", "icon": "06", "desc": "ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"}
]

# ä¾§è¾¹æ å¯¼èˆª
with st.sidebar:
    st.markdown("""
    <div class="progress-container">
        <h4 style="text-align: center; margin-bottom: 1rem; color: #495057;">åˆ†ææµç¨‹</h4>
    """, unsafe_allow_html=True)
    
    # é¡µé¢é€‰æ‹©ï¼ˆæ”¹ä¸ºç›´æ¥é€‰æ‹©æ¡†ï¼‰
    page = st.selectbox(
        "é€‰æ‹©åˆ†ææ¨¡å—",
        [step["name"] for step in ANALYSIS_STEPS],
        index=st.session_state.current_step,
        key="page_selector"
    )
    
    # æ›´æ–°å½“å‰æ­¥éª¤
    st.session_state.current_step = [step["name"] for step in ANALYSIS_STEPS].index(page)
    
    # è¿›åº¦æŒ‡ç¤ºå™¨
    for i, step in enumerate(ANALYSIS_STEPS):
        step_class = ""
        if i < st.session_state.current_step:
            step_class = "completed"
        elif i == st.session_state.current_step:
            step_class = "active"
        
        st.markdown(f"""
        <div class="progress-step {step_class}">
            <div class="step-number">{step['icon']}</div>
            <div>
                <strong>{step['name']}</strong><br>
                <small>{step['desc']}</small>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

# æ•°æ®æ•´åˆåŠŸèƒ½ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
def standardize_output_columns(df):
    """æ ‡å‡†åŒ–è¾“å‡ºåˆ—ç»“æ„ï¼Œç¡®ä¿åŒ…å«æŒ‡å®šçš„åˆ—é¡ºåº"""
    target_columns = [
        'æ•°æ®æ¥æº', 'date', 'æ•°æ®æ¥æº_date',
        '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',
        '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',
        '21', '22', '23', '24', '25', '26', '27', '28', '29', '30',
        'æ•°æ®æ¥æº_æ—¥æœŸ', 'æ—¥æœŸ', 'å›ä¼ æ–°å¢æ•°', 'is_target_month', 'month', 'stat_date',
        'new', 'new_retain_1', 'new_retain_2', 'new_retain_3', 'new_retain_4', 'new_retain_5',
        'new_retain_6', 'new_retain_7', 'new_retain_8', 'new_retain_9', 'new_retain_10',
        'new_retain_11', 'new_retain_12', 'new_retain_13', 'new_retain_14', 'new_retain_15',
        'new_retain_16', 'new_retain_17', 'new_retain_18', 'new_retain_19', 'new_retain_20',
        'new_retain_21', 'new_retain_22', 'new_retain_23', 'new_retain_24', 'new_retain_25',
        'new_retain_26', 'new_retain_27', 'new_retain_28', 'new_retain_29', 'new_retain_30'
    ]

    result_df = pd.DataFrame()
    
    for col_name in target_columns:
        if col_name == 'æ•°æ®æ¥æº':
            result_df[col_name] = df[col_name] if col_name in df.columns else ''
        elif col_name == 'date':
            if col_name in df.columns:
                result_df[col_name] = df[col_name]
            elif 'stat_date' in df.columns:
                result_df[col_name] = df['stat_date']
            else:
                result_df[col_name] = ''
        elif col_name == 'æ•°æ®æ¥æº_date':
            data_source = df['æ•°æ®æ¥æº'] if 'æ•°æ®æ¥æº' in df.columns else ''
            date_col = df['date'] if 'date' in df.columns else (df['stat_date'] if 'stat_date' in df.columns else '')
            result_df[col_name] = data_source.astype(str) + date_col.astype(str)
        elif col_name == 'æ•°æ®æ¥æº_æ—¥æœŸ':
            data_source = df['æ•°æ®æ¥æº'] if 'æ•°æ®æ¥æº' in df.columns else ''
            date_col = df['æ—¥æœŸ'] if 'æ—¥æœŸ' in df.columns else (
                df['date'] if 'date' in df.columns else (df['stat_date'] if 'stat_date' in df.columns else ''))
            result_df[col_name] = data_source.astype(str) + date_col.astype(str)
        else:
            result_df[col_name] = df[col_name] if col_name in df.columns else ''

    for col in df.columns:
        if col not in target_columns:
            result_df[col] = df[col]

    return result_df

def integrate_excel_files_streamlit(uploaded_files, target_month=None, channel_mapping=None):
    """Streamlitç‰ˆæœ¬çš„Excelæ–‡ä»¶æ•´åˆå‡½æ•°ï¼Œæ”¯æŒæ¸ é“æ˜ å°„ä¸å®Œå…¨åŒ¹é…"""
    if target_month is None:
        target_month = get_default_target_month()

    all_data = pd.DataFrame()
    processed_count = 0
    mapping_warnings = []

    for uploaded_file in uploaded_files:
        source_name = os.path.splitext(uploaded_file.name)[0]
        
        # å¦‚æœæœ‰æ¸ é“æ˜ å°„ï¼Œå°è¯•æ ¹æ®æ–‡ä»¶åæ˜ å°„æ¸ é“
        if channel_mapping and source_name in channel_mapping:
            mapped_source = channel_mapping[source_name]
        else:
            mapped_source = source_name
            if channel_mapping:  # å¦‚æœæœ‰æ¸ é“æ˜ å°„ä½†æœªæ‰¾åˆ°åŒ¹é…
                mapping_warnings.append(f"æ–‡ä»¶ '{source_name}' æœªåœ¨æ¸ é“æ˜ å°„è¡¨ä¸­æ‰¾åˆ°å¯¹åº”é¡¹ï¼Œå°†ä½¿ç”¨åŸå§‹æ–‡ä»¶å")
        
        try:
            xls = pd.ExcelFile(uploaded_file)
            sheet_names = xls.sheet_names

            ocpx_sheet = None
            channel_sheet = None

            for sheet in sheet_names:
                if "ocpxç›‘æµ‹ç•™å­˜æ•°" in sheet:
                    ocpx_sheet = sheet
                if "ç›‘æµ‹æ¸ é“å›ä¼ é‡" in sheet:
                    channel_sheet = sheet

            file_data = None

            if ocpx_sheet:
                ocpx_df = pd.read_excel(uploaded_file, sheet_name=ocpx_sheet)
                
                if channel_sheet:
                    channel_df = pd.read_excel(uploaded_file, sheet_name=channel_sheet)
                    if len(channel_df.columns) >= 2:
                        last_two_cols = channel_df.iloc[:, -2:]
                        ocpx_df = ocpx_df.copy()
                        for col_name in last_two_cols.columns:
                            ocpx_df[col_name] = last_two_cols[col_name].values[:len(ocpx_df)] if len(
                                last_two_cols) >= len(ocpx_df) else last_two_cols[col_name].values.tolist() + [
                                None] * (len(ocpx_df) - len(last_two_cols))
                
                file_data = ocpx_df
            else:
                file_data = pd.read_excel(uploaded_file, sheet_name=0)

            if file_data is not None and not file_data.empty:
                file_data_copy = file_data.copy()

                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ ¼å¼è¡¨
                has_stat_date = 'stat_date' in file_data_copy.columns
                retain_columns = [f'new_retain_{i}' for i in range(1, 31)]
                has_retain_columns = any(col in file_data_copy.columns for col in retain_columns)

                if has_stat_date and has_retain_columns:
                    standardized_data = file_data_copy.copy()

                    if 'new' in standardized_data.columns:
                        standardized_data['å›ä¼ æ–°å¢æ•°'] = standardized_data['new']

                    for i in range(1, 31):
                        retain_col = f'new_retain_{i}'
                        if retain_col in standardized_data.columns:
                            standardized_data[str(i)] = standardized_data[retain_col]

                    date_col = 'stat_date'
                    standardized_data[date_col] = pd.to_datetime(standardized_data[date_col], errors='coerce')
                    standardized_data[date_col] = standardized_data[date_col].dt.strftime('%Y-%m-%d')
                    standardized_data['æ—¥æœŸ'] = standardized_data[date_col]
                    standardized_data['month'] = standardized_data[date_col].str[:7]

                    filtered_data = standardized_data[standardized_data['month'] == target_month].copy()

                    if not filtered_data.empty:
                        filtered_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)
                        filtered_data['date'] = filtered_data['stat_date']
                        all_data = pd.concat([all_data, filtered_data], ignore_index=True)
                        processed_count += 1

                else:
                    # å¤„ç†æ—§æ ¼å¼è¡¨çš„é€»è¾‘ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    retention_col = None
                    for col in file_data_copy.columns:
                        if 'ç•™å­˜å¤©æ•°' in str(col):
                            retention_col = col
                            break

                    date_col = None
                    for col in file_data_copy.columns:
                        if 'æ—¥æœŸ' in str(col):
                            date_col = col
                            break

                    if len(file_data_copy.columns) >= 2:
                        second_col = file_data_copy.columns[1]
                        file_data_copy['å›ä¼ æ–°å¢æ•°'] = file_data_copy[second_col]

                    if date_col:
                        try:
                            file_data_copy[date_col] = pd.to_datetime(file_data_copy[date_col], errors='coerce')
                            file_data_copy['month'] = file_data_copy[date_col].dt.strftime('%Y-%m')
                            filtered_data = file_data_copy[file_data_copy['month'] == target_month].copy()
                            
                            if not filtered_data.empty:
                                filtered_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)
                                if retention_col:
                                    filtered_data.rename(columns={retention_col: 'date'}, inplace=True)
                                else:
                                    filtered_data['date'] = filtered_data[date_col].dt.strftime('%Y-%m-%d')
                                
                                all_data = pd.concat([all_data, filtered_data], ignore_index=True)
                                processed_count += 1
                        except:
                            # å¦‚æœæ—¥æœŸå¤„ç†å¤±è´¥ï¼Œä¿ç•™æ‰€æœ‰æ•°æ®
                            file_data_copy.insert(0, 'æ•°æ®æ¥æº', mapped_source)
                            if retention_col:
                                file_data_copy.rename(columns={retention_col: 'date'}, inplace=True)
                            all_data = pd.concat([all_data, file_data_copy], ignore_index=True)
                            processed_count += 1

        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} æ—¶å‡ºé”™: {str(e)}")

    if not all_data.empty:
        standardized_df = standardize_output_columns(all_data)
        return standardized_df, processed_count, mapping_warnings
    else:
        return None, 0, mapping_warnings

def parse_channel_mapping(channel_df):
    """è§£ææ¸ é“æ˜ å°„è¡¨ï¼Œæ”¯æŒæ–°çš„æ ¼å¼ï¼šç¬¬ä¸€åˆ—ä¸ºæ¸ é“åï¼Œåç»­åˆ—ä¸ºæ¸ é“å·"""
    pid_to_channel = {}
    
    for _, row in channel_df.iterrows():
        channel_name = str(row.iloc[0]).strip()  # ç¬¬ä¸€åˆ—æ˜¯æ¸ é“å
        
        # è·³è¿‡ç©ºè¡Œæˆ–æ— æ•ˆçš„æ¸ é“å
        if pd.isna(channel_name) or channel_name == '' or channel_name == 'nan':
            continue
            
        # å¤„ç†åç»­åˆ—çš„æ¸ é“å·
        for col_idx in range(1, len(row)):
            pid = row.iloc[col_idx]
            
            # å¤„ç†å„ç§å¯èƒ½çš„ç©ºå€¼è¡¨ç¤º
            if pd.isna(pid) or str(pid).strip() in ['', 'nan', 'ã€€', ' ']:
                continue
                
            pid_str = str(pid).strip()
            if pid_str:
                pid_to_channel[pid_str] = channel_name
    
    return pid_to_channel

# å®šä¹‰å¹‚å‡½æ•°ä¸æŒ‡æ•°å‡½æ•°
def power_function(x, a, b):
    """å¹‚å‡½æ•°ï¼šy = a * x^b"""
    return a * np.power(x, b)

def exponential_function(x, c, d):
    """æŒ‡æ•°å‡½æ•°ï¼šy = c * exp(d * x)"""
    return c * np.exp(d * x)

def calculate_retention_rates(df):
    """è®¡ç®—ç•™å­˜ç‡æ•°æ® - æ”¹è¿›ç‰ˆ"""
    retention_results = []
    
    # è·å–æ•°æ®æ¥æºåˆ—è¡¨
    data_sources = df['æ•°æ®æ¥æº'].unique()
    
    for source in data_sources:
        source_data = df[df['æ•°æ®æ¥æº'] == source].copy()
        
        # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—åŠ æƒå¹³å‡ç•™å­˜ç‡
        daily_retention = {}
        
        for _, row in source_data.iterrows():
            date = row['date']
            new_users = row.get('å›ä¼ æ–°å¢æ•°', 0)
            
            if pd.isna(new_users) or new_users <= 0:
                continue
            
            for day in range(1, 31):
                day_col = str(day)
                if day_col in row and not pd.isna(row[day_col]):
                    retain_count = row[day_col]
                    retention_rate = retain_count / new_users if new_users > 0 else 0
                    
                    if date not in daily_retention:
                        daily_retention[date] = {}
                    
                    daily_retention[date][day] = {
                        'rate': retention_rate,
                        'weight': new_users,
                        'retain_count': retain_count,
                        'new_users': new_users
                    }
        
        # è®¡ç®—æ•´ä½“åŠ æƒå¹³å‡ç•™å­˜ç‡
        overall_retention = {}
        for day in range(1, 31):
            total_weighted_rate = 0
            total_weight = 0
            
            for date in daily_retention:
                if day in daily_retention[date]:
                    rate = daily_retention[date][day]['rate']
                    weight = daily_retention[date][day]['weight']
                    total_weighted_rate += rate * weight
                    total_weight += weight
            
            if total_weight > 0:
                overall_retention[day] = total_weighted_rate / total_weight
            else:
                overall_retention[day] = 0
        
        retention_results.append({
            'data_source': source,
            'retention_rates': overall_retention,
            'daily_data': daily_retention
        })
    
    return retention_results

def fit_retention_curves_advanced(retention_results):
    """ä½¿ç”¨é«˜çº§æ‹Ÿåˆé€»è¾‘"""
    fitting_results = []
    
    for result in retention_results:
        source = result['data_source']
        retention_rates = result['retention_rates']
        
        # å‡†å¤‡æ‹Ÿåˆæ•°æ®
        days = []
        rates = []
        
        for day in range(1, 31):
            if day in retention_rates and retention_rates[day] > 0:
                days.append(day)
                rates.append(retention_rates[day])
        
        if len(days) < 3:
            # æ•°æ®ç‚¹å¤ªå°‘ï¼Œè·³è¿‡æ‹Ÿåˆ
            fitting_results.append({
                'data_source': source,
                'power_params': [1.0, -0.5],
                'power_r2': 0.0,
                'exp_params': [1.0, -0.1],
                'exp_r2': 0.0,
                'best_model': 'power',
                'days': days,
                'rates': rates,
                'fit_success': False
            })
            continue
        
        days_array = np.array(days)
        rates_array = np.array(rates)
        
        # å¹‚å‡½æ•°æ‹Ÿåˆ
        try:
            popt_power, _ = curve_fit(power_function, days_array, rates_array)
            power_pred = power_function(days_array, *popt_power)
            power_r2 = 1 - np.sum((rates_array - power_pred) ** 2) / np.sum((rates_array - np.mean(rates_array)) ** 2)
            power_success = True
        except Exception as e:
            st.warning(f"å¹‚å‡½æ•°æ‹Ÿåˆå¤±è´¥ {source}: {str(e)}")
            popt_power = [1.0, -0.5]
            power_r2 = 0.0
            power_success = False
        
        # æŒ‡æ•°å‡½æ•°æ‹Ÿåˆ
        try:
            initial_c = rates_array[0]
            initial_d = -0.001
            popt_exp, _ = curve_fit(
                exponential_function,
                days_array,
                rates_array,
                p0=[initial_c, initial_d],
                bounds=([0, -np.inf], [np.inf, 0])  # é™åˆ¶ d < 0
            )
            exp_pred = exponential_function(days_array, *popt_exp)
            exp_r2 = 1 - np.sum((rates_array - exp_pred) ** 2) / np.sum((rates_array - np.mean(rates_array)) ** 2)
            exp_success = True
        except Exception as e:
            st.warning(f"æŒ‡æ•°å‡½æ•°æ‹Ÿåˆå¤±è´¥ {source}: {str(e)}")
            popt_exp = [1.0, -0.1]
            exp_r2 = 0.0
            exp_success = False
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_model = 'power' if power_r2 >= exp_r2 else 'exponential'
        
        fitting_results.append({
            'data_source': source,
            'power_params': popt_power,
            'power_r2': max(0, min(1, power_r2)),
            'exp_params': popt_exp,
            'exp_r2': max(0, min(1, exp_r2)),
            'best_model': best_model,
            'days': days,
            'rates': rates,
            'fit_success': power_success or exp_success
        })
    
    return fitting_results

def calculate_lt_values_advanced(fitting_results, max_days=365):
    """ä½¿ç”¨æ”¹è¿›çš„LTè®¡ç®—æ–¹æ³•"""
    lt_results = []
    
    for result in fitting_results:
        source = result['data_source']
        best_model = result['best_model']
        
        if not result['fit_success']:
            # æ‹Ÿåˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            lt_value = 30.0  # é»˜è®¤LTå€¼
        else:
            if best_model == 'power':
                params = result['power_params']
                a, b = params
                
                # åˆ†é˜¶æ®µè®¡ç®—LT
                # ç¬¬ä¸€é˜¶æ®µï¼š1-30å¤©ï¼ˆä½¿ç”¨æ‹Ÿåˆå‚æ•°ï¼‰
                days_stage1 = np.arange(1, 31)
                rates_stage1 = power_function(days_stage1, a, b)
                lt_stage1 = np.sum(rates_stage1)
                
                # ç¬¬äºŒé˜¶æ®µï¼š31-120å¤©
                days_stage2 = np.arange(31, 121)
                rates_stage2 = power_function(days_stage2, a, b)
                lt_stage2 = np.sum(rates_stage2)
                
                # ç¬¬ä¸‰é˜¶æ®µï¼š121å¤©åˆ°max_daysï¼ˆæŒ‡æ•°è¡°å‡ï¼‰
                if max_days > 120:
                    days_stage3 = np.arange(121, max_days + 1)
                    # ä½¿ç”¨æŒ‡æ•°å‡½æ•°è¿›è¡Œé•¿æœŸé¢„æµ‹
                    try:
                        # åŸºäº120å¤©çš„ç•™å­˜ç‡å¼€å§‹æŒ‡æ•°è¡°å‡
                        base_rate = power_function(120, a, b)
                        decay_rate = -0.01  # è¡°å‡ç‡
                        rates_stage3 = base_rate * np.exp(decay_rate * (days_stage3 - 120))
                        lt_stage3 = np.sum(rates_stage3)
                    except:
                        lt_stage3 = 0
                else:
                    lt_stage3 = 0
                
                lt_value = 1.0 + lt_stage1 + lt_stage2 + lt_stage3
                
            else:  # exponential
                params = result['exp_params']
                c, d = params
                
                # æŒ‡æ•°å‡½æ•°ç§¯åˆ†
                if d != 0:
                    lt_value = 1.0 + (c / d) * (np.exp(d * max_days) - np.exp(d))
                else:
                    lt_value = 1.0 + c * (max_days - 1)
        
        # ç¡®ä¿LTå€¼ä¸ºæ­£æ•°ä¸”åˆç†
        lt_value = max(1.0, min(lt_value, max_days))
        
        lt_results.append({
            'data_source': source,
            'lt_value': lt_value,
            'model_used': best_model,
            'model_params': result[f'{best_model}_params'],
            'r2_score': result[f'{best_model}_r2'],
            'fit_success': result['fit_success']
        })
    
    return lt_results

def create_advanced_visualization(fitting_results, lt_results):
    """åˆ›å»ºé«˜çº§å¯è§†åŒ–å›¾è¡¨"""
    
    # 1. æ‹Ÿåˆæ•ˆæœæ¯”è¾ƒå›¾
    def create_fitting_comparison():
        n_sources = len(fitting_results)
        if n_sources == 0:
            return None
            
        n_cols = min(3, n_sources)
        n_rows = (n_sources + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows), squeeze=False)
        
        for i, result in enumerate(fitting_results):
            row = i // n_cols
            col = i % n_cols
            ax = axes[row, col]
            
            source = result['data_source']
            days = np.array(result['days'])
            rates = np.array(result['rates'])
            
            # åŸå§‹æ•°æ®ç‚¹
            ax.scatter(days, rates, color='red', s=50, alpha=0.7, label='å®é™…æ•°æ®')
            
            # æ‹Ÿåˆæ›²çº¿
            if result['fit_success']:
                x_fit = np.linspace(1, 30, 100)
                
                # ç»˜åˆ¶æœ€ä½³æ‹Ÿåˆæ›²çº¿
                if result['best_model'] == 'power':
                    y_fit = power_function(x_fit, *result['power_params'])
                    model_name = f"å¹‚å‡½æ•° (RÂ²={result['power_r2']:.3f})"
                else:
                    y_fit = exponential_function(x_fit, *result['exp_params'])
                    model_name = f"æŒ‡æ•°å‡½æ•° (RÂ²={result['exp_r2']:.3f})"
                
                ax.plot(x_fit, y_fit, color='blue', linewidth=2, label=model_name)
            
            ax.set_title(f'{source}')
            ax.set_xlabel('å¤©æ•°')
            ax.set_ylabel('ç•™å­˜ç‡')
            ax.grid(True, alpha=0.3)
            ax.legend()
            ax.set_ylim(0, max(rates) * 1.1 if len(rates) > 0 else 1)
        
        # éšè—æœªä½¿ç”¨çš„å­å›¾
        for i in range(n_sources, n_rows * n_cols):
            row = i // n_cols
            col = i % n_cols
            fig.delaxes(axes[row, col])
        
        plt.tight_layout()
        return fig
    
    # 2. LTå€¼å¯¹æ¯”å›¾
    def create_lt_comparison():
        if not lt_results:
            return None
            
        # æŒ‰LTå€¼æ’åº
        sorted_results = sorted(lt_results, key=lambda x: x['lt_value'])
        
        sources = [r['data_source'] for r in sorted_results]
        lt_values = [r['lt_value'] for r in sorted_results]
        
        fig, ax = plt.subplots(figsize=(12, 8))
        
        colors = plt.cm.viridis(np.linspace(0, 1, len(sources)))
        bars = ax.bar(sources, lt_values, color=colors, alpha=0.8)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, lt_values):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{value:.1f}', ha='center', va='bottom', fontweight='bold')
        
        ax.set_xlabel('æ•°æ®æ¥æº')
        ax.set_ylabel('LTå€¼')
        ax.set_title('å„æ¸ é“LTå€¼å¯¹æ¯”')
        ax.tick_params(axis='x', rotation=45)
        ax.grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        return fig
    
    # 3. ç»¼åˆç•™å­˜æ›²çº¿å›¾
    def create_retention_curves():
        if not fitting_results:
            return None
            
        fig, ax = plt.subplots(figsize=(14, 8))
        
        colors = plt.cm.tab10.colors
        
        for i, result in enumerate(fitting_results):
            if not result['fit_success']:
                continue
                
            source = result['data_source']
            color = colors[i % len(colors)]
            
            # ç”Ÿæˆå®Œæ•´çš„ç•™å­˜æ›²çº¿ï¼ˆ1-100å¤©ï¼‰
            x_curve = np.arange(1, 101)
            
            if result['best_model'] == 'power':
                y_curve = power_function(x_curve, *result['power_params'])
            else:
                y_curve = exponential_function(x_curve, *result['exp_params'])
            
            # æ‰¾åˆ°å¯¹åº”çš„LTå€¼
            lt_value = next((r['lt_value'] for r in lt_results if r['data_source'] == source), 0)
            
            ax.plot(x_curve, y_curve, color=color, linewidth=2, 
                   label=f'{source} (LT={lt_value:.1f})')
        
        ax.set_xlabel('å¤©æ•°')
        ax.set_ylabel('ç•™å­˜ç‡')
        ax.set_title('å„æ¸ é“ç•™å­˜æ›²çº¿å¯¹æ¯”')
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.grid(True, alpha=0.3)
        ax.set_xlim(1, 100)
        
        plt.tight_layout()
        return fig
    
    return {
        'fitting_comparison': create_fitting_comparison(),
        'lt_comparison': create_lt_comparison(),
        'retention_curves': create_retention_curves()
    }

# é¡µé¢å†…å®¹
if page == "æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»":
    st.header("æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»")
    
    # æ¸ é“æ˜ å°„é…ç½®
    with st.expander("æ¸ é“æ˜ å°„é…ç½®", expanded=False):
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.markdown("### å½“å‰é…ç½®çŠ¶æ€")
            if st.session_state.channel_mapping:
                st.success(f"å·²é…ç½® {len(st.session_state.channel_mapping)} ä¸ªæ¸ é“æ˜ å°„")
                st.info("æ­£åœ¨ä½¿ç”¨é»˜è®¤æ¸ é“æ˜ å°„è¡¨")
            else:
                st.warning("æœªé…ç½®æ¸ é“æ˜ å°„")
        
        with col2:
            if st.session_state.channel_mapping:
                st.markdown("### æ¸ é“æ˜ å°„ç¤ºä¾‹")
                # æŒ‰æ¸ é“ååˆ†ç»„æ˜¾ç¤º
                mapping_by_channel = {}
                for pid, channel in st.session_state.channel_mapping.items():
                    if channel not in mapping_by_channel:
                        mapping_by_channel[channel] = []
                    mapping_by_channel[channel].append(pid)
                
                # æ˜¾ç¤ºå‰5ä¸ªæ¸ é“æ˜ å°„
                count = 0
                for channel, pids in list(mapping_by_channel.items())[:5]:
                    st.code(f"{channel}: {', '.join(pids[:3])}{'...' if len(pids) > 3 else ''}")
                    count += 1
                
                if len(mapping_by_channel) > 5:
                    st.text(f"... è¿˜æœ‰ {len(mapping_by_channel) - 5} ä¸ªæ¸ é“")
        
        # è‡ªå®šä¹‰æ¸ é“æ˜ å°„æ–‡ä»¶ä¸Šä¼ 
        st.markdown("### ä¸Šä¼ è‡ªå®šä¹‰æ¸ é“æ˜ å°„è¡¨")
        channel_file = st.file_uploader(
            "é€‰æ‹©æ¸ é“æ˜ å°„æ–‡ä»¶ (å¯é€‰)",
            type=['xlsx', 'xls'],
            help="ç¬¬ä¸€åˆ—ä¸ºæ¸ é“åï¼Œåç»­åˆ—ä¸ºå¯¹åº”çš„æ¸ é“å·ã€‚å¦‚ä¸ä¸Šä¼ å°†ä½¿ç”¨é»˜è®¤æ˜ å°„è¡¨"
        )
        
        if channel_file:
            try:
                channel_df = pd.read_excel(channel_file)
                custom_mapping = parse_channel_mapping(channel_df)
                st.session_state.channel_mapping = custom_mapping
                st.success(f"è‡ªå®šä¹‰æ¸ é“æ˜ å°„å·²åŠ è½½ï¼Œå…± {len(custom_mapping)} ä¸ªæ˜ å°„")
                st.dataframe(channel_df.head(), use_container_width=True)
            except Exception as e:
                st.error(f"æ¸ é“æ˜ å°„æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
    
    # æ•°æ®æ–‡ä»¶ä¸Šä¼ 
    st.subheader("æ•°æ®æ–‡ä»¶å¤„ç†")
    
    uploaded_files = st.file_uploader(
        "é€‰æ‹©Excelæ•°æ®æ–‡ä»¶",
        type=['xlsx', 'xls'],
        accept_multiple_files=True,
        help="æ”¯æŒä¸Šä¼ å¤šä¸ªExcelæ–‡ä»¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è§£æç•™å­˜æ•°æ®ï¼Œæ”¯æŒæ–°æ—§ä¸¤ç§æ•°æ®æ ¼å¼"
    )
    
    # ç›®æ ‡æœˆä»½é€‰æ‹©
    default_month = get_default_target_month()
    target_month = st.text_input(
        "ç›®æ ‡æœˆä»½ (YYYY-MM)",
        value=default_month,
        help=f"å½“å‰é»˜è®¤ä¸º2ä¸ªæœˆå‰: {default_month}"
    )
    
    # ä»…åœ¨æœ‰æ–‡ä»¶æ—¶æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯å’Œå¤„ç†æŒ‰é’®
    if uploaded_files:
        # æ˜¾ç¤ºæ–‡ä»¶çŠ¶æ€
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼š{', '.join([f.name for f in uploaded_files])}")
        
        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹å¤„ç†æ•°æ®", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®æ–‡ä»¶..."):
                try:
                    # å¤„ç†æ•°æ®æ–‡ä»¶
                    merged_data, processed_count, mapping_warnings = integrate_excel_files_streamlit(
                        uploaded_files, target_month, st.session_state.channel_mapping
                    )
                    
                    if merged_data is not None and not merged_data.empty:
                        st.session_state.merged_data = merged_data
                        
                        st.success(f"æ•°æ®å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {processed_count} ä¸ªæ–‡ä»¶")
                        
                        # æ˜¾ç¤ºæ¸ é“æ˜ å°„è­¦å‘Šï¼ˆå¦‚æœæœ‰ï¼‰
                        if mapping_warnings:
                            st.warning("æ¸ é“æ˜ å°„æç¤º:")
                            for warning in mapping_warnings:
                                st.write(f"â€¢ {warning}")
                            st.info("è¿™ä¸ä¼šå½±å“åç»­çš„ç•™å­˜ç‡è®¡ç®—å’Œæ‹Ÿåˆåˆ†æ")
                        
                        # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
                        st.subheader("æ•°æ®æ¦‚è§ˆ")
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                            st.markdown(f'<div class="metric-value">{len(merged_data):,}</div>', unsafe_allow_html=True)
                            st.markdown('<div class="metric-label">æ€»è®°å½•æ•°</div>', unsafe_allow_html=True)
                            st.markdown('</div>', unsafe_allow_html=True)
                        
                        with col2:
                            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                            st.markdown(f'<div class="metric-value">{merged_data["æ•°æ®æ¥æº"].nunique()}</div>', unsafe_allow_html=True)
                            st.markdown('<div class="metric-label">æ•°æ®æ¥æº</div>', unsafe_allow_html=True)
                            st.markdown('</div>', unsafe_allow_html=True)
                        
                        with col3:
                            total_new_users = merged_data['å›ä¼ æ–°å¢æ•°'].sum()
                            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                            st.markdown(f'<div class="metric-value">{total_new_users:,.0f}</div>', unsafe_allow_html=True)
                            st.markdown('<div class="metric-label">æ€»æ–°å¢ç”¨æˆ·</div>', unsafe_allow_html=True)
                            st.markdown('</div>', unsafe_allow_html=True)
                        
                        with col4:
                            date_range = f"{merged_data['date'].min()} è‡³ {merged_data['date'].max()}"
                            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                            st.markdown('<div class="metric-value">æ—¥æœŸ</div>', unsafe_allow_html=True)
                            st.markdown(f'<div class="metric-label">{date_range}</div>', unsafe_allow_html=True)
                            st.markdown('</div>', unsafe_allow_html=True)
                        
                        # æ•°æ®é¢„è§ˆ
                        st.subheader("æ•°æ®é¢„è§ˆ")
                        st.dataframe(merged_data.head(10), use_container_width=True)
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    else:
                        st.error("æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œç›®æ ‡æœˆä»½è®¾ç½®")
                
                except Exception as e:
                    st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")
    else:
        st.info("è¯·é€‰æ‹©Excelæ–‡ä»¶å¼€å§‹æ•°æ®å¤„ç†")

elif page == "å¼‚å¸¸æ•°æ®å‰”é™¤":
    st.header("å¼‚å¸¸æ•°æ®å‰”é™¤")
    
    if st.session_state.merged_data is None:
        st.warning("è¯·å…ˆåœ¨ã€Œæ•°æ®ä¸Šä¼ ä¸æ±‡æ€»ã€é¡µé¢å¤„ç†æ•°æ®")
        if st.button("è¿”å›æ•°æ®ä¸Šä¼ é¡µé¢"):
            st.session_state.current_step = 0
            st.rerun()
    else:
        merged_data = st.session_state.merged_data
        
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("å¼‚å¸¸æ•°æ®è¯†åˆ«ä¸å‰”é™¤")
        
        # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
        st.markdown("### æ•°æ®æ¦‚è§ˆ")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»è®°å½•æ•°", f"{len(merged_data):,}")
        with col2:
            st.metric("æ•°æ®æ¥æºæ•°", merged_data['æ•°æ®æ¥æº'].nunique())
        with col3:
            st.metric("å·²å‰”é™¤è®°å½•", len(st.session_state.excluded_data))
        
        # æ•°æ®é¢„è§ˆ
        st.markdown("### æ•°æ®é¢„è§ˆ")
        display_cols = ['æ•°æ®æ¥æº', 'date', 'å›ä¼ æ–°å¢æ•°', '1', '7', '15', '30']
        available_cols = [col for col in display_cols if col in merged_data.columns]
        st.dataframe(merged_data[available_cols].head(8), use_container_width=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # å¼‚å¸¸æ•°æ®å‰”é™¤ç•Œé¢
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("é€‰æ‹©è¦å‰”é™¤çš„æ•°æ®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### æŒ‰æ•°æ®æ¥æºå‰”é™¤")
            
            # æ•°æ®æ¥æºé€‰æ‹©
            all_sources = merged_data['æ•°æ®æ¥æº'].unique().tolist()
            excluded_sources = st.multiselect(
                "é€‰æ‹©è¦å‰”é™¤çš„æ•°æ®æ¥æº",
                options=all_sources,
                help="é€‰ä¸­çš„æ•°æ®æ¥æºå°†è¢«å®Œå…¨æ’é™¤åœ¨ç•™å­˜ç‡è®¡ç®—ä¹‹å¤–"
            )
            
            # æ˜¾ç¤ºé€‰ä¸­æ¥æºçš„ç»Ÿè®¡ä¿¡æ¯
            if excluded_sources:
                excluded_by_source = merged_data[merged_data['æ•°æ®æ¥æº'].isin(excluded_sources)]
                st.info(f"å°†å‰”é™¤ {len(excluded_by_source)} æ¡è®°å½•")
        
        with col2:
            st.markdown("### æŒ‰æ—¥æœŸå‰”é™¤")
            
            # æ—¥æœŸé€‰æ‹©
            all_dates = sorted(merged_data['date'].unique().tolist())
            excluded_dates = st.multiselect(
                "é€‰æ‹©è¦å‰”é™¤çš„æ—¥æœŸ",
                options=all_dates,
                help="é€‰ä¸­æ—¥æœŸçš„æ‰€æœ‰æ•°æ®å°†è¢«æ’é™¤åœ¨ç•™å­˜ç‡è®¡ç®—ä¹‹å¤–"
            )
            
            # æ˜¾ç¤ºé€‰ä¸­æ—¥æœŸçš„ç»Ÿè®¡ä¿¡æ¯
            if excluded_dates:
                excluded_by_date = merged_data[merged_data['date'].isin(excluded_dates)]
                st.info(f"å°†å‰”é™¤ {len(excluded_by_date)} æ¡è®°å½•")
        
        # ç»„åˆå‰”é™¤æ¡ä»¶
        st.markdown("### æŒ‰å…·ä½“æ¡ä»¶å‰”é™¤")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # æ–°å¢ç”¨æˆ·æ•°é˜ˆå€¼
            min_new_users = st.number_input(
                "æœ€å°æ–°å¢ç”¨æˆ·æ•°",
                min_value=0,
                value=0,
                help="ä½äºæ­¤å€¼çš„è®°å½•å°†è¢«å‰”é™¤"
            )
        
        with col2:
            # ç•™å­˜ç‡å¼‚å¸¸æ£€æµ‹
            max_day1_retention = st.number_input(
                "Day1æœ€å¤§ç•™å­˜ç‡",
                min_value=0.0,
                max_value=2.0,
                value=1.5,
                step=0.1,
                help="Day1ç•™å­˜ç‡è¶…è¿‡æ­¤å€¼çš„è®°å½•å°†è¢«å‰”é™¤ï¼ˆå¯èƒ½æ˜¯æ•°æ®é”™è¯¯ï¼‰"
            )
        
        with col3:
            # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
            min_retention_days = st.number_input(
                "æœ€å°‘ç•™å­˜å¤©æ•°",
                min_value=1,
                max_value=30,
                value=7,
                help="ç•™å­˜æ•°æ®å°‘äºæ­¤å¤©æ•°çš„è®°å½•å°†è¢«å‰”é™¤"
            )
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # é¢„è§ˆå°†è¢«å‰”é™¤çš„æ•°æ®
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("å‰”é™¤é¢„è§ˆ")
        
        # è®¡ç®—æ‰€æœ‰å‰”é™¤æ¡ä»¶
        exclusion_mask = pd.Series([False] * len(merged_data), index=merged_data.index)
        
        # æŒ‰æ•°æ®æ¥æºå‰”é™¤
        if excluded_sources:
            source_mask = merged_data['æ•°æ®æ¥æº'].isin(excluded_sources)
            exclusion_mask |= source_mask
        
        # æŒ‰æ—¥æœŸå‰”é™¤
        if excluded_dates:
            date_mask = merged_data['date'].isin(excluded_dates)
            exclusion_mask |= date_mask
        
        # æŒ‰æ–°å¢ç”¨æˆ·æ•°å‰”é™¤
        if min_new_users > 0:
            users_mask = merged_data['å›ä¼ æ–°å¢æ•°'] < min_new_users
            exclusion_mask |= users_mask
        
        # æŒ‰Day1ç•™å­˜ç‡å‰”é™¤
        if '1' in merged_data.columns:
            day1_retention = merged_data['1'] / merged_data['å›ä¼ æ–°å¢æ•°']
            retention_mask = day1_retention > max_day1_retention
            exclusion_mask |= retention_mask
        
        # æŒ‰æ•°æ®å®Œæ•´æ€§å‰”é™¤
        retention_cols = [str(i) for i in range(1, min(31, min_retention_days + 1)) if str(i) in merged_data.columns]
        if retention_cols:
            completeness_mask = merged_data[retention_cols].isna().sum(axis=1) > (len(retention_cols) - min_retention_days)
            exclusion_mask |= completeness_mask
        
        # æ˜¾ç¤ºé¢„è§ˆ
        to_exclude = merged_data[exclusion_mask]
        to_keep = merged_data[~exclusion_mask]
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### å°†è¢«å‰”é™¤çš„æ•°æ®")
            st.markdown(f"**æ•°é‡:** {len(to_exclude)} æ¡")
            if len(to_exclude) > 0:
                st.dataframe(to_exclude[available_cols].head(10), use_container_width=True)
        
        with col2:
            st.markdown("### ä¿ç•™çš„æ•°æ®")
            st.markdown(f"**æ•°é‡:** {len(to_keep)} æ¡")
            if len(to_keep) > 0:
                st.dataframe(to_keep[available_cols].head(10), use_container_width=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # ç¡®è®¤å‰”é™¤
        if st.button("ç¡®è®¤å‰”é™¤å¼‚å¸¸æ•°æ®", type="primary", use_container_width=True):
            if len(to_exclude) > 0:
                # ä¿å­˜å‰”é™¤çš„æ•°æ®è®°å½•
                excluded_records = []
                for _, row in to_exclude.iterrows():
                    excluded_records.append(f"{row['æ•°æ®æ¥æº']} - {row['date']}")
                
                st.session_state.excluded_data = excluded_records
                st.session_state.cleaned_data = to_keep.copy()
                
                st.success(f"æˆåŠŸå‰”é™¤ {len(to_exclude)} æ¡å¼‚å¸¸æ•°æ®ï¼Œä¿ç•™ {len(to_keep)} æ¡æœ‰æ•ˆæ•°æ®")
                
                # æ˜¾ç¤ºæ¸…ç†åçš„æ•°æ®æ¦‚è§ˆ
                st.markdown('<div class="glass-card">', unsafe_allow_html=True)
                st.subheader("æ¸…ç†åæ•°æ®æ¦‚è§ˆ")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                    st.markdown(f'<div class="metric-value">{len(to_keep):,}</div>', unsafe_allow_html=True)
                    st.markdown('<div class="metric-label">æœ‰æ•ˆè®°å½•æ•°</div>', unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True)
                
                with col2:
                    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                    st.markdown(f'<div class="metric-value">{to_keep["æ•°æ®æ¥æº"].nunique()}</div>', unsafe_allow_html=True)
                    st.markdown('<div class="metric-label">æ•°æ®æ¥æº</div>', unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True)
                
                with col3:
                    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                    st.markdown(f'<div class="metric-value">{len(to_exclude):,}</div>', unsafe_allow_html=True)
                    st.markdown('<div class="metric-label">å‰”é™¤è®°å½•æ•°</div>', unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True)
                
                with col4:
                    retention_rate = len(to_keep) / len(merged_data) * 100
                    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                    st.markdown(f'<div class="metric-value">{retention_rate:.1f}%</div>', unsafe_allow_html=True)
                    st.markdown('<div class="metric-label">æ•°æ®ä¿ç•™ç‡</div>', unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True)
                
                st.markdown('</div>', unsafe_allow_html=True)
                
            else:
                st.session_state.cleaned_data = merged_data.copy()
                st.info("æœªå‘ç°éœ€è¦å‰”é™¤çš„å¼‚å¸¸æ•°æ®ï¼Œæ‰€æœ‰æ•°æ®å°†ä¿ç•™")

elif page == "ç•™å­˜ç‡è®¡ç®—":
    st.header("ç•™å­˜ç‡è®¡ç®—")
    
    # ç¡®å®šä½¿ç”¨çš„æ•°æ®æº
    if st.session_state.cleaned_data is not None:
        working_data = st.session_state.cleaned_data
        data_source_info = "ä½¿ç”¨æ¸…ç†åçš„æ•°æ®"
    elif st.session_state.merged_data is not None:
        working_data = st.session_state.merged_data
        data_source_info = "ä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆæœªè¿›è¡Œå¼‚å¸¸æ•°æ®å‰”é™¤ï¼‰"
    else:
        working_data = None
        data_source_info = "æ— å¯ç”¨æ•°æ®"
    
    if working_data is None:
        st.warning("è¯·å…ˆå®Œæˆå‰é¢çš„æ­¥éª¤ä»¥è·å–æ•°æ®")
        if st.button("è¿”å›æ•°æ®ä¸Šä¼ é¡µé¢"):
            st.session_state.current_step = 0
            st.rerun()
    else:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("ç•™å­˜ç‡åˆ†æé…ç½®")
        st.info(data_source_info)
        
        # æ•°æ®æ¥æºé€‰æ‹©
        data_sources = working_data['æ•°æ®æ¥æº'].unique()
        selected_sources = st.multiselect(
            "é€‰æ‹©è¦åˆ†æçš„æ•°æ®æ¥æº",
            options=data_sources,
            default=data_sources,
            help="å¯ä»¥é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®æ¥æºè¿›è¡Œåˆ†æ"
        )
        
        # ç®€åŒ–çŠ¶æ€ä¿¡æ¯æ˜¾ç¤º
        if selected_sources:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ•°æ®æ¥æº", len(selected_sources))
            with col2:
                st.metric("æ€»è®°å½•æ•°", f"{len(working_data):,}")
            with col3:
                st.metric("åˆ†æå¤©æ•°", "1-30å¤©")
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        if st.button("è®¡ç®—ç•™å­˜ç‡", type="primary", use_container_width=True):
            if selected_sources:
                with st.spinner("æ­£åœ¨è®¡ç®—ç•™å­˜ç‡..."):
                    # è¿‡æ»¤é€‰ä¸­çš„æ•°æ®æ¥æº
                    filtered_data = working_data[working_data['æ•°æ®æ¥æº'].isin(selected_sources)]
                    
                    # è®¡ç®—ç•™å­˜ç‡
                    retention_results = calculate_retention_rates(filtered_data)
                    st.session_state.retention_data = retention_results
                    
                    st.success("ç•™å­˜ç‡è®¡ç®—å®Œæˆï¼")
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
                    st.subheader("ç•™å­˜ç‡ç»“æœ")
                    
                    for result in retention_results:
                        with st.expander(f"{result['data_source']} - ç•™å­˜ç‡è¯¦æƒ…", expanded=True):
                            retention_rates = result['retention_rates']
                            
                            # åˆ›å»ºç•™å­˜ç‡è¡¨æ ¼
                            days = list(range(1, 31))
                            rates = [retention_rates.get(day, 0) for day in days]
                            
                            col1, col2 = st.columns([1, 2])
                            
                            with col1:
                                # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                                valid_rates = [r for r in rates if r > 0]
                                if valid_rates:
                                    st.markdown("### å…³é”®æŒ‡æ ‡")
                                    st.metric("Day 1 ç•™å­˜ç‡", f"{rates[0]*100:.2f}%")
                                    st.metric("Day 7 ç•™å­˜ç‡", f"{rates[6]*100:.2f}%" if len(rates) > 6 else "N/A")
                                    st.metric("Day 30 ç•™å­˜ç‡", f"{rates[29]*100:.2f}%" if len(rates) > 29 else "N/A")
                                    st.metric("å¹³å‡ç•™å­˜ç‡", f"{np.mean(valid_rates)*100:.2f}%")
                            
                            with col2:
                                # ç»˜åˆ¶ç•™å­˜ç‡æ›²çº¿
                                valid_days = [d for d, r in zip(days, rates) if r > 0]
                                valid_rates = [r for r in rates if r > 0]
                                
                                if valid_days:
                                    fig, ax = plt.subplots(figsize=(12, 6))
                                    
                                    # ä½¿ç”¨æ¸å˜è‰²
                                    colors = plt.cm.viridis(np.linspace(0, 1, len(valid_days)))
                                    scatter = ax.scatter(valid_days, valid_rates, 
                                                       c=colors, s=80, alpha=0.8, edgecolors='white', linewidth=2)
                                    ax.plot(valid_days, valid_rates, '--', color='#667eea', linewidth=2, alpha=0.7)
                                    
                                    ax.set_xlabel('å¤©æ•°', fontsize=12, fontweight='bold')
                                    ax.set_ylabel('ç•™å­˜ç‡', fontsize=12, fontweight='bold')
                                    ax.set_title(f'{result["data_source"]} ç•™å­˜ç‡æ›²çº¿', fontsize=14, fontweight='bold')
                                    ax.grid(True, alpha=0.3, linestyle='--')
                                    ax.set_ylim(0, max(valid_rates) * 1.1)
                                    
                                    # ç¾åŒ–å›¾è¡¨
                                    ax.spines['top'].set_visible(False)
                                    ax.spines['right'].set_visible(False)
                                    ax.spines['left'].set_linewidth(0.5)
                                    ax.spines['bottom'].set_linewidth(0.5)
                                    
                                    plt.tight_layout()
                                    st.pyplot(fig)
                                    plt.close()
                    
                    st.markdown('</div>', unsafe_allow_html=True)
            else:
                st.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ•°æ®æ¥æº")

elif page == "LTæ‹Ÿåˆåˆ†æ":
    st.header("LTæ‹Ÿåˆåˆ†æ")
    
    if st.session_state.retention_data is None:
        st.warning("è¯·å…ˆåœ¨ã€Œç•™å­˜ç‡è®¡ç®—ã€é¡µé¢è®¡ç®—ç•™å­˜ç‡")
        if st.button("è¿”å›ç•™å­˜ç‡è®¡ç®—é¡µé¢"):
            st.session_state.current_step = 2
            st.rerun()
    else:
        retention_data = st.session_state.retention_data
        
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("æ›²çº¿æ‹Ÿåˆå‚æ•°è®¾ç½®")
        
        st.info("ç³»ç»Ÿå°†è‡ªåŠ¨ä½¿ç”¨å¹‚å‡½æ•°å’ŒæŒ‡æ•°å‡½æ•°è¿›è¡Œæ‹Ÿåˆï¼Œå¹¶é€‰æ‹©æ‹Ÿåˆåº¦æœ€å¥½çš„æ–¹æ³•")
        
        col1, col2 = st.columns(2)
        with col1:
            max_days = st.number_input(
                "LTè®¡ç®—å¤©æ•°èŒƒå›´",
                min_value=30,
                max_value=1000,
                value=365,
                help="è®¾ç½®è®¡ç®—ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸçš„å¤©æ•°èŒƒå›´"
            )
        
        with col2:
            st.metric("æ•°æ®æ¥æº", len(retention_data))
            st.metric("LTå¤©æ•°", max_days)
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        if st.button("å¼€å§‹æ‹Ÿåˆåˆ†æ", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨è¿›è¡Œæ›²çº¿æ‹Ÿåˆ..."):
                # æ‰§è¡Œæ‹Ÿåˆåˆ†æ
                fitting_results = fit_retention_curves_advanced(retention_data)
                
                # è®¡ç®—LTå€¼
                lt_results = calculate_lt_values_advanced(fitting_results, max_days)
                st.session_state.lt_results = lt_results
                
                st.success("æ‹Ÿåˆåˆ†æå®Œæˆï¼")
                
                # åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
                visualizations = create_advanced_visualization(fitting_results, lt_results)
                
                # æ˜¾ç¤ºæ‹Ÿåˆç»“æœ
                st.markdown('<div class="glass-card">', unsafe_allow_html=True)
                st.subheader("æ‹Ÿåˆç»“æœæ¦‚è§ˆ")
                
                # åˆ›å»ºç»“æœæ±‡æ€»è¡¨
                summary_data = []
                for i, result in enumerate(fitting_results):
                    lt_info = lt_results[i]
                    summary_data.append({
                        'æ•°æ®æ¥æº': result['data_source'],
                        'æœ€ä½³æ¨¡å‹': result['best_model'].replace('power', 'å¹‚å‡½æ•°').replace('exponential', 'æŒ‡æ•°å‡½æ•°'),
                        'RÂ²å¾—åˆ†': f"{result[result['best_model'] + '_r2']:.4f}",
                        'LTå€¼': f"{lt_info['lt_value']:.2f}",
                        'æ‹ŸåˆçŠ¶æ€': 'æˆåŠŸ' if result['fit_success'] else 'å¤±è´¥'
                    })
                
                summary_df = pd.DataFrame(summary_data)
                st.dataframe(summary_df, use_container_width=True)
                st.markdown('</div>', unsafe_allow_html=True)
                
                # æ˜¾ç¤ºå¯è§†åŒ–å›¾è¡¨
                if visualizations['fitting_comparison']:
                    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
                    st.subheader("æ‹Ÿåˆæ•ˆæœå¯¹æ¯”")
                    st.pyplot(visualizations['fitting_comparison'])
                    plt.close()
                    st.markdown('</div>', unsafe_allow_html=True)
                
                if visualizations['retention_curves']:
                    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
                    st.subheader("ç•™å­˜æ›²çº¿å¯¹æ¯”")
                    st.pyplot(visualizations['retention_curves'])
                    plt.close()
                    st.markdown('</div>', unsafe_allow_html=True)
                
                if visualizations['lt_comparison']:
                    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
                    st.subheader("LTå€¼å¯¹æ¯”")
                    st.pyplot(visualizations['lt_comparison'])
                    plt.close()
                    st.markdown('</div>', unsafe_allow_html=True)

elif page == "ARPUè®¡ç®—":
    st.header("ARPUè®¡ç®—")
    
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.subheader("ä¸Šä¼ ARPUæ•°æ®")
    
    # ARPUæ•°æ®ä¸Šä¼ 
    arpu_file = st.file_uploader(
        "é€‰æ‹©ARPUæ•°æ®æ–‡ä»¶",
        type=['xlsx', 'xls'],
        help="ä¸Šä¼ åŒ…å«ç”¨æˆ·ä»˜è´¹æ•°æ®çš„Excelæ–‡ä»¶"
    )
    
    if arpu_file:
        try:
            # è¯»å–ARPUæ–‡ä»¶
            arpu_df = pd.read_excel(arpu_file)
            st.success("ARPUæ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
            
            # æ˜¾ç¤ºæ–‡ä»¶é¢„è§ˆ
            st.subheader("æ•°æ®é¢„è§ˆ")
            st.dataframe(arpu_df.head(10), use_container_width=True)
            
            # æ•°æ®åˆ—é€‰æ‹©
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("æ•°æ®åˆ—æ˜ å°„")
                
                # è®©ç”¨æˆ·é€‰æ‹©å…³é”®åˆ—
                source_col = st.selectbox(
                    "æ•°æ®æ¥æºåˆ—",
                    options=arpu_df.columns,
                    help="é€‰æ‹©æ ‡è¯†æ•°æ®æ¥æºçš„åˆ—"
                )
                
                arpu_col = st.selectbox(
                    "ARPUå€¼åˆ—",
                    options=arpu_df.columns,
                    help="é€‰æ‹©åŒ…å«ARPUå€¼çš„åˆ—"
                )
                
                date_col = st.selectbox(
                    "æ—¥æœŸåˆ— (å¯é€‰)",
                    options=['æ— '] + list(arpu_df.columns),
                    help="å¦‚æœæœ‰æ—¥æœŸåˆ—ï¼Œè¯·é€‰æ‹©"
                )
            
            with col2:
                st.subheader("æ•°æ®ç»Ÿè®¡")
                
                # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡
                if arpu_col in arpu_df.columns:
                    arpu_values = pd.to_numeric(arpu_df[arpu_col], errors='coerce')
                    
                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.metric("å¹³å‡ARPU", f"{arpu_values.mean():.2f}")
                        st.metric("æœ€å°å€¼", f"{arpu_values.min():.2f}")
                    with col_b:
                        st.metric("æœ€å¤§å€¼", f"{arpu_values.max():.2f}")
                        st.metric("æœ‰æ•ˆè®°å½•", f"{arpu_values.notna().sum():,}")
            
            # å¤„ç†ARPUæ•°æ®
            if st.button("ä¿å­˜ARPUæ•°æ®", type="primary", use_container_width=True):
                try:
                    # æ ‡å‡†åŒ–ARPUæ•°æ®
                    processed_arpu = arpu_df.copy()
                    processed_arpu['data_source'] = processed_arpu[source_col]
                    processed_arpu['arpu_value'] = pd.to_numeric(processed_arpu[arpu_col], errors='coerce')
                    
                    if date_col != 'æ— ':
                        processed_arpu['date'] = processed_arpu[date_col]
                    
                    # æŒ‰æ•°æ®æ¥æºæ±‡æ€»ARPU
                    arpu_summary = processed_arpu.groupby('data_source')['arpu_value'].mean().reset_index()
                    
                    st.session_state.arpu_data = arpu_summary
                    
                    st.success("ARPUæ•°æ®å¤„ç†å®Œæˆï¼")
                    
                    # æ˜¾ç¤ºæ±‡æ€»ç»“æœ
                    st.subheader("ARPUæ±‡æ€»ç»“æœ")
                    st.dataframe(arpu_summary, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"ARPUæ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")
        
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
    
    else:
        st.info("è¯·ä¸Šä¼ ARPUæ•°æ®æ–‡ä»¶")
        
        # å¦‚æœæ²¡æœ‰ARPUæ•°æ®ï¼Œæä¾›æ‰‹åŠ¨è¾“å…¥é€‰é¡¹
        st.subheader("æ‰‹åŠ¨è®¾ç½®ARPU")
        
        if st.session_state.lt_results:
            # åŸºäºå·²æœ‰çš„LTç»“æœåˆ›å»ºARPUè¾“å…¥
            st.write("ä¸ºæ¯ä¸ªæ•°æ®æ¥æºè®¾ç½®ARPUå€¼ï¼š")
            
            arpu_inputs = {}
            for result in st.session_state.lt_results:
                source = result['data_source']
                arpu_value = st.number_input(
                    f"{source} ARPU",
                    min_value=0.0,
                    value=10.0,
                    step=0.01,
                    format="%.2f"
                )
                arpu_inputs[source] = arpu_value
            
            if st.button("ä¿å­˜æ‰‹åŠ¨ARPUè®¾ç½®", type="primary", use_container_width=True):
                # åˆ›å»ºARPUæ•°æ®æ¡†
                arpu_df = pd.DataFrame([
                    {'data_source': source, 'arpu_value': value} 
                    for source, value in arpu_inputs.items()
                ])
                
                st.session_state.arpu_data = arpu_df
                st.success("ARPUè®¾ç½®å·²ä¿å­˜ï¼")
                st.dataframe(arpu_df, use_container_width=True)
        
        else:
            st.warning("è¯·å…ˆå®ŒæˆLTæ‹Ÿåˆåˆ†æï¼Œç„¶åå†è®¾ç½®ARPU")
    
    st.markdown('</div>', unsafe_allow_html=True)

elif page == "LTVç»“æœæŠ¥å‘Š":
    st.header("LTVç»“æœæŠ¥å‘Š")
    
    # æ£€æŸ¥å¿…è¦æ•°æ®æ˜¯å¦å­˜åœ¨
    if st.session_state.lt_results is None:
        st.warning("è¯·å…ˆå®ŒæˆLTæ‹Ÿåˆåˆ†æ")
        if st.button("è·³è½¬åˆ°LTæ‹Ÿåˆåˆ†æ"):
            st.session_state.current_step = 3
            st.rerun()
    elif st.session_state.arpu_data is None:
        st.warning("è¯·å…ˆå®ŒæˆARPUè®¡ç®—")
        if st.button("è·³è½¬åˆ°ARPUè®¡ç®—"):
            st.session_state.current_step = 4
            st.rerun()
    else:
        # è®¡ç®—LTV
        lt_results = st.session_state.lt_results
        arpu_data = st.session_state.arpu_data
        
        # åˆå¹¶LTå’ŒARPUæ•°æ®
        ltv_results = []
        
        for lt_result in lt_results:
            source = lt_result['data_source']
            lt_value = lt_result['lt_value']
            
            # æŸ¥æ‰¾å¯¹åº”çš„ARPUå€¼
            arpu_row = arpu_data[arpu_data['data_source'] == source]
            if not arpu_row.empty:
                arpu_value = arpu_row.iloc[0]['arpu_value']
            else:
                arpu_value = 0  # å¦‚æœæ‰¾ä¸åˆ°ARPUï¼Œè®¾ä¸º0
            
            # è®¡ç®—LTV
            ltv_value = lt_value * arpu_value
            
            ltv_results.append({
                'data_source': source,
                'lt_value': lt_value,
                'arpu_value': arpu_value,
                'ltv_value': ltv_value,
                'model_used': lt_result['model_used'],
                'r2_score': lt_result['r2_score']
            })
        
        st.session_state.ltv_results = ltv_results
        
        # æ˜¾ç¤ºLTVç»“æœ
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("LTVè®¡ç®—ç»“æœ")
        
        # åˆ›å»ºç»“æœè¡¨æ ¼
        ltv_df = pd.DataFrame(ltv_results)
        ltv_df = ltv_df.rename(columns={
            'data_source': 'æ•°æ®æ¥æº',
            'lt_value': 'LTå€¼',
            'arpu_value': 'ARPU',
            'ltv_value': 'LTV',
            'model_used': 'æ‹Ÿåˆæ¨¡å‹',
            'r2_score': 'RÂ²å¾—åˆ†'
        })
        
        # æ ¼å¼åŒ–æ˜¾ç¤º
        ltv_df['LTå€¼'] = ltv_df['LTå€¼'].round(2)
        ltv_df['ARPU'] = ltv_df['ARPU'].round(2)
        ltv_df['LTV'] = ltv_df['LTV'].round(2)
        ltv_df['RÂ²å¾—åˆ†'] = ltv_df['RÂ²å¾—åˆ†'].round(4)
        
        st.dataframe(ltv_df, use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)
        
        # å…³é”®æŒ‡æ ‡å±•ç¤º
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("å…³é”®æŒ‡æ ‡")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_ltv = ltv_df['LTV'].mean()
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.markdown(f'<div class="metric-value">{avg_ltv:.2f}</div>', unsafe_allow_html=True)
            st.markdown('<div class="metric-label">å¹³å‡LTV</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            max_ltv = ltv_df['LTV'].max()
            best_source = ltv_df.loc[ltv_df['LTV'].idxmax(), 'æ•°æ®æ¥æº']
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.markdown(f'<div class="metric-value">{max_ltv:.2f}</div>', unsafe_allow_html=True)
            st.markdown(f'<div class="metric-label">æœ€é«˜LTV<br>({best_source})</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col3:
            avg_lt = ltv_df['LTå€¼'].mean()
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.markdown(f'<div class="metric-value">{avg_lt:.2f}</div>', unsafe_allow_html=True)
            st.markdown('<div class="metric-label">å¹³å‡LT</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col4:
            avg_arpu = ltv_df['ARPU'].mean()
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.markdown(f'<div class="metric-value">{avg_arpu:.2f}</div>', unsafe_allow_html=True)
            st.markdown('<div class="metric-label">å¹³å‡ARPU</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # LTVå¯¹æ¯”å›¾è¡¨
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("LTVå¯¹æ¯”åˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # LTVæ¡å½¢å›¾
            if not ltv_df.empty:
                fig, ax = plt.subplots(figsize=(12, 8))
                
                # ä½¿ç”¨æ¸å˜è‰²
                colors = plt.cm.viridis(np.linspace(0, 1, len(ltv_df)))
                bars = ax.bar(ltv_df['æ•°æ®æ¥æº'], ltv_df['LTV'], color=colors, alpha=0.8, edgecolor='white', linewidth=2)
                
                ax.set_xlabel('æ•°æ®æ¥æº', fontsize=12, fontweight='bold')
                ax.set_ylabel('LTVå€¼', fontsize=12, fontweight='bold')
                ax.set_title('å„æ¸ é“LTVå¯¹æ¯”', fontsize=14, fontweight='bold')
                ax.tick_params(axis='x', rotation=45)
                
                # åœ¨æ¡å½¢å›¾ä¸Šæ˜¾ç¤ºæ•°å€¼
                for bar, value in zip(bars, ltv_df['LTV']):
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                           f'{value:.1f}', ha='center', va='bottom', fontweight='bold')
                
                # ç¾åŒ–å›¾è¡¨
                ax.spines['top'].set_visible(False)
                ax.spines['right'].set_visible(False)
                ax.grid(True, alpha=0.3, linestyle='--', axis='y')
                
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
        
        with col2:
            # LT vs ARPUæ•£ç‚¹å›¾
            if not ltv_df.empty:
                fig, ax = plt.subplots(figsize=(12, 8))
                scatter = ax.scatter(ltv_df['LTå€¼'], ltv_df['ARPU'], 
                                   c=ltv_df['LTV'], s=200, alpha=0.8, cmap='viridis',
                                   edgecolors='white', linewidth=2)
                
                # æ·»åŠ æ•°æ®æºæ ‡ç­¾
                for i, source in enumerate(ltv_df['æ•°æ®æ¥æº']):
                    ax.annotate(source, (ltv_df['LTå€¼'].iloc[i], ltv_df['ARPU'].iloc[i]),
                               xytext=(5, 5), textcoords='offset points', fontsize=10, fontweight='bold')
                
                ax.set_xlabel('LTå€¼', fontsize=12, fontweight='bold')
                ax.set_ylabel('ARPU', fontsize=12, fontweight='bold')
                ax.set_title('LT vs ARPU å…³ç³»å›¾', fontsize=14, fontweight='bold')
                
                # æ·»åŠ é¢œè‰²æ¡
                cbar = plt.colorbar(scatter)
                cbar.set_label('LTVå€¼', fontsize=12, fontweight='bold')
                
                # ç¾åŒ–å›¾è¡¨
                ax.spines['top'].set_visible(False)
                ax.spines['right'].set_visible(False)
                ax.grid(True, alpha=0.3, linestyle='--')
                
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # å¯¼å‡ºåŠŸèƒ½
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("ç»“æœå¯¼å‡º")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å‡†å¤‡å¯¼å‡ºæ•°æ®
            export_df = ltv_df.copy()
            
            # è½¬æ¢ä¸ºCSV
            csv_data = export_df.to_csv(index=False, encoding='utf-8-sig')
            
            st.download_button(
                label="ä¸‹è½½LTVç»“æœ (CSV)",
                data=csv_data,
                file_name=f"LTV_Results_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col2:
            # åˆ›å»ºè¯¦ç»†æŠ¥å‘Š
            report_text = f"""
LTVåˆ†ææŠ¥å‘Š
=================================
ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ€»ä½“æŒ‡æ ‡
---------------------------------
å‚ä¸åˆ†æçš„æ•°æ®æºæ•°é‡: {len(ltv_df)}
å¹³å‡LTV: {ltv_df['LTV'].mean():.2f}
æœ€é«˜LTV: {ltv_df['LTV'].max():.2f} ({ltv_df.loc[ltv_df['LTV'].idxmax(), 'æ•°æ®æ¥æº']})
å¹³å‡LT: {ltv_df['LTå€¼'].mean():.2f}
å¹³å‡ARPU: {ltv_df['ARPU'].mean():.2f}

è¯¦ç»†ç»“æœ
---------------------------------
"""
            
            for _, row in ltv_df.iterrows():
                report_text += f"""
{row['æ•°æ®æ¥æº']}:
  LTå€¼: {row['LTå€¼']:.2f}
  ARPU: {row['ARPU']:.2f}
  LTV: {row['LTV']:.2f}
  æ‹Ÿåˆæ¨¡å‹: {row['æ‹Ÿåˆæ¨¡å‹']}
  RÂ²å¾—åˆ†: {row['RÂ²å¾—åˆ†']:.4f}
"""
            
            st.download_button(
                label="ä¸‹è½½è¯¦ç»†æŠ¥å‘Š (TXT)",
                data=report_text,
                file_name=f"LTV_Report_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                mime="text/plain",
                use_container_width=True
            )
        
        st.markdown('</div>', unsafe_allow_html=True)

# åº•éƒ¨ä¿¡æ¯
with st.sidebar:
    st.markdown("---")
    st.markdown("""
    <div class="progress-container">
        <h4 style="text-align: center; color: #495057;">ä½¿ç”¨æç¤º</h4>
        <p style="font-size: 0.9rem; color: #6c757d; text-align: center;">
        è¯·æŒ‰ç…§æµç¨‹é¡ºåºå®Œæˆå„ä¸ªæ­¥éª¤ï¼Œæ¯ä¸€æ­¥çš„ç»“æœéƒ½ä¼šä¿å­˜åœ¨å½“å‰ä¼šè¯ä¸­ã€‚
        </p>
        <p style="font-size: 0.8rem; color: #adb5bd; text-align: center;">
        Enhanced Analytics Platform
        </p>
    </div>
    """, unsafe_allow_html=True)
