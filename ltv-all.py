import streamlit as st
import os
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
import datetime
import tempfile
import zipfile
import io
import matplotlib.pyplot as plt
import matplotlib as mpl
import re
from matplotlib.font_manager import FontProperties

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl.styles.stylesheet')
warnings.filterwarnings('ignore', category=UserWarning,
                        message="Could not infer format, so each element will be parsed individually")

# è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="LTV Analytics Platform",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        padding: 0.5rem 0rem 1rem 0rem;
        border-bottom: 2px solid #f0f2f6;
        margin-bottom: 1rem;
    }
    .metric-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 0.5rem 0;
    }
    .status-card {
        background-color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #e1e5e9;
        margin: 0.5rem 0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }
    .progress-item {
        padding: 0.5rem 0;
        border-bottom: 1px solid #f0f2f6;
    }
    .stButton > button {
        width: 100%;
        border-radius: 0.25rem;
        border: 1px solid #1f77b4;
        background-color: #1f77b4;
        color: white;
        font-weight: 500;
    }
    .stButton > button:hover {
        background-color: #0d5aa7;
        border-color: #0d5aa7;
    }
    .sidebar .sidebar-content {
        background-color: #f8f9fa;
    }
    h1, h2, h3 {
        color: #2c3e50;
        font-weight: 600;
    }
    .stSelectbox label, .stMultiselect label, .stFileUploader label {
        font-weight: 500;
        color: #34495e;
    }
    .compact-section {
        margin-top: 0.5rem;
        margin-bottom: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# é»˜è®¤æ¸ é“æ˜ å°„æ•°æ®
DEFAULT_CHANNEL_MAPPING = {
    # æ€»ä½“
    '9000': 'æ€»ä½“',
    
    # æ–°åª’ä½“
    '500345': 'æ–°åª’ä½“', '500346': 'æ–°åª’ä½“', '500447': 'æ–°åª’ä½“', '500449': 'æ–°åª’ä½“', 
    '500450': 'æ–°åª’ä½“', '500531': 'æ–°åª’ä½“', '500542': 'æ–°åª’ä½“',
    
    # åº”ç”¨å®
    '5007XS': 'åº”ç”¨å®', '500349': 'åº”ç”¨å®', '500350': 'åº”ç”¨å®',
    
    # é¼ä¹ç³»åˆ—
    '500285': 'é¼ä¹-ç››ä¸–6',
    '500286': 'é¼ä¹-ç››ä¸–7',
    
    # é…·æ´¾
    '5108': 'é…·æ´¾', '5528': 'é…·æ´¾',
    
    # æ–°ç¾ç³»åˆ—
    '500275': 'æ–°ç¾-åŒ—äº¬2',
    '500274': 'æ–°ç¾-åŒ—äº¬1',
    
    # A_æ·±åœ³è›‹ä¸2
    '500316': 'A_æ·±åœ³è›‹ä¸2',
    
    # ä¸»æµå‚å•†
    '500297': 'è£è€€',
    '5057': 'åä¸º',
    '5237': 'vivo',
    '5599': 'å°ç±³',
    '5115': 'OPPO',
    
    # ç½‘æ˜“
    '500471': 'ç½‘æ˜“', '500480': 'ç½‘æ˜“', '500481': 'ç½‘æ˜“', '500482': 'ç½‘æ˜“',
    
    # åä¸ºéå•†åº—-å“ä¼—
    '500337': 'åä¸ºéå•†åº—-å“ä¼—', '500338': 'åä¸ºéå•†åº—-å“ä¼—', '500343': 'åä¸ºéå•†åº—-å“ä¼—',
    '500445': 'åä¸ºéå•†åº—-å“ä¼—', '500383': 'åä¸ºéå•†åº—-å“ä¼—', '500444': 'åä¸ºéå•†åº—-å“ä¼—',
    '500441': 'åä¸ºéå•†åº—-å“ä¼—',
    
    # é­…æ—
    '5072': 'é­…æ—',
    
    # OPPOéå•†åº—
    '500287': 'OPPOéå•†åº—', '500288': 'OPPOéå•†åº—',
    
    # vivoéå•†åº—
    '5187': 'vivoéå•†åº—',
    
    # ç™¾åº¦semç³»åˆ—
    '500398': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£å®‰å“', '500400': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£å®‰å“', '500404': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£å®‰å“',
    '500402': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£ios', '500403': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£ios', '500405': 'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£ios',
    
    # ç™¾é’è—¤
    '500377': 'ç™¾é’è—¤-å®‰å“', '500379': 'ç™¾é’è—¤-å®‰å“', '500435': 'ç™¾é’è—¤-å®‰å“', '500436': 'ç™¾é’è—¤-å®‰å“',
    '500490': 'ç™¾é’è—¤-å®‰å“', '500491': 'ç™¾é’è—¤-å®‰å“', '500434': 'ç™¾é’è—¤-å®‰å“', '500492': 'ç™¾é’è—¤-å®‰å“',
    '500437': 'ç™¾é’è—¤-ios',
    
    # å°ç±³éå•†åº—
    '500170': 'å°ç±³éå•†åº—',
    
    # åä¸ºéå•†åº—-æ˜Ÿç«
    '500532': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500533': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500534': 'åä¸ºéå•†åº—-æ˜Ÿç«',
    '500537': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500538': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500539': 'åä¸ºéå•†åº—-æ˜Ÿç«',
    '500540': 'åä¸ºéå•†åº—-æ˜Ÿç«', '500541': 'åä¸ºéå•†åº—-æ˜Ÿç«',
    
    # å¾®åšç³»åˆ—
    '500504': 'å¾®åš-èœœæ©˜', '500505': 'å¾®åš-èœœæ©˜',
    '500367': 'å¾®åš-å¤®å¹¿', '500368': 'å¾®åš-å¤®å¹¿', '500369': 'å¾®åš-å¤®å¹¿',
    
    # å¹¿ç‚¹é€š
    '500498': 'å¹¿ç‚¹é€š(5.22èµ·)', '500497': 'å¹¿ç‚¹é€š(5.22èµ·)', '500500': 'å¹¿ç‚¹é€š(5.22èµ·)',
    '500501': 'å¹¿ç‚¹é€š(5.22èµ·)', '500496': 'å¹¿ç‚¹é€š(5.22èµ·)', '500499': 'å¹¿ç‚¹é€š(5.22èµ·)',
    
    # ç½‘æ˜“æ˜“æ•ˆ
    '500514': 'ç½‘æ˜“æ˜“æ•ˆ', '500515': 'ç½‘æ˜“æ˜“æ•ˆ', '500516': 'ç½‘æ˜“æ˜“æ•ˆ'
}

# è®¡ç®—é»˜è®¤ç›®æ ‡æœˆä»½ï¼ˆ2ä¸ªæœˆå‰ï¼‰
def get_default_target_month():
    today = datetime.datetime.now()
    # è®¡ç®—2ä¸ªæœˆå‰
    if today.month <= 2:
        target_year = today.year - 1
        target_month = today.month + 10
    else:
        target_year = today.year
        target_month = today.month - 2
    
    return f"{target_year}-{target_month:02d}"

# ä¸»æ ‡é¢˜
st.markdown('<div class="main-header">', unsafe_allow_html=True)
st.title("LTV Analytics Platform")
st.markdown("**ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†æç³»ç»Ÿ**")
st.markdown('</div>', unsafe_allow_html=True)

# ä¾§è¾¹æ å¯¼èˆª
st.sidebar.markdown("### åˆ†ææµç¨‹")
page = st.sidebar.selectbox(
    "é€‰æ‹©åˆ†ææ¨¡å—",
    [
        "æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»", 
        "ç•™å­˜ç‡è®¡ç®—", 
        "LTæ‹Ÿåˆåˆ†æ", 
        "ARPUè®¡ç®—", 
        "LTVç»“æœæŠ¥å‘Š"
    ],
    label_visibility="collapsed"
)

# åˆå§‹åŒ–session state
session_keys = [
    'channel_mapping', 'merged_data', 'retention_data', 
    'lt_results', 'arpu_data', 'ltv_results'
]
for key in session_keys:
    if key not in st.session_state:
        st.session_state[key] = None

# è®¾ç½®é»˜è®¤æ¸ é“æ˜ å°„
if st.session_state.channel_mapping is None:
    st.session_state.channel_mapping = DEFAULT_CHANNEL_MAPPING

# ===== æ•°æ®æ•´åˆåŠŸèƒ½ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰=====
def standardize_output_columns(df):
    """æ ‡å‡†åŒ–è¾“å‡ºåˆ—ç»“æ„ï¼Œç¡®ä¿åŒ…å«æŒ‡å®šçš„åˆ—é¡ºåº"""
    target_columns = [
        'æ•°æ®æ¥æº', 'date', 'æ•°æ®æ¥æº_date',
        '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',
        '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',
        '21', '22', '23', '24', '25', '26', '27', '28', '29', '30',
        'æ•°æ®æ¥æº_æ—¥æœŸ', 'æ—¥æœŸ', 'å›ä¼ æ–°å¢æ•°', 'is_target_month', 'month', 'stat_date',
        'new', 'new_retain_1', 'new_retain_2', 'new_retain_3', 'new_retain_4', 'new_retain_5',
        'new_retain_6', 'new_retain_7', 'new_retain_8', 'new_retain_9', 'new_retain_10',
        'new_retain_11', 'new_retain_12', 'new_retain_13', 'new_retain_14', 'new_retain_15',
        'new_retain_16', 'new_retain_17', 'new_retain_18', 'new_retain_19', 'new_retain_20',
        'new_retain_21', 'new_retain_22', 'new_retain_23', 'new_retain_24', 'new_retain_25',
        'new_retain_26', 'new_retain_27', 'new_retain_28', 'new_retain_29', 'new_retain_30'
    ]

    result_df = pd.DataFrame()
    
    for col_name in target_columns:
        if col_name == 'æ•°æ®æ¥æº':
            result_df[col_name] = df[col_name] if col_name in df.columns else ''
        elif col_name == 'date':
            if col_name in df.columns:
                result_df[col_name] = df[col_name]
            elif 'stat_date' in df.columns:
                result_df[col_name] = df['stat_date']
            else:
                result_df[col_name] = ''
        elif col_name == 'æ•°æ®æ¥æº_date':
            data_source = df['æ•°æ®æ¥æº'] if 'æ•°æ®æ¥æº' in df.columns else ''
            date_col = df['date'] if 'date' in df.columns else (df['stat_date'] if 'stat_date' in df.columns else '')
            result_df[col_name] = data_source.astype(str) + date_col.astype(str)
        elif col_name == 'æ•°æ®æ¥æº_æ—¥æœŸ':
            data_source = df['æ•°æ®æ¥æº'] if 'æ•°æ®æ¥æº' in df.columns else ''
            date_col = df['æ—¥æœŸ'] if 'æ—¥æœŸ' in df.columns else (
                df['date'] if 'date' in df.columns else (df['stat_date'] if 'stat_date' in df.columns else ''))
            result_df[col_name] = data_source.astype(str) + date_col.astype(str)
        else:
            result_df[col_name] = df[col_name] if col_name in df.columns else ''

    for col in df.columns:
        if col not in target_columns:
            result_df[col] = df[col]

    return result_df

def integrate_excel_files_streamlit(uploaded_files, target_month=None, channel_mapping=None):
    """Streamlitç‰ˆæœ¬çš„Excelæ–‡ä»¶æ•´åˆå‡½æ•°"""
    if target_month is None:
        target_month = get_default_target_month()

    all_data = pd.DataFrame()
    processed_count = 0

    for uploaded_file in uploaded_files:
        source_name = os.path.splitext(uploaded_file.name)[0]
        
        # å¦‚æœæœ‰æ¸ é“æ˜ å°„ï¼Œå°è¯•æ ¹æ®æ–‡ä»¶åæ˜ å°„æ¸ é“
        if channel_mapping and source_name in channel_mapping:
            mapped_source = channel_mapping[source_name]
        else:
            mapped_source = source_name
        
        try:
            xls = pd.ExcelFile(uploaded_file)
            sheet_names = xls.sheet_names

            ocpx_sheet = None
            channel_sheet = None

            for sheet in sheet_names:
                if "ocpxç›‘æµ‹ç•™å­˜æ•°" in sheet:
                    ocpx_sheet = sheet
                if "ç›‘æµ‹æ¸ é“å›ä¼ é‡" in sheet:
                    channel_sheet = sheet

            file_data = None

            if ocpx_sheet:
                ocpx_df = pd.read_excel(uploaded_file, sheet_name=ocpx_sheet)
                
                if channel_sheet:
                    channel_df = pd.read_excel(uploaded_file, sheet_name=channel_sheet)
                    if len(channel_df.columns) >= 2:
                        last_two_cols = channel_df.iloc[:, -2:]
                        ocpx_df = ocpx_df.copy()
                        for col_name in last_two_cols.columns:
                            ocpx_df[col_name] = last_two_cols[col_name].values[:len(ocpx_df)] if len(
                                last_two_cols) >= len(ocpx_df) else last_two_cols[col_name].values.tolist() + [
                                None] * (len(ocpx_df) - len(last_two_cols))
                
                file_data = ocpx_df
            else:
                file_data = pd.read_excel(uploaded_file, sheet_name=0)

            if file_data is not None and not file_data.empty:
                file_data_copy = file_data.copy()

                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ ¼å¼è¡¨
                has_stat_date = 'stat_date' in file_data_copy.columns
                retain_columns = [f'new_retain_{i}' for i in range(1, 31)]
                has_retain_columns = any(col in file_data_copy.columns for col in retain_columns)

                if has_stat_date and has_retain_columns:
                    standardized_data = file_data_copy.copy()

                    if 'new' in standardized_data.columns:
                        standardized_data['å›ä¼ æ–°å¢æ•°'] = standardized_data['new']

                    for i in range(1, 31):
                        retain_col = f'new_retain_{i}'
                        if retain_col in standardized_data.columns:
                            standardized_data[str(i)] = standardized_data[retain_col]

                    date_col = 'stat_date'
                    standardized_data[date_col] = pd.to_datetime(standardized_data[date_col], errors='coerce')
                    standardized_data[date_col] = standardized_data[date_col].dt.strftime('%Y-%m-%d')
                    standardized_data['æ—¥æœŸ'] = standardized_data[date_col]
                    standardized_data['month'] = standardized_data[date_col].str[:7]

                    filtered_data = standardized_data[standardized_data['month'] == target_month].copy()

                    if not filtered_data.empty:
                        filtered_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)
                        filtered_data['date'] = filtered_data['stat_date']
                        all_data = pd.concat([all_data, filtered_data], ignore_index=True)
                        processed_count += 1

                else:
                    # å¤„ç†æ—§æ ¼å¼è¡¨çš„é€»è¾‘ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    retention_col = None
                    for col in file_data_copy.columns:
                        if 'ç•™å­˜å¤©æ•°' in str(col):
                            retention_col = col
                            break

                    date_col = None
                    for col in file_data_copy.columns:
                        if 'æ—¥æœŸ' in str(col):
                            date_col = col
                            break

                    if len(file_data_copy.columns) >= 2:
                        second_col = file_data_copy.columns[1]
                        file_data_copy['å›ä¼ æ–°å¢æ•°'] = file_data_copy[second_col]

                    if date_col:
                        try:
                            file_data_copy[date_col] = pd.to_datetime(file_data_copy[date_col], errors='coerce')
                            file_data_copy['month'] = file_data_copy[date_col].dt.strftime('%Y-%m')
                            filtered_data = file_data_copy[file_data_copy['month'] == target_month].copy()
                            
                            if not filtered_data.empty:
                                filtered_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)
                                if retention_col:
                                    filtered_data.rename(columns={retention_col: 'date'}, inplace=True)
                                else:
                                    filtered_data['date'] = filtered_data[date_col].dt.strftime('%Y-%m-%d')
                                
                                all_data = pd.concat([all_data, filtered_data], ignore_index=True)
                                processed_count += 1
                        except:
                            # å¦‚æœæ—¥æœŸå¤„ç†å¤±è´¥ï¼Œä¿ç•™æ‰€æœ‰æ•°æ®
                            file_data_copy.insert(0, 'æ•°æ®æ¥æº', mapped_source)
                            if retention_col:
                                file_data_copy.rename(columns={retention_col: 'date'}, inplace=True)
                            all_data = pd.concat([all_data, file_data_copy], ignore_index=True)
                            processed_count += 1

        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} æ—¶å‡ºé”™: {str(e)}")

    if not all_data.empty:
        standardized_df = standardize_output_columns(all_data)
        return standardized_df, processed_count
    else:
        return None, 0

def parse_channel_mapping(channel_df):
    """è§£ææ¸ é“æ˜ å°„è¡¨ï¼Œæ”¯æŒæ–°çš„æ ¼å¼ï¼šç¬¬ä¸€åˆ—ä¸ºæ¸ é“åï¼Œåç»­åˆ—ä¸ºæ¸ é“å·"""
    pid_to_channel = {}
    
    for _, row in channel_df.iterrows():
        channel_name = str(row.iloc[0]).strip()  # ç¬¬ä¸€åˆ—æ˜¯æ¸ é“å
        
        # è·³è¿‡ç©ºè¡Œæˆ–æ— æ•ˆçš„æ¸ é“å
        if pd.isna(channel_name) or channel_name == '' or channel_name == 'nan':
            continue
            
        # å¤„ç†åç»­åˆ—çš„æ¸ é“å·
        for col_idx in range(1, len(row)):
            pid = row.iloc[col_idx]
            
            # å¤„ç†å„ç§å¯èƒ½çš„ç©ºå€¼è¡¨ç¤º
            if pd.isna(pid) or str(pid).strip() in ['', 'nan', 'ã€€', ' ']:
                continue
                
            pid_str = str(pid).strip()
            if pid_str:
                pid_to_channel[pid_str] = channel_name
    
    return pid_to_channel

# ===== æ‹Ÿåˆè®¡ç®—åŠŸèƒ½ï¼ˆç”¨numpyæ›¿ä»£scipyï¼‰=====
def numpy_curve_fit_power(x, y, max_iter=1000, tolerance=1e-8):
    """
    ä½¿ç”¨numpyå®ç°å¹‚å‡½æ•°æ‹Ÿåˆï¼šy = a * x^b
    é€šè¿‡å¯¹æ•°çº¿æ€§å›å½’ï¼šlog(y) = log(a) + b*log(x)
    """
    try:
        # è¿‡æ»¤æ‰éæ­£æ•°æ®
        valid_mask = (x > 0) & (y > 0) & np.isfinite(x) & np.isfinite(y)
        if np.sum(valid_mask) < 2:
            return [1.0, -0.5], True  # é»˜è®¤å‚æ•°
        
        x_valid = x[valid_mask]
        y_valid = y[valid_mask]
        
        # å¯¹æ•°å˜æ¢
        log_x = np.log(x_valid)
        log_y = np.log(y_valid)
        
        # çº¿æ€§å›å½’: log_y = log_a + b * log_x
        # æ„å»ºè®¾è®¡çŸ©é˜µ
        X = np.column_stack([np.ones(len(log_x)), log_x])
        
        # æœ€å°äºŒä¹˜è§£
        coeffs = np.linalg.lstsq(X, log_y, rcond=None)[0]
        log_a, b = coeffs
        a = np.exp(log_a)
        
        return [a, b], True
        
    except Exception as e:
        print(f"å¹‚å‡½æ•°æ‹Ÿåˆå¤±è´¥: {e}")
        return [1.0, -0.5], False

def numpy_curve_fit_exponential(x, y, initial_c=None, initial_d=-0.001, max_iter=1000):
    """
    ä½¿ç”¨numpyå®ç°æŒ‡æ•°å‡½æ•°æ‹Ÿåˆï¼šy = c * exp(d * x)
    é€šè¿‡å¯¹æ•°çº¿æ€§å›å½’ï¼šlog(y) = log(c) + d*x
    """
    try:
        # è¿‡æ»¤æ‰éæ­£æ•°æ®
        valid_mask = (y > 0) & np.isfinite(x) & np.isfinite(y)
        if np.sum(valid_mask) < 2:
            return [initial_c or 1.0, initial_d], True
        
        x_valid = x[valid_mask]
        y_valid = y[valid_mask]
        
        # å¯¹æ•°å˜æ¢
        log_y = np.log(y_valid)
        
        # çº¿æ€§å›å½’: log_y = log_c + d * x
        # æ„å»ºè®¾è®¡çŸ©é˜µ
        X = np.column_stack([np.ones(len(x_valid)), x_valid])
        
        # æœ€å°äºŒä¹˜è§£
        coeffs = np.linalg.lstsq(X, log_y, rcond=None)[0]
        log_c, d = coeffs
        c = np.exp(log_c)
        
        # æ£€æŸ¥dæ˜¯å¦ä¸ºè´Ÿæ•°ï¼ˆæŒ‡æ•°è¡°å‡ï¼‰
        if d > 0:
            d = -abs(d)  # å¼ºåˆ¶ä¸ºè´Ÿæ•°ï¼Œç¡®ä¿è¡°å‡
        
        return [c, d], True
        
    except Exception as e:
        print(f"æŒ‡æ•°å‡½æ•°æ‹Ÿåˆå¤±è´¥: {e}")
        return [initial_c or 1.0, initial_d], False

def calculate_r_squared(y_true, y_pred):
    """è®¡ç®—RÂ²å€¼"""
    try:
        # è¿‡æ»¤æ‰æ— æ•ˆå€¼
        valid_mask = np.isfinite(y_true) & np.isfinite(y_pred)
        if np.sum(valid_mask) < 2:
            return 0.0
        
        y_true_valid = y_true[valid_mask]
        y_pred_valid = y_pred[valid_mask]
        
        # è®¡ç®—æ€»å¹³æ–¹å’Œ
        ss_tot = np.sum((y_true_valid - np.mean(y_true_valid)) ** 2)
        
        # è®¡ç®—æ®‹å·®å¹³æ–¹å’Œ
        ss_res = np.sum((y_true_valid - y_pred_valid) ** 2)
        
        # è®¡ç®—RÂ²
        if ss_tot == 0:
            return 1.0 if ss_res == 0 else 0.0
        
        r_squared = 1 - (ss_res / ss_tot)
        return max(0.0, min(1.0, r_squared))  # ç¡®ä¿åœ¨[0,1]èŒƒå›´å†…
        
    except Exception as e:
        print(f"è®¡ç®—RÂ²å¤±è´¥: {e}")
        return 0.0

def calculate_retention_rates(df):
    """è®¡ç®—ç•™å­˜ç‡æ•°æ®"""
    retention_results = []
    
    # è·å–æ•°æ®æ¥æºåˆ—è¡¨
    data_sources = df['æ•°æ®æ¥æº'].unique()
    
    for source in data_sources:
        source_data = df[df['æ•°æ®æ¥æº'] == source].copy()
        
        # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—åŠ æƒå¹³å‡ç•™å­˜ç‡
        daily_retention = {}
        
        for _, row in source_data.iterrows():
            date = row['date']
            new_users = row.get('å›ä¼ æ–°å¢æ•°', 0)
            
            if pd.isna(new_users) or new_users <= 0:
                continue
            
            for day in range(1, 31):
                day_col = str(day)
                if day_col in row and not pd.isna(row[day_col]):
                    retain_count = row[day_col]
                    retention_rate = retain_count / new_users if new_users > 0 else 0
                    
                    if date not in daily_retention:
                        daily_retention[date] = {}
                    
                    daily_retention[date][day] = {
                        'rate': retention_rate,
                        'weight': new_users,
                        'retain_count': retain_count,
                        'new_users': new_users
                    }
        
        # è®¡ç®—æ•´ä½“åŠ æƒå¹³å‡ç•™å­˜ç‡
        overall_retention = {}
        for day in range(1, 31):
            total_weighted_rate = 0
            total_weight = 0
            
            for date in daily_retention:
                if day in daily_retention[date]:
                    rate = daily_retention[date][day]['rate']
                    weight = daily_retention[date][day]['weight']
                    total_weighted_rate += rate * weight
                    total_weight += weight
            
            if total_weight > 0:
                overall_retention[day] = total_weighted_rate / total_weight
            else:
                overall_retention[day] = 0
        
        retention_results.append({
            'data_source': source,
            'retention_rates': overall_retention,
            'daily_data': daily_retention
        })
    
    return retention_results

def fit_retention_curves(retention_results):
    """å¯¹ç•™å­˜ç‡è¿›è¡Œæ›²çº¿æ‹Ÿåˆ"""
    fitting_results = []
    
    for result in retention_results:
        source = result['data_source']
        retention_rates = result['retention_rates']
        
        # å‡†å¤‡æ‹Ÿåˆæ•°æ®
        days = []
        rates = []
        
        for day in range(1, 31):
            if day in retention_rates and retention_rates[day] > 0:
                days.append(day)
                rates.append(retention_rates[day])
        
        if len(days) < 3:
            # æ•°æ®ç‚¹å¤ªå°‘ï¼Œè·³è¿‡æ‹Ÿåˆ
            fitting_results.append({
                'data_source': source,
                'power_params': [1.0, -0.5],
                'power_r2': 0.0,
                'exp_params': [1.0, -0.1],
                'exp_r2': 0.0,
                'best_model': 'power',
                'days': days,
                'rates': rates
            })
            continue
        
        days_array = np.array(days)
        rates_array = np.array(rates)
        
        # å¹‚å‡½æ•°æ‹Ÿåˆ
        power_params, power_success = numpy_curve_fit_power(days_array, rates_array)
        if power_success:
            power_pred = power_params[0] * (days_array ** power_params[1])
            power_r2 = calculate_r_squared(rates_array, power_pred)
        else:
            power_r2 = 0.0
        
        # æŒ‡æ•°å‡½æ•°æ‹Ÿåˆ
        exp_params, exp_success = numpy_curve_fit_exponential(days_array, rates_array)
        if exp_success:
            exp_pred = exp_params[0] * np.exp(exp_params[1] * days_array)
            exp_r2 = calculate_r_squared(rates_array, exp_pred)
        else:
            exp_r2 = 0.0
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_model = 'power' if power_r2 >= exp_r2 else 'exponential'
        
        fitting_results.append({
            'data_source': source,
            'power_params': power_params,
            'power_r2': power_r2,
            'exp_params': exp_params,
            'exp_r2': exp_r2,
            'best_model': best_model,
            'days': days,
            'rates': rates
        })
    
    return fitting_results

def calculate_lt_values(fitting_results, max_days=365):
    """è®¡ç®—LTå€¼"""
    lt_results = []
    
    for result in fitting_results:
        source = result['data_source']
        best_model = result['best_model']
        
        if best_model == 'power':
            params = result['power_params']
            a, b = params
            
            # å¹‚å‡½æ•°ç§¯åˆ†ï¼šâˆ«(a * x^b)dx from 1 to max_days
            if b != -1:
                lt_value = (a / (b + 1)) * (max_days**(b + 1) - 1)
            else:
                # å½“b=-1æ—¶ï¼Œç§¯åˆ†æ˜¯å¯¹æ•°å‡½æ•°
                lt_value = a * np.log(max_days)
        else:
            params = result['exp_params']
            c, d = params
            
            # æŒ‡æ•°å‡½æ•°ç§¯åˆ†ï¼šâˆ«(c * e^(d*x))dx from 1 to max_days
            if d != 0:
                lt_value = (c / d) * (np.exp(d * max_days) - np.exp(d))
            else:
                lt_value = c * (max_days - 1)
        
        # ç¡®ä¿LTå€¼ä¸ºæ­£æ•°ä¸”åˆç†
        lt_value = max(0, min(lt_value, max_days))
        
        lt_results.append({
            'data_source': source,
            'lt_value': lt_value,
            'model_used': best_model,
            'model_params': result[f'{best_model}_params'],
            'r2_score': result[f'{best_model}_r2']
        })
    
    return lt_results

# ===== é¡µé¢å†…å®¹ =====
if page == "æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»":
    st.header("æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»")
    
    # æ˜¾ç¤ºé»˜è®¤æ¸ é“æ˜ å°„çŠ¶æ€
    with st.expander("æ¸ é“æ˜ å°„é…ç½®", expanded=False):
        st.markdown("**å½“å‰æ¸ é“æ˜ å°„çŠ¶æ€:**")
        
        col1, col2 = st.columns([1, 2])
        with col1:
            if st.session_state.channel_mapping:
                st.success(f"å·²é…ç½® {len(st.session_state.channel_mapping)} ä¸ªæ¸ é“æ˜ å°„")
                st.text("ä½¿ç”¨é»˜è®¤æ¸ é“æ˜ å°„è¡¨")
            else:
                st.warning("æœªé…ç½®æ¸ é“æ˜ å°„")
        
        with col2:
            # æ˜¾ç¤ºéƒ¨åˆ†æ˜ å°„ç¤ºä¾‹
            if st.session_state.channel_mapping:
                sample_items = list(st.session_state.channel_mapping.items())[:5]
                for pid, channel in sample_items:
                    st.text(f"{pid} â†’ {channel}")
                if len(st.session_state.channel_mapping) > 5:
                    st.text(f"... è¿˜æœ‰ {len(st.session_state.channel_mapping) - 5} ä¸ªæ˜ å°„")
        
        # è‡ªå®šä¹‰æ¸ é“æ˜ å°„æ–‡ä»¶ä¸Šä¼ 
        st.markdown("**ä¸Šä¼ è‡ªå®šä¹‰æ¸ é“æ˜ å°„è¡¨ (å¯é€‰):**")
        channel_file = st.file_uploader(
            "é€‰æ‹©æ¸ é“æ˜ å°„æ–‡ä»¶",
            type=['xlsx', 'xls'],
            help="ç¬¬ä¸€åˆ—ä¸ºæ¸ é“åï¼Œåç»­åˆ—ä¸ºå¯¹åº”çš„æ¸ é“å·ã€‚å¦‚ä¸ä¸Šä¼ å°†ä½¿ç”¨é»˜è®¤æ˜ å°„è¡¨"
        )
        
        if channel_file:
            try:
                channel_df = pd.read_excel(channel_file)
                custom_mapping = parse_channel_mapping(channel_df)
                st.session_state.channel_mapping = custom_mapping
                st.success(f"è‡ªå®šä¹‰æ¸ é“æ˜ å°„å·²åŠ è½½ï¼Œå…± {len(custom_mapping)} ä¸ªæ˜ å°„")
                st.dataframe(channel_df.head(), use_container_width=True)
            except Exception as e:
                st.error(f"æ¸ é“æ˜ å°„æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
    
    # æ•°æ®æ–‡ä»¶ä¸Šä¼ 
    st.subheader("æ•°æ®æ–‡ä»¶å¤„ç†")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        uploaded_files = st.file_uploader(
            "é€‰æ‹©Excelæ•°æ®æ–‡ä»¶",
            type=['xlsx', 'xls'],
            accept_multiple_files=True,
            help="æ”¯æŒä¸Šä¼ å¤šä¸ªExcelæ–‡ä»¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è§£æç•™å­˜æ•°æ®"
        )
        
        # ç›®æ ‡æœˆä»½é€‰æ‹©
        default_month = get_default_target_month()
        target_month = st.text_input(
            "ç›®æ ‡æœˆä»½ (YYYY-MM)",
            value=default_month,
            help=f"å½“å‰é»˜è®¤ä¸º2ä¸ªæœˆå‰: {default_month}"
        )
    
    with col2:
        st.markdown('<div class="status-card">', unsafe_allow_html=True)
        st.markdown("### å¤„ç†çŠ¶æ€")
        
        if uploaded_files:
            st.success(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            for file in uploaded_files:
                st.text(f"â€¢ {file.name}")
        else:
            st.info("æœªé€‰æ‹©æ•°æ®æ–‡ä»¶")
        
        st.text(f"ç›®æ ‡æœˆä»½: {target_month}")
        st.text(f"æ¸ é“æ˜ å°„: {len(st.session_state.channel_mapping)} ä¸ª")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # å¤„ç†æŒ‰é’®
    if st.button("å¼€å§‹å¤„ç†æ•°æ®", type="primary", use_container_width=True):
        if uploaded_files:
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®æ–‡ä»¶..."):
                try:
                    # å¤„ç†æ•°æ®æ–‡ä»¶
                    merged_data, processed_count = integrate_excel_files_streamlit(
                        uploaded_files, target_month, st.session_state.channel_mapping
                    )
                    
                    if merged_data is not None and not merged_data.empty:
                        st.session_state.merged_data = merged_data
                        
                        st.success(f"æ•°æ®å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {processed_count} ä¸ªæ–‡ä»¶")
                        
                        # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                        st.subheader("æ•°æ®é¢„è§ˆ")
                        st.dataframe(merged_data.head(10), use_container_width=True)
                        
                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("æ€»è®°å½•æ•°", len(merged_data))
                        with col2:
                            st.metric("æ•°æ®æ¥æº", merged_data['æ•°æ®æ¥æº'].nunique())
                        with col3:
                            st.metric("æ—¥æœŸèŒƒå›´", f"{merged_data['date'].min()} è‡³ {merged_data['date'].max()}")
                        with col4:
                            total_new_users = merged_data['å›ä¼ æ–°å¢æ•°'].sum()
                            st.metric("æ€»æ–°å¢ç”¨æˆ·", f"{total_new_users:,.0f}")
                    
                    else:
                        st.error("æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œç›®æ ‡æœˆä»½è®¾ç½®")
                
                except Exception as e:
                    st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")
        else:
            st.error("è¯·å…ˆé€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶")

elif page == "ç•™å­˜ç‡è®¡ç®—":
    st.header("ç•™å­˜ç‡è®¡ç®—")
    
    if st.session_state.merged_data is None:
        st.warning("è¯·å…ˆåœ¨ã€Œæ•°æ®ä¸Šä¼ ä¸æ±‡æ€»ã€é¡µé¢å¤„ç†æ•°æ®")
        if st.button("è¿”å›æ•°æ®ä¸Šä¼ é¡µé¢"):
            st.experimental_rerun()
    else:
        merged_data = st.session_state.merged_data
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.subheader("ç•™å­˜ç‡åˆ†æé…ç½®")
            
            # æ•°æ®æ¥æºé€‰æ‹©
            data_sources = merged_data['æ•°æ®æ¥æº'].unique()
            selected_sources = st.multiselect(
                "é€‰æ‹©è¦åˆ†æçš„æ•°æ®æ¥æº",
                options=data_sources,
                default=data_sources,
                help="å¯ä»¥é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®æ¥æºè¿›è¡Œåˆ†æ"
            )
        
        with col2:
            st.markdown('<div class="status-card">', unsafe_allow_html=True)
            st.markdown("### åˆ†æèŒƒå›´")
            st.text(f"æ•°æ®æ¥æº: {len(selected_sources)}")
            st.text(f"æ€»è®°å½•æ•°: {len(merged_data)}")
            st.text(f"åˆ†æå¤©æ•°: 1-30å¤©")
            st.markdown('</div>', unsafe_allow_html=True)
        
        if st.button("è®¡ç®—ç•™å­˜ç‡", type="primary", use_container_width=True):
            if selected_sources:
                with st.spinner("æ­£åœ¨è®¡ç®—ç•™å­˜ç‡..."):
                    # è¿‡æ»¤é€‰ä¸­çš„æ•°æ®æ¥æº
                    filtered_data = merged_data[merged_data['æ•°æ®æ¥æº'].isin(selected_sources)]
                    
                    # è®¡ç®—ç•™å­˜ç‡
                    retention_results = calculate_retention_rates(filtered_data)
                    st.session_state.retention_data = retention_results
                    
                    st.success("ç•™å­˜ç‡è®¡ç®—å®Œæˆï¼")
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.subheader("ç•™å­˜ç‡ç»“æœ")
                    
                    for result in retention_results:
                        with st.expander(f"{result['data_source']} - ç•™å­˜ç‡è¯¦æƒ…"):
                            retention_rates = result['retention_rates']
                            
                            # åˆ›å»ºç•™å­˜ç‡è¡¨æ ¼
                            days = list(range(1, 31))
                            rates = [retention_rates.get(day, 0) for day in days]
                            
                            df_display = pd.DataFrame({
                                'å¤©æ•°': days,
                                'ç•™å­˜ç‡': [f"{rate:.4f}" for rate in rates],
                                'ç™¾åˆ†æ¯”': [f"{rate*100:.2f}%" for rate in rates]
                            })
                            
                            col1, col2 = st.columns([2, 1])
                            with col1:
                                st.dataframe(df_display, use_container_width=True)
                            
                            with col2:
                                # ç»˜åˆ¶ç•™å­˜ç‡æ›²çº¿
                                fig, ax = plt.subplots(figsize=(8, 6))
                                valid_days = [d for d, r in zip(days, rates) if r > 0]
                                valid_rates = [r for r in rates if r > 0]
                                
                                if valid_days:
                                    ax.plot(valid_days, valid_rates, 'o-', linewidth=2, markersize=6)
                                    ax.set_xlabel('å¤©æ•°')
                                    ax.set_ylabel('ç•™å­˜ç‡')
                                    ax.set_title(f'{result["data_source"]} ç•™å­˜ç‡æ›²çº¿')
                                    ax.grid(True, alpha=0.3)
                                    ax.set_ylim(0, max(valid_rates) * 1.1)
                                
                                st.pyplot(fig)
                                plt.close()
            else:
                st.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ•°æ®æ¥æº")

elif page == "LTæ‹Ÿåˆåˆ†æ":
    st.header("LTæ‹Ÿåˆåˆ†æ")
    
    if st.session_state.retention_data is None:
        st.warning("è¯·å…ˆåœ¨ã€Œç•™å­˜ç‡è®¡ç®—ã€é¡µé¢è®¡ç®—ç•™å­˜ç‡")
        if st.button("è¿”å›ç•™å­˜ç‡è®¡ç®—é¡µé¢"):
            st.experimental_rerun()
    else:
        retention_data = st.session_state.retention_data
        
        st.subheader("æ›²çº¿æ‹Ÿåˆå‚æ•°è®¾ç½®")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("**æ‹Ÿåˆæ–¹æ³•é€‰æ‹©ï¼š**")
            fit_methods = st.multiselect(
                "é€‰æ‹©æ‹Ÿåˆæ–¹æ³•",
                options=["å¹‚å‡½æ•° (Power)", "æŒ‡æ•°å‡½æ•° (Exponential)"],
                default=["å¹‚å‡½æ•° (Power)", "æŒ‡æ•°å‡½æ•° (Exponential)"],
                help="ç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©æ‹Ÿåˆåº¦æœ€å¥½çš„æ–¹æ³•"
            )
            
            max_days = st.number_input(
                "LTè®¡ç®—å¤©æ•°èŒƒå›´",
                min_value=30,
                max_value=1000,
                value=365,
                help="è®¾ç½®è®¡ç®—ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸçš„å¤©æ•°èŒƒå›´"
            )
        
        with col2:
            st.markdown('<div class="status-card">', unsafe_allow_html=True)
            st.markdown("### æ‹Ÿåˆè®¾ç½®")
            st.text(f"æ•°æ®æ¥æº: {len(retention_data)}")
            st.text(f"æ‹Ÿåˆæ–¹æ³•: {len(fit_methods)}")
            st.text(f"LTå¤©æ•°: {max_days}")
            st.markdown('</div>', unsafe_allow_html=True)
        
        if st.button("å¼€å§‹æ‹Ÿåˆåˆ†æ", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨è¿›è¡Œæ›²çº¿æ‹Ÿåˆ..."):
                # æ‰§è¡Œæ‹Ÿåˆåˆ†æ
                fitting_results = fit_retention_curves(retention_data)
                
                # è®¡ç®—LTå€¼
                lt_results = calculate_lt_values(fitting_results, max_days)
                st.session_state.lt_results = lt_results
                
                st.success("æ‹Ÿåˆåˆ†æå®Œæˆï¼")
                
                # æ˜¾ç¤ºæ‹Ÿåˆç»“æœ
                st.subheader("æ‹Ÿåˆç»“æœ")
                
                for i, result in enumerate(fitting_results):
                    source = result['data_source']
                    
                    with st.expander(f"{source} - æ‹Ÿåˆåˆ†æè¯¦æƒ…", expanded=True):
                        col1, col2 = st.columns([1, 1])
                        
                        with col1:
                            # æ˜¾ç¤ºæ‹Ÿåˆå‚æ•°
                            st.markdown("**æ‹Ÿåˆå‚æ•°ï¼š**")
                            
                            # å¹‚å‡½æ•°ç»“æœ
                            power_params = result['power_params']
                            power_r2 = result['power_r2']
                            st.write(f"**å¹‚å‡½æ•°:** y = {power_params[0]:.4f} Ã— x^{power_params[1]:.4f}")
                            st.write(f"RÂ² = {power_r2:.4f}")
                            
                            # æŒ‡æ•°å‡½æ•°ç»“æœ
                            exp_params = result['exp_params']
                            exp_r2 = result['exp_r2']
                            st.write(f"**æŒ‡æ•°å‡½æ•°:** y = {exp_params[0]:.4f} Ã— e^({exp_params[1]:.4f}x)")
                            st.write(f"RÂ² = {exp_r2:.4f}")
                            
                            # æœ€ä½³æ¨¡å‹
                            best_model = result['best_model']
                            st.success(f"**æœ€ä½³æ¨¡å‹:** {best_model}")
                            
                            # LTå€¼
                            lt_value = lt_results[i]['lt_value']
                            st.metric("**LTå€¼**", f"{lt_value:.2f}", help=f"åŸºäº{max_days}å¤©è®¡ç®—")
                        
                        with col2:
                            # ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿
                            days = np.array(result['days'])
                            rates = np.array(result['rates'])
                            
                            if len(days) > 0:
                                fig, ax = plt.subplots(figsize=(10, 6))
                                
                                # åŸå§‹æ•°æ®ç‚¹
                                ax.scatter(days, rates, color='red', s=50, alpha=0.7, label='å®é™…æ•°æ®', zorder=5)
                                
                                # æ‹Ÿåˆæ›²çº¿
                                x_fit = np.linspace(1, 30, 100)
                                
                                # å¹‚å‡½æ•°æ‹Ÿåˆæ›²çº¿
                                y_power = power_params[0] * (x_fit ** power_params[1])
                                ax.plot(x_fit, y_power, '--', color='blue', linewidth=2, 
                                       label=f'å¹‚å‡½æ•° (RÂ²={power_r2:.3f})', alpha=0.8)
                                
                                # æŒ‡æ•°å‡½æ•°æ‹Ÿåˆæ›²çº¿
                                y_exp = exp_params[0] * np.exp(exp_params[1] * x_fit)
                                ax.plot(x_fit, y_exp, '--', color='green', linewidth=2, 
                                       label=f'æŒ‡æ•°å‡½æ•° (RÂ²={exp_r2:.3f})', alpha=0.8)
                                
                                # çªå‡ºæ˜¾ç¤ºæœ€ä½³æ‹Ÿåˆ
                                if best_model == 'power':
                                    ax.plot(x_fit, y_power, '-', color='blue', linewidth=3, 
                                           label='æœ€ä½³æ‹Ÿåˆ', alpha=1.0, zorder=4)
                                else:
                                    ax.plot(x_fit, y_exp, '-', color='green', linewidth=3, 
                                           label='æœ€ä½³æ‹Ÿåˆ', alpha=1.0, zorder=4)
                                
                                ax.set_xlabel('å¤©æ•°')
                                ax.set_ylabel('ç•™å­˜ç‡')
                                ax.set_title(f'{source} - ç•™å­˜ç‡æ‹Ÿåˆæ›²çº¿')
                                ax.legend()
                                ax.grid(True, alpha=0.3)
                                ax.set_xlim(0, 31)
                                ax.set_ylim(0, max(rates) * 1.1)
                                
                                st.pyplot(fig)
                                plt.close()

elif page == "ARPUè®¡ç®—":
    st.header("ARPUè®¡ç®—")
    
    st.subheader("ä¸Šä¼ ARPUæ•°æ®")
    
    # ARPUæ•°æ®ä¸Šä¼ 
    arpu_file = st.file_uploader(
        "é€‰æ‹©ARPUæ•°æ®æ–‡ä»¶",
        type=['xlsx', 'xls'],
        help="ä¸Šä¼ åŒ…å«ç”¨æˆ·ä»˜è´¹æ•°æ®çš„Excelæ–‡ä»¶"
    )
    
    if arpu_file:
        try:
            # è¯»å–ARPUæ–‡ä»¶
            arpu_df = pd.read_excel(arpu_file)
            st.success("ARPUæ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
            
            # æ˜¾ç¤ºæ–‡ä»¶é¢„è§ˆ
            st.subheader("æ•°æ®é¢„è§ˆ")
            st.dataframe(arpu_df.head(10), use_container_width=True)
            
            # æ•°æ®åˆ—é€‰æ‹©
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("æ•°æ®åˆ—æ˜ å°„")
                
                # è®©ç”¨æˆ·é€‰æ‹©å…³é”®åˆ—
                source_col = st.selectbox(
                    "æ•°æ®æ¥æºåˆ—",
                    options=arpu_df.columns,
                    help="é€‰æ‹©æ ‡è¯†æ•°æ®æ¥æºçš„åˆ—"
                )
                
                arpu_col = st.selectbox(
                    "ARPUå€¼åˆ—",
                    options=arpu_df.columns,
                    help="é€‰æ‹©åŒ…å«ARPUå€¼çš„åˆ—"
                )
                
                date_col = st.selectbox(
                    "æ—¥æœŸåˆ— (å¯é€‰)",
                    options=['æ— '] + list(arpu_df.columns),
                    help="å¦‚æœæœ‰æ—¥æœŸåˆ—ï¼Œè¯·é€‰æ‹©"
                )
            
            with col2:
                st.subheader("æ•°æ®ç»Ÿè®¡")
                
                # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡
                if arpu_col in arpu_df.columns:
                    arpu_values = pd.to_numeric(arpu_df[arpu_col], errors='coerce')
                    
                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.metric("å¹³å‡ARPU", f"{arpu_values.mean():.2f}")
                        st.metric("æœ€å°å€¼", f"{arpu_values.min():.2f}")
                    with col_b:
                        st.metric("æœ€å¤§å€¼", f"{arpu_values.max():.2f}")
                        st.metric("æœ‰æ•ˆè®°å½•", f"{arpu_values.notna().sum()}")
            
            # å¤„ç†ARPUæ•°æ®
            if st.button("ä¿å­˜ARPUæ•°æ®", type="primary", use_container_width=True):
                try:
                    # æ ‡å‡†åŒ–ARPUæ•°æ®
                    processed_arpu = arpu_df.copy()
                    processed_arpu['data_source'] = processed_arpu[source_col]
                    processed_arpu['arpu_value'] = pd.to_numeric(processed_arpu[arpu_col], errors='coerce')
                    
                    if date_col != 'æ— ':
                        processed_arpu['date'] = processed_arpu[date_col]
                    
                    # æŒ‰æ•°æ®æ¥æºæ±‡æ€»ARPU
                    arpu_summary = processed_arpu.groupby('data_source')['arpu_value'].mean().reset_index()
                    
                    st.session_state.arpu_data = arpu_summary
                    
                    st.success("ARPUæ•°æ®å¤„ç†å®Œæˆï¼")
                    
                    # æ˜¾ç¤ºæ±‡æ€»ç»“æœ
                    st.subheader("ARPUæ±‡æ€»ç»“æœ")
                    st.dataframe(arpu_summary, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"ARPUæ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")
        
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
    
    else:
        st.info("è¯·ä¸Šä¼ ARPUæ•°æ®æ–‡ä»¶")
        
        # å¦‚æœæ²¡æœ‰ARPUæ•°æ®ï¼Œæä¾›æ‰‹åŠ¨è¾“å…¥é€‰é¡¹
        st.subheader("æ‰‹åŠ¨è®¾ç½®ARPU")
        
        if st.session_state.lt_results:
            # åŸºäºå·²æœ‰çš„LTç»“æœåˆ›å»ºARPUè¾“å…¥
            st.write("ä¸ºæ¯ä¸ªæ•°æ®æ¥æºè®¾ç½®ARPUå€¼ï¼š")
            
            arpu_inputs = {}
            for result in st.session_state.lt_results:
                source = result['data_source']
                arpu_value = st.number_input(
                    f"{source} ARPU",
                    min_value=0.0,
                    value=10.0,
                    step=0.01,
                    format="%.2f"
                )
                arpu_inputs[source] = arpu_value
            
            if st.button("ä¿å­˜æ‰‹åŠ¨ARPUè®¾ç½®", type="primary", use_container_width=True):
                # åˆ›å»ºARPUæ•°æ®æ¡†
                arpu_df = pd.DataFrame([
                    {'data_source': source, 'arpu_value': value} 
                    for source, value in arpu_inputs.items()
                ])
                
                st.session_state.arpu_data = arpu_df
                st.success("ARPUè®¾ç½®å·²ä¿å­˜ï¼")
                st.dataframe(arpu_df, use_container_width=True)
        
        else:
            st.warning("è¯·å…ˆå®ŒæˆLTæ‹Ÿåˆåˆ†æï¼Œç„¶åå†è®¾ç½®ARPU")

elif page == "LTVç»“æœæŠ¥å‘Š":
    st.header("LTVç»“æœæŠ¥å‘Š")
    
    # æ£€æŸ¥å¿…è¦æ•°æ®æ˜¯å¦å­˜åœ¨
    if st.session_state.lt_results is None:
        st.warning("è¯·å…ˆå®ŒæˆLTæ‹Ÿåˆåˆ†æ")
        if st.button("è·³è½¬åˆ°LTæ‹Ÿåˆåˆ†æ"):
            st.experimental_rerun()
    elif st.session_state.arpu_data is None:
        st.warning("è¯·å…ˆå®ŒæˆARPUè®¡ç®—")
        if st.button("è·³è½¬åˆ°ARPUè®¡ç®—"):
            st.experimental_rerun()
    else:
        # è®¡ç®—LTV
        lt_results = st.session_state.lt_results
        arpu_data = st.session_state.arpu_data
        
        # åˆå¹¶LTå’ŒARPUæ•°æ®
        ltv_results = []
        
        for lt_result in lt_results:
            source = lt_result['data_source']
            lt_value = lt_result['lt_value']
            
            # æŸ¥æ‰¾å¯¹åº”çš„ARPUå€¼
            arpu_row = arpu_data[arpu_data['data_source'] == source]
            if not arpu_row.empty:
                arpu_value = arpu_row.iloc[0]['arpu_value']
            else:
                arpu_value = 0  # å¦‚æœæ‰¾ä¸åˆ°ARPUï¼Œè®¾ä¸º0
            
            # è®¡ç®—LTV
            ltv_value = lt_value * arpu_value
            
            ltv_results.append({
                'data_source': source,
                'lt_value': lt_value,
                'arpu_value': arpu_value,
                'ltv_value': ltv_value,
                'model_used': lt_result['model_used'],
                'r2_score': lt_result['r2_score']
            })
        
        st.session_state.ltv_results = ltv_results
        
        # æ˜¾ç¤ºLTVç»“æœ
        st.subheader("LTVè®¡ç®—ç»“æœ")
        
        # åˆ›å»ºç»“æœè¡¨æ ¼
        ltv_df = pd.DataFrame(ltv_results)
        ltv_df = ltv_df.rename(columns={
            'data_source': 'æ•°æ®æ¥æº',
            'lt_value': 'LTå€¼',
            'arpu_value': 'ARPU',
            'ltv_value': 'LTV',
            'model_used': 'æ‹Ÿåˆæ¨¡å‹',
            'r2_score': 'RÂ²å¾—åˆ†'
        })
        
        # æ ¼å¼åŒ–æ˜¾ç¤º
        ltv_df['LTå€¼'] = ltv_df['LTå€¼'].round(2)
        ltv_df['ARPU'] = ltv_df['ARPU'].round(2)
        ltv_df['LTV'] = ltv_df['LTV'].round(2)
        ltv_df['RÂ²å¾—åˆ†'] = ltv_df['RÂ²å¾—åˆ†'].round(4)
        
        st.dataframe(ltv_df, use_container_width=True)
        
        # å…³é”®æŒ‡æ ‡å±•ç¤º
        st.subheader("å…³é”®æŒ‡æ ‡")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_ltv = ltv_df['LTV'].mean()
            st.metric("å¹³å‡LTV", f"{avg_ltv:.2f}")
        
        with col2:
            max_ltv = ltv_df['LTV'].max()
            best_source = ltv_df.loc[ltv_df['LTV'].idxmax(), 'æ•°æ®æ¥æº']
            st.metric("æœ€é«˜LTV", f"{max_ltv:.2f}", delta=best_source)
        
        with col3:
            avg_lt = ltv_df['LTå€¼'].mean()
            st.metric("å¹³å‡LT", f"{avg_lt:.2f}")
        
        with col4:
            avg_arpu = ltv_df['ARPU'].mean()
            st.metric("å¹³å‡ARPU", f"{avg_arpu:.2f}")
        
        # LTVå¯¹æ¯”å›¾è¡¨
        st.subheader("LTVå¯¹æ¯”åˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # LTVæ¡å½¢å›¾
            fig, ax = plt.subplots(figsize=(10, 6))
            bars = ax.bar(ltv_df['æ•°æ®æ¥æº'], ltv_df['LTV'], color='steelblue', alpha=0.7)
            ax.set_xlabel('æ•°æ®æ¥æº')
            ax.set_ylabel('LTVå€¼')
            ax.set_title('å„æ¸ é“LTVå¯¹æ¯”')
            ax.tick_params(axis='x', rotation=45)
            
            # åœ¨æ¡å½¢å›¾ä¸Šæ˜¾ç¤ºæ•°å€¼
            for bar, value in zip(bars, ltv_df['LTV']):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                       f'{value:.1f}', ha='center', va='bottom')
            
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
        
        with col2:
            # LT vs ARPUæ•£ç‚¹å›¾
            fig, ax = plt.subplots(figsize=(10, 6))
            scatter = ax.scatter(ltv_df['LTå€¼'], ltv_df['ARPU'], 
                               c=ltv_df['LTV'], s=100, alpha=0.7, cmap='viridis')
            
            # æ·»åŠ æ•°æ®æºæ ‡ç­¾
            for i, source in enumerate(ltv_df['æ•°æ®æ¥æº']):
                ax.annotate(source, (ltv_df['LTå€¼'].iloc[i], ltv_df['ARPU'].iloc[i]),
                           xytext=(5, 5), textcoords='offset points', fontsize=8)
            
            ax.set_xlabel('LTå€¼')
            ax.set_ylabel('ARPU')
            ax.set_title('LT vs ARPU å…³ç³»å›¾')
            
            # æ·»åŠ é¢œè‰²æ¡
            cbar = plt.colorbar(scatter)
            cbar.set_label('LTVå€¼')
            
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
        
        # æ¨¡å‹è´¨é‡åˆ†æ
        st.subheader("æ¨¡å‹è´¨é‡åˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # RÂ²å¾—åˆ†åˆ†å¸ƒ
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.bar(ltv_df['æ•°æ®æ¥æº'], ltv_df['RÂ²å¾—åˆ†'], color='lightcoral', alpha=0.7)
            ax.set_xlabel('æ•°æ®æ¥æº')
            ax.set_ylabel('RÂ²å¾—åˆ†')
            ax.set_title('æ¨¡å‹æ‹Ÿåˆè´¨é‡ (RÂ²å¾—åˆ†)')
            ax.tick_params(axis='x', rotation=45)
            ax.set_ylim(0, 1)
            
            # æ·»åŠ è´¨é‡è¯„ä»·çº¿
            ax.axhline(y=0.8, color='green', linestyle='--', alpha=0.7, label='ä¼˜ç§€ (0.8+)')
            ax.axhline(y=0.6, color='orange', linestyle='--', alpha=0.7, label='è‰¯å¥½ (0.6+)')
            ax.axhline(y=0.4, color='red', linestyle='--', alpha=0.7, label='ä¸€èˆ¬ (0.4+)')
            ax.legend()
            
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
        
        with col2:
            # æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡
            model_counts = ltv_df['æ‹Ÿåˆæ¨¡å‹'].value_counts()
            
            fig, ax = plt.subplots(figsize=(8, 6))
            colors = ['lightblue', 'lightgreen']
            wedges, texts, autotexts = ax.pie(model_counts.values, labels=model_counts.index, 
                                             autopct='%1.1f%%', colors=colors, startangle=90)
            ax.set_title('æ‹Ÿåˆæ¨¡å‹ä½¿ç”¨åˆ†å¸ƒ')
            
            st.pyplot(fig)
            plt.close()
        
        # å¯¼å‡ºåŠŸèƒ½
        st.subheader("ç»“æœå¯¼å‡º")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å‡†å¤‡å¯¼å‡ºæ•°æ®
            export_df = ltv_df.copy()
            
            # è½¬æ¢ä¸ºCSV
            csv_data = export_df.to_csv(index=False, encoding='utf-8-sig')
            
            st.download_button(
                label="ä¸‹è½½LTVç»“æœ (CSV)",
                data=csv_data,
                file_name=f"LTV_Results_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col2:
            # åˆ›å»ºè¯¦ç»†æŠ¥å‘Š
            report_text = f"""
LTVåˆ†ææŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

=== æ€»ä½“æŒ‡æ ‡ ===
å‚ä¸åˆ†æçš„æ•°æ®æºæ•°é‡: {len(ltv_df)}
å¹³å‡LTV: {avg_ltv:.2f}
æœ€é«˜LTV: {max_ltv:.2f} ({best_source})
å¹³å‡LT: {avg_lt:.2f}
å¹³å‡ARPU: {avg_arpu:.2f}

=== è¯¦ç»†ç»“æœ ===
"""
            
            for _, row in ltv_df.iterrows():
                report_text += f"""
{row['æ•°æ®æ¥æº']}:
  LTå€¼: {row['LTå€¼']:.2f}
  ARPU: {row['ARPU']:.2f}
  LTV: {row['LTV']:.2f}
  æ‹Ÿåˆæ¨¡å‹: {row['æ‹Ÿåˆæ¨¡å‹']}
  RÂ²å¾—åˆ†: {row['RÂ²å¾—åˆ†']:.4f}
"""
            
            st.download_button(
                label="ä¸‹è½½è¯¦ç»†æŠ¥å‘Š (TXT)",
                data=report_text,
                file_name=f"LTV_Report_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                mime="text/plain",
                use_container_width=True
            )

# åº•éƒ¨ä¿¡æ¯
st.sidebar.markdown("---")
st.sidebar.markdown("### åˆ†ææ­¥éª¤")
st.sidebar.markdown("""
1. **æ•°æ®ä¸Šä¼ ä¸æ±‡æ€»** - ä¸Šä¼ åŸå§‹æ•°æ®æ–‡ä»¶
2. **ç•™å­˜ç‡è®¡ç®—** - è®¡ç®—ç”¨æˆ·ç•™å­˜ç‡
3. **LTæ‹Ÿåˆåˆ†æ** - æ‹Ÿåˆç”Ÿå‘½å‘¨æœŸæ›²çº¿
4. **ARPUè®¡ç®—** - è®¾ç½®/è®¡ç®—ç”¨æˆ·ä»·å€¼
5. **LTVç»“æœæŠ¥å‘Š** - ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
""")

st.sidebar.markdown("---")
st.sidebar.info("**æç¤º**: è¯·æŒ‰ç…§æµç¨‹é¡ºåºå®Œæˆå„ä¸ªæ­¥éª¤ï¼Œæ¯ä¸€æ­¥çš„ç»“æœéƒ½ä¼šä¿å­˜åœ¨å½“å‰ä¼šè¯ä¸­ã€‚")
