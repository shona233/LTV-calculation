import streamlit as st
import os
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
import datetime
import tempfile
import zipfile
import io
import matplotlib.pyplot as plt
import matplotlib as mpl
import re
from matplotlib.font_manager import FontProperties
import seaborn as sns
from scipy.optimize import curve_fit

# ==================== åŸºç¡€é…ç½® ====================
# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl.styles.stylesheet')
warnings.filterwarnings('ignore', category=UserWarning,
                        message="Could not infer format, so each element will be parsed individually")

# è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ - å¢å¼ºç‰ˆæœ¬
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    try:
        import matplotlib.font_manager as fm
        
        # ç³»ç»Ÿä¸­æ–‡å­—ä½“åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        chinese_fonts = [
            'SimHei',           # é»‘ä½“
            'Microsoft YaHei',  # å¾®è½¯é›…é»‘
            'SimSun',          # å®‹ä½“
            'KaiTi',           # æ¥·ä½“
            'FangSong',        # ä»¿å®‹
            'STSong',          # åæ–‡å®‹ä½“
            'STHeiti',         # åæ–‡é»‘ä½“
            'Arial Unicode MS', # Arial Unicode MS
            'DejaVu Sans',     # å¤‡ç”¨å­—ä½“
        ]
        
        # è·å–ç³»ç»Ÿæ‰€æœ‰å¯ç”¨å­—ä½“
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“
        selected_font = None
        for font in chinese_fonts:
            if font in available_fonts:
                selected_font = font
                break
        
        if selected_font:
            # è®¾ç½®matplotlibä¸­æ–‡å­—ä½“
            plt.rcParams['font.sans-serif'] = [selected_font, 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS']
            plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
            plt.rcParams['font.size'] = 10
            return True
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS']
            plt.rcParams['axes.unicode_minus'] = False
            plt.rcParams['font.size'] = 10
            return False
        
    except Exception as e:
        # ä½¿ç”¨é»˜è®¤è®¾ç½®ä½œä¸ºå¤‡ç”¨
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS']
        plt.rcParams['axes.unicode_minus'] = False
        plt.rcParams['font.size'] = 10
        return False

# åˆå§‹åŒ–å­—ä½“è®¾ç½®
setup_chinese_font()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="LTV Analytics Platform",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="ğŸ“Š"
)

# ==================== CSS æ ·å¼å®šä¹‰ ====================
# å•†ä¸šè“è‰²ç³»é…è‰²æ ·å¼ï¼ˆä¿®æ”¹äº¤äº’é¢œè‰²ä¸ºé»„è‰²ï¼‰
st.markdown("""
<style>
    /* å…¨å±€æ ·å¼ */
    .main {
        background: #f8fafc;
        min-height: 100vh;
    }

    .block-container {
        padding: 1rem 1rem 3rem 1rem;
        max-width: 100%;
        background: transparent;
    }

    /* ä¸»æ ‡é¢˜åŒºåŸŸ */
    .main-header {
        background: linear-gradient(135deg, #1e40af 0%, #3b82f6 100%);
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 20px rgba(30, 64, 175, 0.3);
        margin-bottom: 1.5rem;
        text-align: center;
        color: white;
    }

    .main-title {
        font-size: 2rem;
        font-weight: 700;
        color: white;
        margin-bottom: 0.5rem;
        text-shadow: 0 2px 4px rgba(0,0,0,0.3);
    }

    .main-subtitle {
        color: rgba(255,255,255,0.9);
        font-size: 1.2rem;
        font-weight: 400;
    }

    /* å¡ç‰‡æ ·å¼ */
    .glass-card {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 12px;
        padding: 1.5rem;
        box-shadow: 0 8px 32px rgba(30, 64, 175, 0.1);
        border: 1px solid rgba(59, 130, 246, 0.2);
        margin-bottom: 1.5rem;
        backdrop-filter: blur(10px);
    }

    /* åˆ†ç•Œçº¿ */
    .section-divider {
        height: 2px;
        background: linear-gradient(90deg, #1e40af, #3b82f6);
        margin: 1.5rem 0;
    }

    /* æŒ‡æ ‡å¡ç‰‡ */
    .metric-card {
        background: linear-gradient(135deg, #2563eb 0%, #1d4ed8 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 12px;
        text-align: center;
        margin-bottom: 1rem;
        box-shadow: 0 4px 15px rgba(37, 99, 235, 0.3);
    }

    .metric-value {
        font-size: 2.2rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        color: white;
        text-shadow: 0 2px 4px rgba(0,0,0,0.3);
    }

    .metric-label {
        font-size: 0.95rem;
        color: rgba(255,255,255,0.9);
    }

    /* çŠ¶æ€å¡ç‰‡ */
    .status-card {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        border-left: 4px solid #1e40af;
        box-shadow: 0 4px 15px rgba(30, 64, 175, 0.1);
        margin-bottom: 1rem;
    }

    /* å¯¼èˆªæ­¥éª¤æ ·å¼ */
    .nav-container {
        background: linear-gradient(135deg, #1e40af 0%, #3b82f6 100%);
        border-radius: 12px;
        padding: 1.5rem;
        margin-bottom: 1rem;
        color: white;
        box-shadow: 0 4px 20px rgba(30, 64, 175, 0.3);
    }

    /* æ­¥éª¤è¯¦æƒ…æ ·å¼ */
    .step-details {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 8px;
        padding: 0.8rem;
        margin-top: 0.5rem;
        font-size: 0.85rem;
        color: rgba(255,255,255,0.8);
    }

    .step-details ul {
        margin: 0.3rem 0;
        padding-left: 1rem;
        list-style-type: disc;
    }

    .step-details li {
        margin-bottom: 0.2rem;
        line-height: 1.4;
    }

    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #1e40af 0%, #3b82f6 100%);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.6rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(30, 64, 175, 0.3);
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(30, 64, 175, 0.4);
    }

    /* é€‰æ‹©æ¡†æ ·å¼ - ä¿®æ”¹ä¸ºé»„è‰²äº¤äº’ */
    .stSelectbox label, .stMultiselect label, .stFileUploader label {
        font-weight: 600;
        color: #1e40af;
        margin-bottom: 0.5rem;
    }

    .stSelectbox > div > div > div {
        border-color: #f59e0b !important;
    }

    .stSelectbox > div > div > div:focus-within {
        border-color: #f59e0b !important;
        box-shadow: 0 0 0 1px #f59e0b !important;
    }

    .stMultiSelect > div > div > div {
        border-color: #f59e0b !important;
    }

    .stMultiSelect > div > div > div:focus-within {
        border-color: #f59e0b !important;
        box-shadow: 0 0 0 1px #f59e0b !important;
    }

    /* æ ‡é¢˜æ ·å¼ */
    h1, h2, h3, h4 {
        color: #1e40af;
        font-weight: 600;
        font-size: 1.2rem !important;
    }

    /* è¯´æ˜æ–‡å­—æ ·å¼ */
    .step-explanation {
        background: linear-gradient(135deg, rgba(30, 64, 175, 0.1) 0%, rgba(59, 130, 246, 0.1) 100%);
        border-left: 4px solid #1e40af;
        padding: 1.5rem;
        margin-top: 2rem;
        border-radius: 0 12px 12px 0;
    }

    .step-explanation h4 {
        color: #1e40af;
        margin-bottom: 0.8rem;
        font-size: 1.2rem;
        font-weight: 700;
    }

    .step-explanation ul {
        margin: 0.5rem 0;
        padding-left: 1.5rem;
        list-style-type: disc;
    }

    .step-explanation li {
        margin-bottom: 0.5rem;
        color: #1e40af;
        line-height: 1.6;
    }

    .step-explanation strong {
        color: #1e40af;
        font-weight: 600;
    }

    /* åŸç†è§£é‡Šæ¡†æ ·å¼ */
    .principle-box {
        background: rgba(59, 130, 246, 0.05);
        border: 1px solid rgba(59, 130, 246, 0.2);
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }

    .principle-title {
        color: #1e40af;
        font-weight: 600;
        font-size: 1rem;
        margin-bottom: 0.5rem;
    }

    .principle-content {
        color: #374151;
        font-size: 0.9rem;
        line-height: 1.5;
    }

    /* æç¤ºæ¡†æ ·å¼ */
    .step-tip {
        background: #eff6ff;
        border: 1px solid #bfdbfe;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        border-left: 4px solid #3b82f6;
    }

    .step-tip-title {
        color: #1e40af;
        font-weight: 600;
        font-size: 0.95rem;
        margin-bottom: 0.5rem;
    }

    .step-tip-content {
        color: #374151;
        font-size: 0.85rem;
        line-height: 1.4;
    }

    /* å‰”é™¤ä¿¡æ¯æ ·å¼ */
    .exclusion-info {
        background: #fef2f2;
        border: 1px solid #fecaca;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        border-left: 4px solid #ef4444;
    }

    .exclusion-info-title {
        color: #dc2626;
        font-weight: 600;
        font-size: 0.95rem;
        margin-bottom: 0.5rem;
    }

    .exclusion-info-content {
        color: #374151;
        font-size: 0.85rem;
        line-height: 1.4;
    }

    /* æ•°æ®æ¥æºæç¤ºæ ·å¼ */
    .data-source-info {
        background: #f0fdf4;
        border: 1px solid #bbf7d0;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        border-left: 4px solid #22c55e;
    }

    .data-source-info-title {
        color: #16a34a;
        font-weight: 600;
        font-size: 0.95rem;
        margin-bottom: 0.5rem;
    }

    .data-source-info-content {
        color: #374151;
        font-size: 0.85rem;
        line-height: 1.4;
    }

    /* è­¦å‘Šæ ·å¼ - ä¿®æ”¹ä¸ºé»„è‰² */
    .stAlert > div {
        background-color: #fef3c7 !important;
        border-color: #f59e0b !important;
        color: #92400e !important;
    }

    /* éšè—é»˜è®¤çš„Streamlitå…ƒç´  */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ==================== é»˜è®¤é…ç½®æ•°æ® ====================
# ä¿®æ”¹é»˜è®¤æ¸ é“æ˜ å°„æ•°æ® - æ”¹ä¸ºåç§°å¯¹åº”å¤šä¸ªæ¸ é“å·
DEFAULT_CHANNEL_MAPPING = {
    'æ€»ä½“': ['9000'],
    'æ–°åª’ä½“': ['500345', '500346', '500447', '500449', '500450', '500531', '500542'],
    'åº”ç”¨å®': ['5007XS', '500349', '500350'],
    'é¼ä¹-ç››ä¸–6': ['500285'],
    'é¼ä¹-ç››ä¸–7': ['500286'],
    'é…·æ´¾': ['5108', '5528'],
    'æ–°ç¾-åŒ—äº¬2': ['500275'],
    'æ–°ç¾-åŒ—äº¬1': ['500274'],
    'A_æ·±åœ³è›‹ä¸2': ['500316'],
    'è£è€€': ['500297'],
    'åä¸º': ['5057'],
    'vivo': ['5237'],
    'å°ç±³': ['5599'],
    'OPPO': ['5115'],
    'ç½‘æ˜“': ['500471', '500480', '500481', '500482'],
    'åä¸ºéå•†åº—-å“ä¼—': ['500337', '500338', '500343', '500445', '500383', '500444', '500441'],
    'é­…æ—': ['5072'],
    'OPPOéå•†åº—': ['500287', '500288'],
    'vivoéå•†åº—': ['5187'],
    'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£å®‰å“': ['500398', '500400', '500404'],
    'ç™¾åº¦sem--ç™¾åº¦æ—¶ä»£ios': ['500402', '500403', '500405'],
    'ç™¾é’è—¤-å®‰å“': ['500377', '500379', '500435', '500436', '500490', '500491', '500434', '500492'],
    'ç™¾é’è—¤-ios': ['500437'],
    'å°ç±³éå•†åº—': ['500170'],
    'åä¸ºéå•†åº—-æ˜Ÿç«': ['500532', '500533', '500534', '500537', '500538', '500539', '500540', '500541'],
    'å¾®åš-èœœæ©˜': ['500504', '500505'],
    'å¾®åš-å¤®å¹¿': ['500367', '500368', '500369'],
    'å¹¿ç‚¹é€š': ['500498', '500497', '500500', '500501', '500496', '500499'],
    'ç½‘æ˜“æ˜“æ•ˆ': ['500514', '500515', '500516']
}

# ==================== æ—¥æœŸå¤„ç†å‡½æ•° ====================
# è®¡ç®—é»˜è®¤ç›®æ ‡æœˆä»½ï¼ˆ2ä¸ªæœˆå‰ï¼‰
def get_default_target_month():
    today = datetime.datetime.now()
    if today.month <= 2:
        target_year = today.year - 1
        target_month = today.month + 10
    else:
        target_year = today.year
        target_month = today.month - 2
    return f"{target_year}-{target_month:02d}"

# ==================== æ•°æ®ç±»å‹è½¬æ¢å‡½æ•° ====================
def safe_convert_to_numeric(value):
    """
    å®‰å…¨åœ°å°†å€¼è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
    """
    if pd.isna(value) or value == '' or value is None:
        return 0
    try:
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå…ˆå»é™¤ç©ºæ ¼
        if isinstance(value, str):
            value = value.strip()
            if value == '' or value.lower() in ['nan', 'null', 'none']:
                return 0
        return pd.to_numeric(value, errors='coerce')
    except:
        return 0

# ==================== æ•°æ®ç»“æ„æ ‡å‡†åŒ–å‡½æ•° ====================
def standardize_output_columns(df):
    """
    æ ‡å‡†åŒ–è¾“å‡ºåˆ—ç»“æ„ï¼Œç¡®ä¿åŒ…å«æŒ‡å®šçš„åˆ—é¡ºåºï¼Œå¹¶æ­£ç¡®å¤„ç†æ•°æ®ç±»å‹
    """
    print("æ­£åœ¨æ ‡å‡†åŒ–è¾“å‡ºåˆ—ç»“æ„...")

    # å®šä¹‰ç›®æ ‡åˆ—é¡ºåº
    target_columns = [
        'æ•°æ®æ¥æº', 'date', 'æ•°æ®æ¥æº_date',
        '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',
        '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',
        '21', '22', '23', '24', '25', '26', '27', '28', '29', '30',
        'æ•°æ®æ¥æº_æ—¥æœŸ', 'æ—¥æœŸ', 'å›ä¼ æ–°å¢æ•°', 'is_target_month', 'month', 'stat_date'
    ]

    # æŒ‰ç›®æ ‡åˆ—é¡ºåºåˆ›å»ºç»“æœDataFrame
    result_df = pd.DataFrame()

    # æŒ‰ç²¾ç¡®é¡ºåºæ·»åŠ æ¯ä¸€åˆ—
    for col_name in target_columns:
        if col_name == 'æ•°æ®æ¥æº':
            result_df[col_name] = df[col_name].astype(str) if col_name in df.columns else ''
        elif col_name == 'date':
            if col_name in df.columns:
                result_df[col_name] = df[col_name].astype(str)
            elif 'stat_date' in df.columns:
                result_df[col_name] = df['stat_date'].astype(str)
            else:
                result_df[col_name] = ''
        elif col_name == 'æ•°æ®æ¥æº_date':
            # åˆ›å»ºæ•°æ®æ¥æº_dateåˆ—
            data_source = df['æ•°æ®æ¥æº'].astype(str) if 'æ•°æ®æ¥æº' in df.columns else pd.Series([''] * len(df))
            
            if 'date' in df.columns:
                date_col_str = df['date'].astype(str)
            elif 'stat_date' in df.columns:
                date_col_str = df['stat_date'].astype(str)
            else:
                date_col_str = pd.Series([''] * len(df))

            result_df[col_name] = data_source + date_col_str
        elif col_name == 'æ•°æ®æ¥æº_æ—¥æœŸ':
            # åˆ›å»ºæ•°æ®æ¥æº_æ—¥æœŸåˆ—
            data_source = df['æ•°æ®æ¥æº'].astype(str) if 'æ•°æ®æ¥æº' in df.columns else pd.Series([''] * len(df))

            if 'æ—¥æœŸ' in df.columns:
                date_col_str = df['æ—¥æœŸ'].astype(str)
            elif 'date' in df.columns:
                date_col_str = df['date'].astype(str)
            elif 'stat_date' in df.columns:
                date_col_str = df['stat_date'].astype(str)
            else:
                date_col_str = pd.Series([''] * len(df))

            result_df[col_name] = data_source + date_col_str
        elif col_name in ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10',
                          '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',
                          '21', '22', '23', '24', '25', '26', '27', '28', '29', '30']:
            # æ•°å­—åˆ—ï¼šç¡®ä¿è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
            if col_name in df.columns:
                result_df[col_name] = df[col_name].apply(safe_convert_to_numeric)
            else:
                result_df[col_name] = 0
        elif col_name == 'å›ä¼ æ–°å¢æ•°':
            # å›ä¼ æ–°å¢æ•°åˆ—ï¼šç¡®ä¿è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
            if col_name in df.columns:
                result_df[col_name] = df[col_name].apply(safe_convert_to_numeric)
            else:
                result_df[col_name] = 0
        else:
            # å…¶ä»–åˆ—ç›´æ¥å¤åˆ¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å¡«ç©º
            if col_name in df.columns:
                result_df[col_name] = df[col_name]
            else:
                result_df[col_name] = ''

    # æ·»åŠ åŸæ•°æ®ä¸­å­˜åœ¨ä½†ä¸åœ¨ç›®æ ‡åˆ—è¡¨ä¸­çš„å…¶ä»–åˆ—ï¼ˆä¿æŒåœ¨æœ€åï¼‰
    for col in df.columns:
        if col not in target_columns:
            result_df[col] = df[col]

    print(f"å·²æ ‡å‡†åŒ–è¾“å‡ºåˆ—ç»“æ„ï¼Œå…± {len(result_df.columns)} åˆ—ï¼ŒæŒ‰æŒ‡å®šé¡ºåºæ’åˆ—")
    return result_df

# ==================== æ¸ é“æ˜ å°„å¤„ç†å‡½æ•° ====================
def parse_channel_mapping_from_excel(channel_file):
    """
    ä»ä¸Šä¼ çš„Excelæ–‡ä»¶è§£ææ¸ é“æ˜ å°„ï¼Œè¿”å›æ¸ é“åç§°åˆ°æ¸ é“å·åˆ—è¡¨çš„æ˜ å°„
    """
    try:
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(channel_file)
        
        channel_to_pids = {}
        
        # éå†æ¯ä¸€è¡Œ
        for _, row in df.iterrows():
            # ç¬¬ä¸€åˆ—æ˜¯æ¸ é“åç§°
            channel_name = str(row.iloc[0]).strip()
            if pd.isna(channel_name) or channel_name == '' or channel_name == 'nan':
                continue
                
            # ä»ç¬¬äºŒåˆ—å¼€å§‹æ˜¯æ¸ é“å·
            pids = []
            for col_idx in range(1, len(row)):
                pid = row.iloc[col_idx]
                if pd.isna(pid) or str(pid).strip() in ['', 'nan', 'ã€€', ' ']:
                    continue
                # ç¡®ä¿æ¸ é“å·æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œå»é™¤å°æ•°
                pid_str = str(int(float(pid))) if isinstance(pid, (int, float)) else str(pid).strip()
                if pid_str:
                    pids.append(pid_str)
            
            if pids:
                channel_to_pids[channel_name] = pids
                    
        return channel_to_pids
    except Exception as e:
        st.error(f"è§£ææ¸ é“æ˜ å°„æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
        return {}

def convert_mapping_for_lookup(channel_to_pids):
    """
    å°†æ¸ é“åç§°åˆ°æ¸ é“å·åˆ—è¡¨çš„æ˜ å°„è½¬æ¢ä¸ºæ¸ é“å·åˆ°æ¸ é“åç§°çš„æ˜ å°„
    """
    pid_to_channel = {}
    for channel_name, pids in channel_to_pids.items():
        for pid in pids:
            pid_to_channel[str(pid)] = channel_name
    return pid_to_channel

# ==================== æ–‡ä»¶æ•´åˆæ ¸å¿ƒå‡½æ•° ====================
def integrate_excel_files_streamlit(uploaded_files, target_month=None, channel_mapping=None):
    """
    æ•´åˆä¸Šä¼ çš„Excelæ–‡ä»¶ï¼Œæ”¯æŒæ–°æ ¼å¼è¡¨å’Œä¼ ç»Ÿæ ¼å¼è¡¨ï¼Œä¼˜åŒ–è¯»å–é€Ÿåº¦
    """
    if target_month is None:
        target_month = get_default_target_month()

    all_data = pd.DataFrame()
    processed_count = 0
    mapping_warnings = []
    file_previews = []  # å­˜å‚¨æ¯ä¸ªæ–‡ä»¶çš„é¢„è§ˆæ•°æ®

    for uploaded_file in uploaded_files:
        source_name = os.path.splitext(uploaded_file.name)[0]

        # æ¸ é“æ˜ å°„å¤„ç†
        if channel_mapping and source_name in channel_mapping:
            mapped_source = channel_mapping[source_name]
        else:
            mapped_source = source_name
            if channel_mapping:
                mapping_warnings.append(f"æ–‡ä»¶ '{source_name}' æœªåœ¨æ¸ é“æ˜ å°„è¡¨ä¸­æ‰¾åˆ°å¯¹åº”é¡¹")

        try:
            # ä¼˜åŒ–æ–‡ä»¶è¯»å– - åªè¯»å–éœ€è¦çš„åˆ—å’Œè¡Œ
            try:
                # å…ˆè¯»å–æ–‡ä»¶ä¿¡æ¯
                xls = pd.ExcelFile(uploaded_file)
                sheet_names = xls.sheet_names

                # æŸ¥æ‰¾ç›®æ ‡å·¥ä½œè¡¨
                ocpx_sheet = None
                for sheet in sheet_names:
                    if "ocpxç›‘æµ‹ç•™å­˜æ•°" in sheet:
                        ocpx_sheet = sheet
                        break

                if ocpx_sheet:
                    file_data = pd.read_excel(uploaded_file, sheet_name=ocpx_sheet, nrows=1000)  # é™åˆ¶è¯»å–è¡Œæ•°
                else:
                    file_data = pd.read_excel(uploaded_file, sheet_name=0, nrows=1000)  # é™åˆ¶è¯»å–è¡Œæ•°
            except Exception:
                # å¦‚æœå¿«é€Ÿè¯»å–å¤±è´¥ï¼Œä½¿ç”¨å¸¸è§„æ–¹æ³•
                file_data = pd.read_excel(uploaded_file, sheet_name=0)

            if file_data is not None and not file_data.empty:
                # æ·»åŠ æ–‡ä»¶é¢„è§ˆæ•°æ®ï¼ˆå–å‰2è¡Œï¼‰
                preview_data = file_data.head(2).copy()
                preview_data.insert(0, 'æ–‡ä»¶å', uploaded_file.name)
                file_previews.append(preview_data)
                
                file_data_copy = file_data.copy()

                # ========== æ£€æµ‹æ–‡ä»¶æ ¼å¼ç±»å‹ ==========
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ ¼å¼è¡¨ï¼ˆåŒ…å«stat_dateå’Œç•™å­˜åˆ—ï¼‰
                is_new_format = False
                has_stat_date = 'stat_date' in file_data_copy.columns
                retain_columns = [f'new_retain_{i}' for i in range(1, 31)]
                has_retain_columns = any(col in file_data_copy.columns for col in retain_columns)

                # ========== å¤„ç†æ–°æ ¼å¼è¡¨ ==========
                if has_stat_date and has_retain_columns:
                    is_new_format = True
                    print(f"æ£€æµ‹åˆ° {uploaded_file.name} æ˜¯æ–°æ ¼å¼è¡¨ï¼ˆå«stat_dateå’Œç•™å­˜åˆ—ï¼‰")

                    # åˆ›å»ºæ ‡å‡†çš„è¾“å‡ºç»“æ„
                    standardized_data = file_data_copy.copy()

                    # å°†newåˆ—çš„å€¼æ˜ å°„åˆ°"å›ä¼ æ–°å¢æ•°"åˆ—ï¼Œç¡®ä¿æ˜¯æ•°å€¼ç±»å‹
                    if 'new' in standardized_data.columns:
                        standardized_data['å›ä¼ æ–°å¢æ•°'] = standardized_data['new'].apply(safe_convert_to_numeric)

                    # å°†new_retain_1åˆ°new_retain_30çš„å€¼åˆ†åˆ«æ˜ å°„åˆ°æ•°å­—åˆ—å(1åˆ°30)ï¼Œç¡®ä¿æ˜¯æ•°å€¼ç±»å‹
                    for i in range(1, 31):
                        retain_col = f'new_retain_{i}'
                        if retain_col in standardized_data.columns:
                            standardized_data[str(i)] = standardized_data[retain_col].apply(safe_convert_to_numeric)

                    # ç¡®ä¿stat_dateè¢«è§†ä¸ºæ—¥æœŸåˆ—
                    date_col = 'stat_date'
                    standardized_data[date_col] = pd.to_datetime(standardized_data[date_col], errors='coerce')
                    # å°†æ—¥æœŸè½¬ä¸ºå­—ç¬¦ä¸²æ ¼å¼
                    standardized_data[date_col] = standardized_data[date_col].dt.strftime('%Y-%m-%d')
                    # æ·»åŠ "æ—¥æœŸ"åˆ—ï¼Œä¸stat_dateç›¸åŒ
                    standardized_data['æ—¥æœŸ'] = standardized_data[date_col]
                    # æ·»åŠ æœˆä»½åˆ—
                    standardized_data['month'] = standardized_data[date_col].str[:7]

                    # ç­›é€‰ç›®æ ‡æœˆä»½çš„æ•°æ®
                    filtered_data = standardized_data[standardized_data['month'] == target_month].copy()

                    # å¦‚æœå­˜åœ¨ç•™å­˜å¤©æ•°åˆ—ï¼Œè¿˜è¦ä¿ç•™ç‰¹æ®Šè¡Œ
                    retention_col = None
                    for col in standardized_data.columns:
                        if 'ç•™å­˜å¤©æ•°' in str(col):
                            retention_col = col
                            break

                    if retention_col is not None:
                        # æ‰¾å‡ºç•™å­˜å¤©æ•°ä¸ºç‰¹å®šå€¼çš„è¡Œ
                        special_rows = standardized_data[(standardized_data[retention_col] == "2025-02-01") |
                                                         (standardized_data[retention_col] == "åˆè®¡") |
                                                         (standardized_data[retention_col].astype(
                                                             str) == "2025-02-01") |
                                                         (standardized_data[retention_col].astype(str) == "åˆè®¡")]

                        # åˆå¹¶æ•°æ®æ¡†ï¼šç›®æ ‡æœˆä»½çš„æ•°æ®å’Œç‰¹æ®Šè¡Œ
                        if not special_rows.empty:
                            filtered_data = pd.concat([filtered_data, special_rows]).drop_duplicates()

                    if not filtered_data.empty:
                        # æ·»åŠ æ•°æ®æ¥æºåˆ—
                        filtered_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)

                        # å¤„ç†dateåˆ—
                        if retention_col is not None:
                            filtered_data.rename(columns={retention_col: 'date'}, inplace=True)
                        elif 'stat_date' in filtered_data.columns:
                            filtered_data['date'] = filtered_data['stat_date']

                        # å°†ç­›é€‰åçš„æ•°æ®æ·»åŠ åˆ°æ€»æ•°æ®æ¡†
                        all_data = pd.concat([all_data, filtered_data], ignore_index=True)
                        processed_count += 1

                # ========== å¤„ç†ä¼ ç»Ÿæ ¼å¼è¡¨ ==========
                else:
                    # æŸ¥æ‰¾ç•™å­˜å¤©æ•°åˆ—
                    retention_col = None
                    for col in file_data_copy.columns:
                        if 'ç•™å­˜å¤©æ•°' in str(col):
                            retention_col = col
                            break

                    # æŸ¥æ‰¾å›ä¼ æ–°å¢æ•°åˆ—æˆ–total_new_usersåˆ—
                    report_users_col = None
                    for col in file_data_copy.columns:
                        if 'å›ä¼ æ–°å¢æ•°' in str(col):
                            report_users_col = col
                            break
                        if 'total_new_users' in str(col).lower():
                            report_users_col = col
                            break

                    # è·å–ç¬¬äºŒåˆ—ä½œä¸ºå¤‡é€‰
                    column_b = file_data_copy.columns[1] if len(file_data_copy.columns) > 1 else None

                    # æ£€æŸ¥æ˜¯å¦æœ‰æ—¥æœŸåˆ—
                    date_col = None
                    for col in file_data_copy.columns:
                        if 'æ—¥æœŸ' in str(col):
                            date_col = col
                            break

                    # ========== å¤„ç†å›ä¼ æ–°å¢æ•°åˆ—æ˜ å°„ ==========
                    if report_users_col and report_users_col != 'å›ä¼ æ–°å¢æ•°':
                        file_data_copy['å›ä¼ æ–°å¢æ•°'] = file_data_copy[report_users_col].apply(safe_convert_to_numeric)
                    elif not report_users_col and column_b:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³åˆ—ï¼Œä½¿ç”¨ç¬¬äºŒåˆ—ä½œä¸º"å›ä¼ æ–°å¢æ•°"
                        file_data_copy['å›ä¼ æ–°å¢æ•°'] = file_data_copy[column_b].apply(safe_convert_to_numeric)

                    # ========== å¤„ç†æ•°å­—åˆ—ï¼ˆ1-30å¤©ç•™å­˜æ•°æ®ï¼‰==========
                    for i in range(1, 31):
                        col_name = str(i)
                        if col_name in file_data_copy.columns:
                            file_data_copy[col_name] = file_data_copy[col_name].apply(safe_convert_to_numeric)

                    # ========== å¤„ç†æ—¥æœŸåˆ—æ•°æ®å’Œç­›é€‰ ==========
                    if date_col:
                        # å°†æ—¥æœŸåˆ—è½¬æ¢ä¸ºæ—¥æœŸç±»å‹ä»¥ä¾¿è®¡ç®—å‰åèŒƒå›´
                        try:
                            if not pd.api.types.is_datetime64_dtype(file_data_copy[date_col]):
                                temp_dates = pd.to_datetime(file_data_copy[date_col], errors='coerce')
                                file_data_copy[date_col] = temp_dates

                            # æå–ç›®æ ‡æœˆä»½çš„ç¬¬ä¸€å¤©å’Œæœ€åä¸€å¤©
                            target_year, target_month_num = map(int, target_month.split('-'))
                            first_day_of_month = pd.Timestamp(year=target_year, month=target_month_num, day=1)

                            # è®¡ç®—ä¸‹ä¸€ä¸ªæœˆçš„ç¬¬ä¸€å¤©
                            if target_month_num == 12:
                                next_month = pd.Timestamp(year=target_year + 1, month=1, day=1)
                            else:
                                next_month = pd.Timestamp(year=target_year, month=target_month_num + 1, day=1)

                            # æœ€åä¸€å¤©æ˜¯ä¸‹ä¸€ä¸ªæœˆçš„ç¬¬ä¸€å¤©å‡ä¸€å¤©
                            last_day_of_month = next_month - pd.Timedelta(days=1)

                            # è®¡ç®—ç›®æ ‡èŒƒå›´ï¼ˆæœˆä»½å‰å5å¤©ï¼‰
                            start_date = first_day_of_month - pd.Timedelta(days=5)
                            end_date = last_day_of_month + pd.Timedelta(days=5)

                            # ç­›é€‰æ—¥æœŸåœ¨èŒƒå›´å†…çš„æ•°æ®
                            mask = (file_data_copy[date_col] >= start_date) & (file_data_copy[date_col] <= end_date)

                            # å¦‚æœå­˜åœ¨ç•™å­˜å¤©æ•°åˆ—ï¼Œè¿˜è¦ä¿ç•™ç‰¹æ®Šå€¼çš„è¡Œ
                            if retention_col is not None:
                                # ç”ŸæˆæŒ‡å®šæœˆä»½çš„æ‰€æœ‰æ—¥æœŸå€¼çš„åˆ—è¡¨
                                all_month_dates = []
                                current_date = first_day_of_month
                                while current_date <= last_day_of_month:
                                    date_str = current_date.strftime('%Y-%m-%d')
                                    all_month_dates.append(date_str)
                                    current_date += pd.Timedelta(days=1)

                                # æ·»åŠ "åˆè®¡"ä½œä¸ºç‰¹æ®Šå€¼
                                all_month_dates.append("åˆè®¡")

                                # æ‰¾å‡ºç•™å­˜å¤©æ•°ä¸ºç‰¹å®šå€¼çš„è¡Œ
                                retention_col_str = file_data_copy[retention_col].astype(str)
                                special_rows_mask = np.zeros(len(file_data_copy), dtype=bool)

                                for date_val in all_month_dates:
                                    special_rows_mask = special_rows_mask | (retention_col_str == date_val)

                                # åˆå¹¶ç­›é€‰æ¡ä»¶ï¼šæ—¥æœŸåœ¨èŒƒå›´å†…ï¼Œæˆ–ç•™å­˜å¤©æ•°ä¸ºç‰¹å®šå€¼
                                mask = mask | special_rows_mask

                            filtered_data = file_data_copy[mask].copy()

                            # æ·»åŠ æ ‡è®°åˆ—å’Œæœˆä»½ä¿¡æ¯åˆ—
                            filtered_data['is_target_month'] = (filtered_data[date_col] >= first_day_of_month) & (
                                    filtered_data[date_col] <= last_day_of_month)
                            filtered_data['month'] = filtered_data[date_col].dt.strftime('%Y-%m')

                            # å°†æ—¥æœŸè½¬å›å­—ç¬¦ä¸²æ ¼å¼
                            filtered_data[date_col] = filtered_data[date_col].dt.strftime('%Y-%m-%d')

                            if not filtered_data.empty:
                                # æ·»åŠ æ•°æ®æ¥æºåˆ—
                                filtered_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)

                                # å°†"ç•™å­˜å¤©æ•°"åˆ—é‡å‘½åä¸º"date"
                                if retention_col is not None:
                                    filtered_data.rename(columns={retention_col: 'date'}, inplace=True)
                                elif date_col != 'date':
                                    filtered_data['date'] = filtered_data[date_col]

                                # å°†ç­›é€‰åçš„æ•°æ®æ·»åŠ åˆ°æ€»æ•°æ®æ¡†
                                all_data = pd.concat([all_data, filtered_data], ignore_index=True)
                                processed_count += 1

                        except Exception as e:
                            print(f"å¤„ç†æ—¥æœŸèŒƒå›´æ—¶å‡ºé”™: {str(e)}")
                            # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œé€€å›åˆ°ä»…ç­›é€‰æœˆä»½çš„æ–¹æ³•
                            file_data_copy['month'] = file_data_copy[date_col].apply(
                                lambda x: x[:7] if isinstance(x, str) else None
                            )

                            # ç­›é€‰ç›®æ ‡æœˆä»½çš„æ•°æ®
                            filtered_data = file_data_copy[file_data_copy['month'] == target_month].copy()

                            if 'month' in filtered_data.columns:
                                filtered_data.drop('month', axis=1, inplace=True)

                            if not filtered_data.empty:
                                # æ·»åŠ æ•°æ®æ¥æºåˆ—
                                filtered_data.insert(0, 'æ•°æ®æ¥æº', mapped_source)

                                # å¤„ç†dateåˆ—
                                if retention_col is not None:
                                    filtered_data.rename(columns={retention_col: 'date'}, inplace=True)
                                elif date_col != 'date':
                                    filtered_data['date'] = filtered_data[date_col]

                                # å°†ç­›é€‰åçš„æ•°æ®æ·»åŠ åˆ°æ€»æ•°æ®æ¡†
                                all_data = pd.concat([all_data, filtered_data], ignore_index=True)
                                processed_count += 1

                    else:
                        # å¦‚æœæ²¡æœ‰æ—¥æœŸåˆ—ï¼Œä¿ç•™æ‰€æœ‰æ•°æ®
                        # æ·»åŠ æ•°æ®æ¥æºåˆ—
                        file_data_copy.insert(0, 'æ•°æ®æ¥æº', mapped_source)

                        # å°†"ç•™å­˜å¤©æ•°"åˆ—é‡å‘½åä¸º"date"ï¼Œå¦‚æœæœ‰çš„è¯
                        if retention_col is not None:
                            file_data_copy.rename(columns={retention_col: 'date'}, inplace=True)

                        # å°†æ‰€æœ‰æ•°æ®æ·»åŠ åˆ°æ€»æ•°æ®æ¡†
                        all_data = pd.concat([all_data, file_data_copy], ignore_index=True)
                        processed_count += 1

        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} æ—¶å‡ºé”™: {str(e)}")

    # ========== å¤„ç†åˆå¹¶åçš„æ•°æ® ==========
    if not all_data.empty:
        # æŸ¥æ‰¾dateåˆ—
        date_col = None
        for col in all_data.columns:
            if col == 'date':
                date_col = col
                break

        # ä¸ºæ–°æ ¼å¼è¡¨åˆ›å»ºdateåˆ—
        if date_col is None and 'stat_date' in all_data.columns:
            all_data['date'] = all_data['stat_date']
            date_col = 'date'

        # æ’åºå¤„ç†
        sort_columns = []
        if 'æ•°æ®æ¥æº' in all_data.columns:
            sort_columns.append('æ•°æ®æ¥æº')

        if date_col:
            try:
                all_data[date_col] = pd.to_datetime(all_data[date_col], errors='coerce')
                sort_columns.append(date_col)
            except:
                sort_columns.append(date_col)

        # æ‰§è¡Œæ’åº
        if sort_columns:
            all_data = all_data.sort_values(by=sort_columns)
            # å°†æ—¥æœŸåˆ—è½¬å›å­—ç¬¦ä¸²æ ¼å¼
            if date_col and pd.api.types.is_datetime64_dtype(all_data[date_col]):
                all_data[date_col] = all_data[date_col].dt.strftime('%Y-%m-%d')

        # æ ‡å‡†åŒ–è¾“å‡ºåˆ—ç»“æ„
        standardized_df = standardize_output_columns(all_data)
        return standardized_df, processed_count, mapping_warnings, file_previews
    else:
        return None, 0, mapping_warnings, file_previews

# ==================== æ•°å­¦å»ºæ¨¡å‡½æ•°ï¼ˆå‚è€ƒç¬¬äºŒæ®µä»£ç ï¼‰====================
# å®šä¹‰æ•°å­¦å‡½æ•°
def power_function(x, a, b):
    """å¹‚å‡½æ•°ï¼šy = a * x^b"""
    return a * np.power(x, b)

def exponential_function(x, c, d):
    """æŒ‡æ•°å‡½æ•°ï¼šy = c * exp(d * x)"""
    return c * np.exp(d * x)

# ==================== ç•™å­˜ç‡è®¡ç®—å‡½æ•° - æ–°çš„è®¡ç®—æ–¹æ³• ====================
def calculate_retention_rates_new_method(df):
    """
    æ–°çš„ç•™å­˜ç‡è®¡ç®—æ–¹æ³•ï¼šå¯¹æ–°å¢æ±‚å‡å€¼ï¼Œå¯¹1-30åˆ—ä¹Ÿæ±‚å‡å€¼ï¼Œç„¶åç”¨1-30åˆ†åˆ«é™¤ä»¥æ–°å¢çš„å¹³å‡å€¼
    """
    retention_results = []
    data_sources = df['æ•°æ®æ¥æº'].unique()

    for source in data_sources:
        source_data = df[df['æ•°æ®æ¥æº'] == source].copy()
        
        # è®¡ç®—æ–°å¢ç”¨æˆ·æ•°çš„å¹³å‡å€¼
        new_users_values = []
        for _, row in source_data.iterrows():
            new_users = safe_convert_to_numeric(row.get('å›ä¼ æ–°å¢æ•°', 0))
            if not pd.isna(new_users) and new_users > 0:
                new_users_values.append(new_users)
        
        if not new_users_values:
            continue
            
        avg_new_users = np.mean(new_users_values)
        
        # è®¡ç®—å„å¤©ç•™å­˜æ•°çš„å¹³å‡å€¼ï¼Œç„¶åè®¡ç®—ç•™å­˜ç‡
        days = []
        rates = []
        
        for day in range(1, 31):
            day_col = str(day)
            day_values = []
            
            for _, row in source_data.iterrows():
                if day_col in row and not pd.isna(row[day_col]):
                    retain_count = safe_convert_to_numeric(row[day_col])
                    if retain_count >= 0:  # å…è®¸0å€¼
                        day_values.append(retain_count)
            
            if day_values:
                avg_retain_count = np.mean(day_values)
                retention_rate = avg_retain_count / avg_new_users
                if 0 < retention_rate <= 1.0:  # ä¿®æ”¹èŒƒå›´ï¼š0 < ç•™å­˜ç‡ â‰¤ 100%
                    days.append(day)
                    rates.append(retention_rate)

        if days:
            retention_data = {
                'data_source': source,
                'days': np.array(days),
                'rates': np.array(rates)
            }
            retention_results.append(retention_data)

    return retention_results

# ==================== è®¡ç®—æŒ‡å®šå¤©æ•°çš„ç´¯ç§¯LTå€¼å‡½æ•°ï¼ˆå‚è€ƒç¬¬äºŒæ®µä»£ç ï¼‰====================
def calculate_cumulative_lt(days_array, rates_array, target_days):
    """è®¡ç®—æŒ‡å®šå¤©æ•°çš„ç´¯ç§¯LTå€¼"""
    result = {}
    for day in target_days:
        idx = np.searchsorted(days_array, day, side='right')
        if idx > 0:
            # è®¡ç®—åˆ°æŒ‡å®šå¤©æ•°çš„ç´¯ç§¯LTå€¼ï¼ˆåŒ…æ‹¬ç¬¬0å¤©çš„1.0ï¼‰
            cumulative_lt = 1.0 + np.sum(rates_array[1:idx])
            result[day] = cumulative_lt
    return result

# ==================== LTæ‹Ÿåˆåˆ†æå‡½æ•° - å®Œå…¨å‚è€ƒç¬¬äºŒæ®µä»£ç é€»è¾‘ ====================
def calculate_lt_advanced(retention_result, channel_name, lt_years=5, return_curve_data=False, key_days=None):
    """
    æŒ‰æ¸ é“è§„åˆ™è®¡ç®— LTï¼Œå…è®¸ 1-30 å¤©æ•°æ®ä¸è¿ç»­ã€‚
    å®Œå…¨å‚è€ƒç¬¬äºŒæ®µä»£ç é€»è¾‘
    """
    # æ¸ é“è§„åˆ™ - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´
    CHANNEL_RULES = {
        "åä¸º": {"stage_2": [30, 120], "stage_3_base": [120, 220]},
        "å°ç±³": {"stage_2": [30, 190], "stage_3_base": [190, 290]},
        "oppo": {"stage_2": [30, 160], "stage_3_base": [160, 260]},
        "vivo": {"stage_2": [30, 150], "stage_3_base": [150, 250]},
        "iphone": {"stage_2": [30, 150], "stage_3_base": [150, 250], "stage_2_func": "log"},
        "å…¶ä»–": {"stage_2": [30, 100], "stage_3_base": [100, 200]}
    }

    # æ¸ é“è§„åˆ™åŒ¹é… - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´
    if re.search(r'\d+æœˆåä¸º$', channel_name):
        rules = CHANNEL_RULES["åä¸º"]
    elif re.search(r'\d+æœˆå°ç±³$', channel_name):
        rules = CHANNEL_RULES["å°ç±³"]
    elif re.search(r'\d+æœˆoppo$', channel_name) or re.search(r'\d+æœˆOPPO$', channel_name):
        rules = CHANNEL_RULES["oppo"]
    elif re.search(r'\d+æœˆvivo$', channel_name):
        rules = CHANNEL_RULES["vivo"]
    elif re.search(r'\d+æœˆ[iI][pP]hone$', channel_name):
        rules = CHANNEL_RULES["iphone"]
    else:
        rules = CHANNEL_RULES["å…¶ä»–"]
        
    stage_2_start, stage_2_end = rules["stage_2"]
    stage_3_base_start, stage_3_base_end = rules["stage_3_base"]

    # è®¡ç®—æœ€å¤§å¤©æ•°ï¼ˆæ ¹æ®æŒ‡å®šå¹´æ•°ï¼‰
    max_days = lt_years * 365

    days = retention_result["days"]
    rates = retention_result["rates"]

    # å­˜å‚¨æ‹Ÿåˆå‚æ•°ï¼Œç”¨äºåç»­åˆ†æ
    fit_params = {}

    # ----- ç¬¬ä¸€é˜¶æ®µ - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´ -----
    try:
        # ç”¨å·²æœ‰æ•°æ®å¯¹ 1-30 å¤©çš„ç•™å­˜ç‡è¿›è¡Œæ‹Ÿåˆ
        popt_power, _ = curve_fit(power_function, days, rates)
        a, b = popt_power
        fit_params["power"] = {"a": a, "b": b}

        # ç”¨æ‹Ÿåˆå‡½æ•°ç”Ÿæˆå®Œæ•´çš„ 1-30 å¤©ç•™å­˜ç‡
        days_full = np.arange(1, 31)  # è¿ç»­çš„ 1-30 å¤©
        rates_full = power_function(days_full, a, b)

        # ç¬¬ä¸€é˜¶æ®µçš„ LT ç´¯åŠ å€¼
        lt1_to_30 = np.sum(rates_full)
    except Exception as e:
        lt1_to_30 = 0.0
        a, b = 1.0, -1.0  # é»˜è®¤å‚æ•°

    # ----- ç¬¬äºŒé˜¶æ®µ - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´ -----
    try:
        days_stage_2 = np.arange(stage_2_start, stage_2_end + 1)
        rates_stage_2 = power_function(days_stage_2, a, b)
        lt_stage_2 = np.sum(rates_stage_2)
    except Exception as e:
        lt_stage_2 = 0.0
        rates_stage_2 = np.array([])

    # ----- ç¬¬ä¸‰é˜¶æ®µ - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´ -----
    try:
        days_stage_3_base = np.arange(stage_3_base_start, stage_3_base_end + 1)
        rates_stage_3_base = power_function(days_stage_3_base, a, b)

        # æŒ‡æ•°æ‹Ÿåˆ
        initial_c = rates_stage_3_base[0]
        initial_d = -0.001
        popt_exp, _ = curve_fit(
            exponential_function,
            days_stage_3_base,
            rates_stage_3_base,
            p0=[initial_c, initial_d],
            bounds=([0, -np.inf], [np.inf, 0])  # é™åˆ¶ d < 0
        )
        c, d = popt_exp
        fit_params["exponential"] = {"c": c, "d": d}
        days_stage_3 = np.arange(stage_3_base_start, max_days + 1)  # ä½¿ç”¨å¯å˜çš„æœ€å¤§å¤©æ•°
        rates_stage_3 = exponential_function(days_stage_3, c, d)
        lt_stage_3 = np.sum(rates_stage_3)
    except Exception as e:
        days_stage_3 = np.arange(stage_3_base_start, max_days + 1)  # ä½¿ç”¨å¯å˜çš„æœ€å¤§å¤©æ•°
        rates_stage_3 = power_function(days_stage_3, a, b) if 'a' in locals() else np.zeros(len(days_stage_3))
        lt_stage_3 = np.sum(rates_stage_3)

    # ----- æ€» LT è®¡ç®— - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´ -----
    total_lt = 1.0 + lt1_to_30 + lt_stage_2 + lt_stage_3

    # è®¡ç®—RÂ²ç”¨äºè¯„ä¼°æ‹Ÿåˆè´¨é‡
    try:
        predicted_rates = power_function(days, a, b)
        r2_score = 1 - np.sum((rates - predicted_rates) ** 2) / np.sum((rates - np.mean(rates)) ** 2)
    except:
        r2_score = 0.0

    if return_curve_data:
        # è¿”å›ä¸åŒ…å«ç¬¬0å¤©çš„æ›²çº¿æ•°æ®ç”¨äºå¯è§†åŒ– - ä¸ç¬¬äºŒæ®µä»£ç å®Œå…¨ä¸€è‡´
        all_days = np.concatenate([
            days_full,      # ç¬¬1-30å¤©
            days_stage_2,   # ç¬¬äºŒé˜¶æ®µ
            days_stage_3    # ç¬¬ä¸‰é˜¶æ®µ
        ])
        
        if 'rates_stage_2' not in locals():
            rates_stage_2 = power_function(days_stage_2, a, b)
        
        all_rates = np.concatenate([
            rates_full,                # ç¬¬1-30å¤©
            rates_stage_2,             # ç¬¬äºŒé˜¶æ®µ
            rates_stage_3              # ç¬¬ä¸‰é˜¶æ®µ
        ])

        # æŒ‰å¤©æ•°æ’åº
        sort_idx = np.argsort(all_days)
        all_days = all_days[sort_idx]
        all_rates = all_rates[sort_idx]

        # åªè¿”å›åˆ°æŒ‡å®šå¹´æ•°çš„æ•°æ®
        max_idx = np.searchsorted(all_days, lt_years * 365, side='right')
        all_days = all_days[:max_idx]
        all_rates = all_rates[:max_idx]

        # è®¡ç®—å…³é”®æ—¶é—´ç‚¹çš„ç´¯ç§¯LTå€¼
        key_days_lt = {}
        if key_days:
            key_days_lt = calculate_cumulative_lt(all_days, all_rates, key_days)

        return {
            'lt_value': total_lt,
            'fit_params': fit_params,
            'power_r2': max(0, min(1, r2_score)),
            'success': True,
            'model_used': 'power+exponential',
            'curve_days': all_days,
            'curve_rates': all_rates,
            'key_days_lt': key_days_lt
        }

    return total_lt

# ==================== é«˜è´¨é‡å¯è§†åŒ–å‡½æ•°ï¼ˆä¿®æ”¹ä¸ºå•æ¸ é“æ­£æ–¹å½¢å›¾è¡¨ï¼‰====================
def create_single_channel_charts(visualization_data_5y, original_data):
    """
    åˆ›å»ºå•æ¸ é“çš„5å¹´LTæ‹Ÿåˆæ›²çº¿å›¾è¡¨ï¼ˆæ­£æ–¹å½¢ï¼‰
    """
    # ç¡®ä¿ä¸­æ–‡å­—ä½“è®¾ç½®
    setup_chinese_font()
    
    # é¢œè‰²é…ç½®
    colors = plt.cm.tab10.colors
    
    # æŒ‰LTå€¼ä»ä½åˆ°é«˜æ’åºæ¸ é“
    sorted_channels = sorted(visualization_data_5y.items(), key=lambda x: x[1]['lt'])
    
    chart_figures = []
    
    # åˆ›å»ºå•æ¸ é“å›¾è¡¨
    for idx, (channel_name, data_5y) in enumerate(sorted_channels):
        color = colors[idx % len(colors)]
        
        # åˆ›å»ºæ­£æ–¹å½¢å›¾è¡¨
        fig = plt.figure(figsize=(6, 6))  # æ­£æ–¹å½¢å°ºå¯¸
        ax = fig.add_subplot(111)
        
        # ç»˜åˆ¶å®é™…æ•°æ®ç‚¹
        if channel_name in original_data:
            ax.scatter(
                original_data[channel_name]["days"],
                original_data[channel_name]["rates"],
                color='red',
                s=50,
                alpha=0.7,
                label='å®é™…æ•°æ®',
                zorder=3
            )
        
        # ç»˜åˆ¶5å¹´æ‹Ÿåˆæ›²çº¿
        ax.plot(
            data_5y["days"],
            data_5y["rates"],
            color='blue',
            linewidth=2,
            label='5å¹´LTæ‹Ÿåˆæ›²çº¿',
            zorder=2
        )
        
        # è®¾ç½®å›¾è¡¨æ ·å¼
        ax.set_xlim(0, 1825)  # 5å¹´
        ax.set_ylim(0, 0.6)
        ax.set_xlabel('ç•™å­˜å¤©æ•°', fontsize=12)
        ax.set_ylabel('ç•™å­˜ç‡', fontsize=12)
        ax.set_title(f'{channel_name} - 5å¹´LT: {data_5y["lt"]:.2f}', fontsize=14, fontweight='bold')
        ax.grid(True, linestyle='--', alpha=0.3)
        ax.legend(fontsize=10)
        
        # è®¾ç½®Yè½´åˆ»åº¦ä¸ºç™¾åˆ†æ¯”
        y_ticks = [0, 0.15, 0.3, 0.45, 0.6]
        y_labels = ['0%', '15%', '30%', '45%', '60%']
        ax.set_yticks(y_ticks)
        ax.set_yticklabels(y_labels)
        
        plt.tight_layout()
        
        chart_figures.append({
            'channel': channel_name,
            'figure': fig,
            'lt_value': data_5y["lt"]
        })
    
    return chart_figures

# ==================== ARPUå¤„ç†å‡½æ•° ====================
def process_arpu_data(df, start_month, end_month, channel_mapping):
    """
    å¤„ç†ARPUæ•°æ®ï¼šæ ¹æ®æœˆä»½ç­›é€‰ï¼Œæ ¹æ®æ¸ é“æ˜ å°„åŒ¹é…ï¼Œè®¡ç®—ARPU
    """
    try:
        # ç¡®ä¿æœ‰å¿…è¦çš„åˆ—
        required_cols = ['pid', 'instl_user_cnt', 'ad_all_rven_1d_m']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            return None, f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}"
        
        # æ·»åŠ æœˆä»½åˆ—ï¼ˆå¦‚æœæœ‰æ—¥æœŸåˆ—ï¼‰
        date_columns = [col for col in df.columns if 'æ—¥æœŸ' in str(col) or 'date' in str(col).lower()]
        if date_columns:
            date_col = date_columns[0]
            df['month'] = pd.to_datetime(df[date_col], errors='coerce').dt.strftime('%Y-%m')
            
            # ç­›é€‰æœˆä»½èŒƒå›´
            filtered_df = df[(df['month'] >= start_month) & (df['month'] <= end_month)].copy()
        else:
            # å¦‚æœæ²¡æœ‰æ—¥æœŸåˆ—ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®
            filtered_df = df.copy()
        
        if filtered_df.empty:
            return None, "ç­›é€‰æœˆä»½åæ— æ•°æ®"
        
        # å°†pidè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        filtered_df['pid'] = filtered_df['pid'].astype(str)
        
        # æ ¹æ®æ¸ é“æ˜ å°„åŒ¹é…æ¸ é“åç§°
        pid_to_channel = convert_mapping_for_lookup(channel_mapping)
        
        # æ·»åŠ æ¸ é“åç§°åˆ—
        filtered_df['channel_name'] = filtered_df['pid'].map(pid_to_channel)
        
        # åªä¿ç•™æœ‰æ¸ é“æ˜ å°„çš„æ•°æ®
        mapped_df = filtered_df[filtered_df['channel_name'].notna()].copy()
        
        if mapped_df.empty:
            return None, "æ ¹æ®æ¸ é“æ˜ å°„ç­›é€‰åæ— æ•°æ®"
        
        # ç¡®ä¿æ•°å€¼åˆ—ä¸ºæ•°å€¼ç±»å‹
        mapped_df['instl_user_cnt'] = pd.to_numeric(mapped_df['instl_user_cnt'], errors='coerce').fillna(0)
        mapped_df['ad_all_rven_1d_m'] = pd.to_numeric(mapped_df['ad_all_rven_1d_m'], errors='coerce').fillna(0)
        
        # æŒ‰æ¸ é“åç§°èšåˆ
        result_df = mapped_df.groupby('channel_name').agg({
            'instl_user_cnt': 'sum',
            'ad_all_rven_1d_m': 'sum'
        }).reset_index()
        
        # è®¡ç®—ARPU
        result_df['arpu_value'] = result_df['ad_all_rven_1d_m'] / result_df['instl_user_cnt']
        result_df['arpu_value'] = result_df['arpu_value'].fillna(0)
        
        # é‡å‘½ååˆ—
        result_df = result_df.rename(columns={'channel_name': 'data_source'})
        
        return result_df, None
        
    except Exception as e:
        return None, f"å¤„ç†ARPUæ•°æ®æ—¶å‡ºé”™: {str(e)}"

# ==================== é¡µé¢åˆå§‹åŒ– ====================
# ä¸»æ ‡é¢˜
st.markdown("""
<div class="main-header">
    <div class="main-title">ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†æç³»ç»Ÿ</div>
    <div class="main-subtitle">åŸºäºåˆ†é˜¶æ®µæ•°å­¦å»ºæ¨¡çš„LTVé¢„æµ‹ v2.0</div>
</div>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
session_keys = [
    'channel_mapping', 'merged_data', 'cleaned_data', 'retention_data',
    'lt_results_2y', 'lt_results_5y', 'arpu_data', 'ltv_results', 'current_step', 'excluded_data',
    'excluded_dates_info', 'file_previews', 'show_exclusion_panel'
]
for key in session_keys:
    if key not in st.session_state:
        st.session_state[key] = None

# è®¾ç½®é»˜è®¤å€¼
if st.session_state.channel_mapping is None:
    st.session_state.channel_mapping = DEFAULT_CHANNEL_MAPPING
if st.session_state.current_step is None:
    st.session_state.current_step = 0
if st.session_state.excluded_data is None:
    st.session_state.excluded_data = []
if st.session_state.excluded_dates_info is None:
    st.session_state.excluded_dates_info = []
if st.session_state.show_exclusion_panel is None:
    st.session_state.show_exclusion_panel = False

# ==================== åˆ†ææ­¥éª¤å®šä¹‰ ====================
# ä¿®æ”¹åˆ†ææ­¥éª¤å®šä¹‰ä¸º3æ­¥
ANALYSIS_STEPS = [
    {
        "name": "LTæ¨¡å‹æ„å»º",
        "sub_steps": ["æ•°æ®ä¸Šä¼ æ±‡æ€»", "å¼‚å¸¸å‰”é™¤", "ç•™å­˜ç‡è®¡ç®—", "LTæ‹Ÿåˆåˆ†æ"]
    },
    {
        "name": "ARPUè®¡ç®—",
        "sub_steps": []
    },
    {
        "name": "LTVç»“æœæŠ¥å‘Š",
        "sub_steps": []
    }
]

# ==================== æ­¥éª¤çŠ¶æ€æ£€æŸ¥å‡½æ•° ====================
def get_step_status(step_index):
    if step_index == st.session_state.current_step:
        return "active"
    if step_index == 0 and st.session_state.lt_results_5y is not None:
        return "completed"
    elif step_index == 1 and st.session_state.arpu_data is not None:
        return "completed"
    elif step_index == 2 and st.session_state.ltv_results is not None:
        return "completed"
    return "normal"

# ==================== ä¾§è¾¹æ å¯¼èˆª ====================
with st.sidebar:
    st.markdown('<div class="nav-container">', unsafe_allow_html=True)
    st.markdown('<h4 style="text-align: center; margin-bottom: 1rem; color: white;">åˆ†ææµç¨‹</h4>',
                unsafe_allow_html=True)

    for i, step in enumerate(ANALYSIS_STEPS):
        if st.button(f"{i + 1}. {step['name']}", key=f"nav_{i}",
                     use_container_width=True,
                     type="primary" if get_step_status(i) == "active" else "secondary"):
            st.session_state.current_step = i
            st.rerun()
        
        # æ˜¾ç¤ºå­æ­¥éª¤ï¼ˆä»…å¯¹ç¬¬ä¸€æ­¥ï¼‰
        if i == 0 and step['sub_steps']:
            st.markdown('<div class="step-details">', unsafe_allow_html=True)
            st.markdown('<ul>', unsafe_allow_html=True)
            for sub_step in step['sub_steps']:
                st.markdown(f'<li>{sub_step}</li>', unsafe_allow_html=True)
            st.markdown('</ul>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)
    
    # ä½¿ç”¨æŒ‡å—
    st.markdown("---")
    st.markdown("""
    <div class="nav-container">
        <h4 style="text-align: center; color: white;">ä½¿ç”¨æŒ‡å—</h4>
        <p style="font-size: 0.9rem; color: rgba(255,255,255,0.9); text-align: center;">
        ç‚¹å‡»ä¸Šæ–¹æ­¥éª¤å¯ç›´æ¥è·³è½¬ï¼Œç³»ç»Ÿä¼šæä¾›ç›¸åº”çš„æ“ä½œæŒ‡å¯¼ã€‚
        </p>
        <p style="font-size: 0.8rem; color: rgba(255,255,255,0.7); text-align: center;">
        LTVæ™ºèƒ½åˆ†æå¹³å° v2.0<br>
        åŸºäºåˆ†é˜¶æ®µæ•°å­¦å»ºæ¨¡
        </p>
    </div>
    """, unsafe_allow_html=True)

# ==================== è¾…åŠ©å‡½æ•° ====================
def show_dependency_tip(required_step):
    """æ˜¾ç¤ºä¾èµ–æç¤ºï¼Œä½†ä¸é˜»æ­¢ç»§ç»­æ“ä½œ"""
    st.markdown(f"""
    <div class="step-tip">
        <div class="step-tip-title">ğŸ’¡ å»ºè®®</div>
        <div class="step-tip-content">å»ºè®®å…ˆå®Œæˆã€Œ{required_step}ã€æ­¥éª¤ï¼Œä»¥è·å¾—æ›´å¥½çš„åˆ†ææ•ˆæœã€‚æ‚¨ä¹Ÿå¯ä»¥ç»§ç»­å½“å‰æ­¥éª¤çš„æ“ä½œã€‚</div>
    </div>
    """, unsafe_allow_html=True)

# ==================== é¡µé¢è·¯ç”± ====================
current_page = ANALYSIS_STEPS[st.session_state.current_step]["name"]

# ==================== é¡µé¢å†…å®¹ ====================

if current_page == "LTæ¨¡å‹æ„å»º":
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š LTæ¨¡å‹æ„å»ºåŸç†</div>
        <div class="principle-content">
        LTæ¨¡å‹æ„å»ºåŒ…å«å››ä¸ªæ ¸å¿ƒæ­¥éª¤ï¼šæ•°æ®ä¸Šä¼ æ±‡æ€»ã€å¼‚å¸¸å‰”é™¤ã€ç•™å­˜ç‡è®¡ç®—ã€LTæ‹Ÿåˆåˆ†æã€‚ç³»ç»Ÿé›†æˆå¤šæºExcelç•™å­˜æ•°æ®ï¼Œæ”¯æŒHUE/ocpxåŒæ ¼å¼è§£æï¼Œç»å¼‚å¸¸æ¸…æ´—åè®¡ç®—æ ‡å‡†åŒ–ç•™å­˜ç‡ï¼Œæœ€ç»ˆé€šè¿‡ä¸‰é˜¶æ®µæ•°å­¦å»ºæ¨¡ç”Ÿæˆç²¾ç¡®çš„ç”Ÿå‘½å‘¨æœŸæ¨¡å‹ã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # æ­¥éª¤1ï¼šæ•°æ®ä¸Šä¼ æ±‡æ€»
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.subheader("æ­¥éª¤1ï¼šæ•°æ®ä¸Šä¼ æ±‡æ€»")
    
    # æ¸ é“æ˜ å°„æ–‡ä»¶è®¾ç½®
    st.markdown("### æ¸ é“æ˜ å°„é…ç½®")
    
    # æ–‡ä»¶æ ¼å¼è¯´æ˜
    st.markdown("""
    <div class="step-tip">
        <div class="step-tip-title">ğŸ“‹ æ¸ é“æ˜ å°„æ–‡ä»¶æ ¼å¼è¦æ±‚</div>
        <div class="step-tip-content">
        â€¢ Excelç¬¬ä¸€åˆ—ï¼šæ¸ é“åç§°<br>
        â€¢ åç»­åˆ—ï¼šæ¸ é“å·(ä¸€ä¸ªæ¸ é“å¯å¯¹åº”å¤šä¸ªæ¸ é“å·)<br>
        â€¢ æ¸ é“å·æ”¯æŒæ•´æ•°å’Œå­—ç¬¦ä¸²æ ¼å¼
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # æ¸ é“æ˜ å°„æ–‡ä»¶ä¸Šä¼ 
    channel_mapping_file = st.file_uploader(
        "ä¸Šä¼ æ¸ é“æ˜ å°„æ–‡ä»¶ (Excelæ ¼å¼ï¼Œå¯é€‰)",
        type=['xlsx', 'xls'],
        help="æ ¼å¼ï¼šç¬¬ä¸€åˆ—ä¸ºæ¸ é“åç§°ï¼Œåç»­åˆ—ä¸ºå¯¹åº”çš„æ¸ é“å·"
    )
    
    if channel_mapping_file:
        try:
            custom_mapping = parse_channel_mapping_from_excel(channel_mapping_file)
            if custom_mapping and isinstance(custom_mapping, dict) and len(custom_mapping) > 0:
                st.session_state.channel_mapping = custom_mapping
                st.success(f"æ¸ é“æ˜ å°„æ–‡ä»¶åŠ è½½æˆåŠŸï¼å…±åŒ…å« {len(custom_mapping)} ä¸ªæ¸ é“æ˜ å°„")
                
                # æ˜¾ç¤ºæ˜ å°„é¢„è§ˆ - é»˜è®¤å±•å¼€
                with st.expander("æŸ¥çœ‹æ¸ é“æ˜ å°„è¯¦æƒ…", expanded=True):
                    mapping_display_data = []
                    for channel, pids in custom_mapping.items():
                        mapping_display_data.append({
                            'æ¸ é“åç§°': channel,
                            'æ¸ é“å·': ', '.join(pids)
                        })
                    mapping_df = pd.DataFrame(mapping_display_data)
                    st.dataframe(mapping_df, use_container_width=True)
            else:
                st.error("æ¸ é“æ˜ å°„æ–‡ä»¶è§£æå¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤æ˜ å°„")
        except Exception as e:
            st.error(f"è¯»å–æ¸ é“æ˜ å°„æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")
    else:
        st.info("æœªä¸Šä¼ æ¸ é“æ˜ å°„æ–‡ä»¶ï¼Œå°†ä½¿ç”¨é»˜è®¤æ˜ å°„å…³ç³»")
        
        # æ˜¾ç¤ºé»˜è®¤æ˜ å°„
        with st.expander("æŸ¥çœ‹é»˜è®¤æ¸ é“æ˜ å°„"):
            default_mapping_display = []
            for channel, pids in DEFAULT_CHANNEL_MAPPING.items():
                default_mapping_display.append({
                    'æ¸ é“åç§°': channel,
                    'æ¸ é“å·': ', '.join(pids)
                })
            default_mapping_df = pd.DataFrame(default_mapping_display)
            st.dataframe(default_mapping_df, use_container_width=True)
    
    st.markdown("### æ•°æ®æ–‡ä»¶ä¸Šä¼ ")

    # æ•°æ®æ–‡ä»¶æ ¼å¼è¯´æ˜
    st.markdown("""
    <div class="step-tip">
        <div class="step-tip-title">ğŸ“‹ æ•°æ®æ–‡ä»¶æ ¼å¼è¦æ±‚</div>
        <div class="step-tip-content">
        <strong>HUEå¯¼å‡ºè¡¨ï¼š</strong><br>
        â€¢ åŒ…å«stat_dateåˆ—ï¼ˆæ—¥æœŸï¼‰<br>
        â€¢ åŒ…å«newåˆ—ï¼ˆæ–°å¢ç”¨æˆ·æ•°ï¼‰<br>
        â€¢ åŒ…å«new_retain_1åˆ°new_retain_30åˆ—ï¼ˆå„å¤©ç•™å­˜æ•°ï¼‰<br><br>
        <strong>ocpxå¯¼å‡ºè¡¨ï¼š</strong><br>
        â€¢ åŒ…å«ç•™å­˜å¤©æ•°åˆ—<br>
        â€¢ åŒ…å«å›ä¼ æ–°å¢æ•°åˆ—<br>
        â€¢ åŒ…å«1-30æ•°å­—åˆ—ï¼ˆå„å¤©ç•™å­˜æ•°ï¼‰<br>
        â€¢ æ”¯æŒExcelå·¥ä½œè¡¨ååŒ…å«"ocpxç›‘æµ‹ç•™å­˜æ•°"çš„ç‰¹æ®Šè¡¨æ ¼
        </div>
    </div>
    """, unsafe_allow_html=True)

    uploaded_files = st.file_uploader(
        "é€‰æ‹©Excelæ•°æ®æ–‡ä»¶",
        type=['xlsx', 'xls'],
        accept_multiple_files=True,
        help="æ”¯æŒä¸Šä¼ å¤šä¸ªExcelæ–‡ä»¶"
    )

    default_month = get_default_target_month()
    target_month = st.text_input("ç›®æ ‡æœˆä»½ (YYYY-MM)", value=default_month)

    if uploaded_files:
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")

        if st.button("å¼€å§‹å¤„ç†æ•°æ®", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®æ–‡ä»¶..."):
                try:
                    # è½¬æ¢æ¸ é“æ˜ å°„æ ¼å¼
                    pid_to_channel_mapping = convert_mapping_for_lookup(st.session_state.channel_mapping)
                    
                    merged_data, processed_count, mapping_warnings, file_previews = integrate_excel_files_streamlit(
                        uploaded_files, target_month, pid_to_channel_mapping
                    )

                    if merged_data is not None and not merged_data.empty:
                        st.session_state.merged_data = merged_data
                        st.session_state.file_previews = file_previews
                        st.success(f"æ•°æ®å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {processed_count} ä¸ªæ–‡ä»¶")

                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æ€»è®°å½•æ•°", f"{len(merged_data):,}")
                        with col2:
                            st.metric("æ•°æ®æ¥æºæ•°", merged_data['æ•°æ®æ¥æº'].nunique())
                        with col3:
                            if 'å›ä¼ æ–°å¢æ•°' in merged_data.columns:
                                total_users = merged_data['å›ä¼ æ–°å¢æ•°'].sum()
                                st.metric("æ€»æ–°å¢ç”¨æˆ·", f"{total_users:,.0f}")

                        # æ˜¾ç¤ºæ˜ å°„è­¦å‘Š
                        if mapping_warnings:
                            st.warning("ä»¥ä¸‹æ–‡ä»¶æœªåœ¨æ¸ é“æ˜ å°„ä¸­æ‰¾åˆ°å¯¹åº”å…³ç³»ï¼š")
                            for warning in mapping_warnings:
                                st.text(f"â€¢ {warning}")

                        # æ˜¾ç¤ºæ¯ä¸ªæ–‡ä»¶çš„é¢„è§ˆæ•°æ®
                        st.subheader("å„æ–‡ä»¶æ•°æ®é¢„è§ˆ")
                        if file_previews:
                            for preview in file_previews:
                                with st.expander(f"æ–‡ä»¶ï¼š{preview['æ–‡ä»¶å'].iloc[0]}"):
                                    st.dataframe(preview, use_container_width=True)
                        
                    else:
                        st.error("æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
                except Exception as e:
                    st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")
    else:
        st.info("è¯·é€‰æ‹©Excelæ–‡ä»¶å¼€å§‹æ•°æ®å¤„ç†")

    st.markdown('</div>', unsafe_allow_html=True)
    
    # æ­¥éª¤2ï¼šå¼‚å¸¸æ•°æ®å‰”é™¤ï¼ˆå¯é€‰ï¼‰
    if st.session_state.merged_data is not None:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("æ­¥éª¤2ï¼šå¼‚å¸¸æ•°æ®å‰”é™¤ï¼ˆå¯é€‰ï¼‰")
        
        if not st.session_state.show_exclusion_panel:
            if st.button("éœ€è¦å‰”é™¤å¼‚å¸¸æ•°æ®", type="secondary", use_container_width=True):
                st.session_state.show_exclusion_panel = True
                st.rerun()
        else:
            merged_data = st.session_state.merged_data
            
            st.info("æ³¨æ„ï¼šæ‰€æœ‰å‰”é™¤æ¡ä»¶å¿…é¡»åŒæ—¶æ»¡è¶³æ‰ä¼šè¢«å‰”é™¤ï¼ˆä¸”å…³ç³»ï¼‰")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("### æŒ‰æ•°æ®æ¥æºå‰”é™¤")
                all_sources = merged_data['æ•°æ®æ¥æº'].unique().tolist()
                excluded_sources = st.multiselect("é€‰æ‹©è¦å‰”é™¤çš„æ•°æ®æ¥æº", options=all_sources)

            with col2:
                st.markdown("### æŒ‰æ—¥æœŸå‰”é™¤")
                if 'date' in merged_data.columns:
                    all_dates = sorted(merged_data['date'].unique().tolist())
                    excluded_dates = st.multiselect("é€‰æ‹©è¦å‰”é™¤çš„æ—¥æœŸ", options=all_dates)
                else:
                    st.info("æ•°æ®ä¸­æ— æ—¥æœŸå­—æ®µ")
                    excluded_dates = []

            try:
                exclusion_mask = pd.Series([True] * len(merged_data), index=merged_data.index)

                if excluded_sources:
                    source_mask = merged_data['æ•°æ®æ¥æº'].isin(excluded_sources)
                    exclusion_mask &= source_mask

                if 'date' in merged_data.columns and excluded_dates:
                    date_mask = merged_data['date'].isin(excluded_dates)
                    exclusion_mask &= date_mask

                if not excluded_sources and not excluded_dates:
                    exclusion_mask = pd.Series([False] * len(merged_data), index=merged_data.index)

                to_exclude = merged_data[exclusion_mask]
                to_keep = merged_data[~exclusion_mask]

            except Exception as e:
                st.error(f"è®¡ç®—å‰”é™¤æ¡ä»¶æ—¶å‡ºé”™: {str(e)}")
                to_exclude = pd.DataFrame()
                to_keep = merged_data.copy()

            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"### å°†è¢«å‰”é™¤çš„æ•°æ® ({len(to_exclude)} æ¡)")
                if len(to_exclude) > 0:
                    st.dataframe(to_exclude.head(5), use_container_width=True)

            with col2:
                st.markdown(f"### ä¿ç•™çš„æ•°æ® ({len(to_keep)} æ¡)")
                if len(to_keep) > 0:
                    st.dataframe(to_keep.head(5), use_container_width=True)

            col1, col2 = st.columns(2)
            with col1:
                if st.button("ç¡®è®¤å‰”é™¤å¼‚å¸¸æ•°æ®", type="primary", use_container_width=True):
                    try:
                        if len(to_exclude) > 0:
                            # è®°å½•å…·ä½“å‰”é™¤çš„æ—¥æœŸä¿¡æ¯
                            excluded_dates_info = []
                            for _, row in to_exclude.iterrows():
                                source = row.get('æ•°æ®æ¥æº', 'Unknown')
                                date = row.get('date', 'Unknown')
                                excluded_dates_info.append(f"{source}-{date}")
                            
                            st.session_state.excluded_data = excluded_dates_info
                            st.session_state.excluded_dates_info = excluded_dates
                            st.session_state.cleaned_data = to_keep.copy()
                            st.success(f"æˆåŠŸå‰”é™¤ {len(to_exclude)} æ¡å¼‚å¸¸æ•°æ®")
                        else:
                            st.session_state.cleaned_data = merged_data.copy()
                            st.session_state.excluded_dates_info = []
                            st.info("æœªå‘ç°éœ€è¦å‰”é™¤çš„å¼‚å¸¸æ•°æ®")
                        st.session_state.show_exclusion_panel = False
                    except Exception as e:
                        st.error(f"å‰”é™¤æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            
            with col2:
                if st.button("è·³è¿‡å¼‚å¸¸å‰”é™¤", type="secondary", use_container_width=True):
                    st.session_state.cleaned_data = merged_data.copy()
                    st.session_state.excluded_dates_info = []
                    st.session_state.show_exclusion_panel = False
                    st.info("è·³è¿‡å¼‚å¸¸æ•°æ®å‰”é™¤ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")

        st.markdown('</div>', unsafe_allow_html=True)
    
    # æ­¥éª¤3ï¼šç•™å­˜ç‡è®¡ç®—
    working_data = st.session_state.cleaned_data if st.session_state.cleaned_data is not None else st.session_state.merged_data
    
    if working_data is not None:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("æ­¥éª¤3ï¼šç•™å­˜ç‡è®¡ç®—")
        
        # æ•°æ®æ¥æºä¿¡æ¯
        data_source_info = "ä½¿ç”¨æ¸…ç†åçš„æ•°æ®" if st.session_state.cleaned_data is not None else "ä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆæœªç»å‰”é™¤å¤„ç†ï¼‰"
        st.markdown(f"""
        <div class="data-source-info">
            <div class="data-source-info-title">ğŸ“Š æ•°æ®æ¥æº</div>
            <div class="data-source-info-content">{data_source_info}</div>
        </div>
        """, unsafe_allow_html=True)

        # æ˜¾ç¤ºå‰”é™¤ä¿¡æ¯
        if st.session_state.excluded_dates_info and len(st.session_state.excluded_dates_info) > 0:
            excluded_dates_str = ", ".join(st.session_state.excluded_dates_info)
            st.markdown(f"""
            <div class="exclusion-info">
                <div class="exclusion-info-title">âš ï¸ æ•°æ®å‰”é™¤ä¿¡æ¯</div>
                <div class="exclusion-info-content">
                å·²å‰”é™¤ä»¥ä¸‹æ—¥æœŸçš„æ•°æ®ï¼š{excluded_dates_str}
                </div>
            </div>
            """, unsafe_allow_html=True)

        # æ•°æ®è´¨é‡è¦æ±‚è¯´æ˜
        st.markdown("""
        <div class="step-tip">
            <div class="step-tip-title">ğŸ“‹ æ•°æ®è´¨é‡è¦æ±‚ä¸è®¡ç®—æ–¹æ³•</div>
            <div class="step-tip-content">
            â€¢ æ–°å¢ç”¨æˆ·æ•°å¿…é¡»å¤§äº0<br>
            â€¢ ç•™å­˜ç‡èŒƒå›´ï¼š0 < ç•™å­˜ç‡ â‰¤ 100% <br>
            â€¢ è®¡ç®—æ–¹æ³•ï¼šå¯¹æ–°å¢ç”¨æˆ·æ•°æ±‚å‡å€¼ï¼Œå¯¹1-30å¤©å„åˆ—æ±‚å‡å€¼ï¼Œç„¶åç”¨å„å¤©ç•™å­˜æ•°å‡å€¼é™¤ä»¥æ–°å¢ç”¨æˆ·æ•°å‡å€¼<br>
            â€¢ æ”¯æŒ1-30å¤©ç•™å­˜æ•°æ®çš„éè¿ç»­è¾“å…¥
            </div>
        </div>
        """, unsafe_allow_html=True)

        data_sources = working_data['æ•°æ®æ¥æº'].unique()
        selected_sources = st.multiselect("é€‰æ‹©è¦åˆ†æçš„æ•°æ®æ¥æº", options=data_sources, default=data_sources)

        if st.button("è®¡ç®—ç•™å­˜ç‡", type="primary", use_container_width=True):
            if selected_sources:
                with st.spinner("æ­£åœ¨è®¡ç®—ç•™å­˜ç‡..."):
                    filtered_data = working_data[working_data['æ•°æ®æ¥æº'].isin(selected_sources)]
                    retention_results = calculate_retention_rates_new_method(filtered_data)
                    st.session_state.retention_data = retention_results

                    st.success("ç•™å­˜ç‡è®¡ç®—å®Œæˆï¼")

                    # åˆ›å»ºç•™å­˜ç‡è¡¨æ ¼å±•ç¤º
                    if retention_results:
                        st.subheader("ç•™å­˜ç‡è®¡ç®—ç»“æœ")
                        
                        # åˆ›å»º30å¤©ç•™å­˜ç‡è¡¨æ ¼
                        days_range = list(range(1, 31))
                        retention_table = pd.DataFrame({'å¤©æ•°': days_range})
                        
                        for result in retention_results:
                            channel_name = result['data_source']
                            days = result['days']
                            rates = result['rates']
                            
                            # åˆ›å»ºå®Œæ•´çš„ç•™å­˜ç‡æ•°ç»„
                            full_rates = [None] * 30
                            for day, rate in zip(days, rates):
                                if 1 <= day <= 30:
                                    full_rates[day-1] = f"{rate:.4f}"
                            
                            retention_table[channel_name] = full_rates
                        
                        # æ˜¾ç¤ºç•™å­˜ç‡è¡¨æ ¼ï¼ˆé»˜è®¤å±•å¼€ï¼Œæ˜¾ç¤º10è¡Œï¼‰
                        with st.expander("ç•™å­˜ç‡è¯¦ç»†æ•°æ®è¡¨", expanded=True):
                            st.dataframe(retention_table.head(10), use_container_width=True, height=400)
                            if len(retention_table) > 10:
                                st.info("è¡¨æ ¼æ˜¾ç¤ºå‰10è¡Œï¼Œå¯æ»šåŠ¨æŸ¥çœ‹æ›´å¤šæ•°æ®")
            else:
                st.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ•°æ®æ¥æº")

        st.markdown('</div>', unsafe_allow_html=True)
    
    # æ­¥éª¤4ï¼šLTæ‹Ÿåˆåˆ†æ
    if st.session_state.retention_data is not None:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("æ­¥éª¤4ï¼šLTæ‹Ÿåˆåˆ†æ")
        
        # åŸç†è§£é‡Š
        st.markdown("""
        <div class="principle-box">
            <div class="principle-title">ğŸ“š æ‹Ÿåˆåˆ†æåŸç†</div>
            <div class="principle-content">
            LTæ‹Ÿåˆåˆ†æé€šè¿‡ä¸‰ä¸ªé˜¶æ®µæ¨¡æ‹Ÿç”¨æˆ·æµå¤±è§„å¾‹ï¼š<br>
            <strong>ç¬¬ä¸€é˜¶æ®µ(1-30å¤©)ï¼š</strong>ä½¿ç”¨å¹‚å‡½æ•°æ‹Ÿåˆå‰30å¤©çš„çœŸå®ç•™å­˜æ•°æ®ï¼Œè¡¥å…¨ç¼ºå¤±çš„ç•™å­˜ç‡<br>
            <strong>ç¬¬äºŒé˜¶æ®µ(31-Xå¤©)ï¼š</strong>å»¶ç»­å¹‚å‡½æ•°è¶‹åŠ¿ï¼Œé¢„æµ‹ä¸­æœŸç•™å­˜å˜åŒ–<br>
            <strong>ç¬¬ä¸‰é˜¶æ®µ(Y-Nå¹´)ï¼š</strong>åˆ‡æ¢åˆ°æŒ‡æ•°å‡½æ•°ï¼Œæ¨¡æ‹Ÿé•¿æœŸç”¨æˆ·çš„ç¼“æ…¢æµå¤±è¿‡ç¨‹<br>
            ä¸åŒæ¸ é“é‡‡ç”¨ä¸åŒçš„é˜¶æ®µåˆ’åˆ†è§„åˆ™ï¼Œç¡®ä¿æ‹Ÿåˆç»“æœç¬¦åˆå„æ¸ é“çš„ç”¨æˆ·è¡Œä¸ºç‰¹å¾ã€‚
            </div>
        </div>
        """, unsafe_allow_html=True)

        # æ¸ é“è§„åˆ™è¯´æ˜
        st.markdown("""
        <div class="step-tip">
            <div class="step-tip-title">ğŸ“‹ æ¸ é“æ‹Ÿåˆè§„åˆ™</div>
            <div class="step-tip-content">
            <strong>åä¸ºæ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-120å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ120-220å¤©<br>
            <strong>å°ç±³æ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-190å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ190-290å¤©<br>
            <strong>oppoæ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-160å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ160-260å¤©<br>
            <strong>vivoæ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-150å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ150-250å¤©<br>
            <strong>iPhoneæ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-150å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ150-250å¤©<br>
            <strong>å…¶ä»–æ¸ é“ï¼š</strong>ç¬¬äºŒé˜¶æ®µ30-100å¤©ï¼Œç¬¬ä¸‰é˜¶æ®µ100-200å¤©
            </div>
        </div>
        """, unsafe_allow_html=True)

        if st.button("å¼€å§‹LTæ‹Ÿåˆåˆ†æ", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨è¿›è¡Œæ‹Ÿåˆè®¡ç®—..."):
                retention_data = st.session_state.retention_data
                
                lt_results_2y = []
                lt_results_5y = []
                visualization_data_5y = {}
                original_data = {}
                
                # å…³é”®æ—¶é—´ç‚¹åˆ—è¡¨
                key_days = [1, 7, 30, 60, 90, 100, 150, 200, 300]

                for retention_result in retention_data:
                    channel_name = retention_result['data_source']
                    
                    # è®¡ç®—5å¹´LT
                    lt_result_5y = calculate_lt_advanced(retention_result, channel_name, 5, 
                                                        return_curve_data=True, key_days=key_days)

                    # è®¡ç®—2å¹´LT
                    lt_result_2y = calculate_lt_advanced(retention_result, channel_name, 2, 
                                                       return_curve_data=True, key_days=key_days)

                    lt_results_5y.append({
                        'data_source': channel_name,
                        'lt_value': lt_result_5y['lt_value'],
                        'fit_success': lt_result_5y['success'],
                        'fit_params': lt_result_5y['fit_params'],
                        'power_r2': lt_result_5y['power_r2'],
                        'model_used': lt_result_5y['model_used']
                    })
                    
                    lt_results_2y.append({
                        'data_source': channel_name,
                        'lt_value': lt_result_2y['lt_value'],
                        'fit_success': lt_result_2y['success'],
                        'fit_params': lt_result_2y['fit_params'],
                        'power_r2': lt_result_2y['power_r2'],
                        'model_used': lt_result_2y['model_used']
                    })

                    # ä¿å­˜å¯è§†åŒ–æ•°æ®
                    visualization_data_5y[channel_name] = {
                        "days": lt_result_5y['curve_days'],
                        "rates": lt_result_5y['curve_rates'],
                        "lt": lt_result_5y['lt_value']
                    }

                    # ä¿å­˜åŸå§‹æ•°æ®
                    original_data[channel_name] = {
                        "days": retention_result['days'],
                        "rates": retention_result['rates']
                    }

                st.session_state.lt_results_5y = lt_results_5y
                st.session_state.lt_results_2y = lt_results_2y
                st.success("LTæ‹Ÿåˆåˆ†æå®Œæˆï¼")

                # æ˜¾ç¤ºLTå€¼è¡¨æ ¼
                if lt_results_5y:
                    st.subheader("LTåˆ†æç»“æœ")
                    results_df = pd.DataFrame([
                        {
                            'æ¸ é“åç§°': r['data_source'],
                            '5å¹´LT': round(r['lt_value'], 2),
                            'æ‹ŸåˆçŠ¶æ€': 'æˆåŠŸ' if r['fit_success'] else 'å¤±è´¥',
                            'RÂ²å¾—åˆ†': round(r['power_r2'], 3),
                            'ä½¿ç”¨æ¨¡å‹': r['model_used']
                        }
                        for r in lt_results_5y
                    ])
                    st.dataframe(results_df, use_container_width=True)

                # åˆ›å»ºå•æ¸ é“æ‹Ÿåˆå›¾è¡¨
                if visualization_data_5y and original_data:
                    st.subheader("å„æ¸ é“5å¹´LTæ‹Ÿåˆåˆ†æå›¾è¡¨")
                    
                    with st.spinner("æ­£åœ¨ç”Ÿæˆä¸“ä¸šå›¾è¡¨..."):
                        chart_figures = create_single_channel_charts(visualization_data_5y, original_data)
                    
                    # æ˜¾ç¤ºå•æ¸ é“å›¾è¡¨ï¼ˆæŒ‰LTå€¼æ’åºï¼‰
                    st.markdown("### å„æ¸ é“å•ç‹¬åˆ†æå›¾è¡¨ï¼ˆæŒ‰LTå€¼ä»ä½åˆ°é«˜æ’åºï¼‰")
                    
                    # æ¯è¡Œæ˜¾ç¤º3ä¸ªå›¾è¡¨
                    for i in range(0, len(chart_figures), 3):
                        cols = st.columns(3)
                        for j, col in enumerate(cols):
                            if i + j < len(chart_figures):
                                chart_data = chart_figures[i + j]
                                with col:
                                    st.pyplot(chart_data['figure'], use_container_width=True)
                                    plt.close(chart_data['figure'])

        st.markdown('</div>', unsafe_allow_html=True)

elif current_page == "ARPUè®¡ç®—":
    # ä¾èµ–æ€§æç¤º
    if st.session_state.lt_results_5y is None:
        show_dependency_tip("LTæ¨¡å‹æ„å»º")
    
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š ARPUè®¡ç®—åŸç†</div>
        <div class="principle-content">
        ARPUï¼ˆAverage Revenue Per Userï¼‰æ˜¯è®¡ç®—LTVçš„å…³é”®å‚æ•°ã€‚ç³»ç»Ÿæ”¯æŒExcelæ–‡ä»¶ä¸Šä¼ å’Œæ‰‹åŠ¨è®¾ç½®ä¸¤ç§æ–¹å¼ã€‚å¯¹äºExcelæ–‡ä»¶ï¼Œç³»ç»Ÿä¼šæ ¹æ®pidåˆ—åŒ¹é…æ¸ é“ï¼ŒæŒ‰æœˆä»½ç­›é€‰æ•°æ®ï¼Œç„¶åè®¡ç®—ARPU = ad_all_rven_1d_mæ±‚å’Œ / instl_user_cntæ±‚å’Œã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)

    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    st.subheader("ARPUæ•°æ®å¤„ç†")

    # ARPUæ–‡ä»¶æ ¼å¼è¯´æ˜
    st.markdown("""
    <div class="step-tip">
        <div class="step-tip-title">ğŸ“‹ ARPUæ–‡ä»¶æ ¼å¼è¦æ±‚</div>
        <div class="step-tip-content">
        â€¢ Excelæ ¼å¼(.xlsx/.xls)<br>
        â€¢ å¿…éœ€åˆ—ï¼špidã€instl_user_cntã€ad_all_rven_1d_m<br>
        â€¢ å¯é€‰ï¼šæ—¥æœŸåˆ—ï¼ˆç”¨äºæœˆä»½ç­›é€‰ï¼‰<br>
        â€¢ ç³»ç»Ÿä¼šæ ¹æ®æ¸ é“æ˜ å°„åŒ¹é…pidï¼Œå¹¶æŒ‰æ¸ é“èšåˆè®¡ç®—ARPU
        </div>
    </div>
    """, unsafe_allow_html=True)

    arpu_file = st.file_uploader("é€‰æ‹©ARPUæ•°æ®æ–‡ä»¶ (Excelæ ¼å¼)", type=['xlsx', 'xls'])

    if arpu_file:
        try:
            with st.spinner("æ­£åœ¨è¯»å–ARPUæ–‡ä»¶..."):
                arpu_df = pd.read_excel(arpu_file)
            st.success("ARPUæ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
            st.dataframe(arpu_df.head(10), use_container_width=True)

            # æ£€æŸ¥å¿…éœ€åˆ—
            required_cols = ['pid', 'instl_user_cnt', 'ad_all_rven_1d_m']
            missing_cols = [col for col in required_cols if col not in arpu_df.columns]
            
            if missing_cols:
                st.error(f"æ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_cols}")
            else:
                # æœˆä»½ç­›é€‰
                st.markdown("### æœˆä»½ç­›é€‰")
                col1, col2 = st.columns(2)
                
                with col1:
                    start_month = st.text_input("å¼€å§‹æœˆä»½ (YYYY-MM)", value="2024-04")
                with col2:
                    end_month = st.text_input("ç»“æŸæœˆä»½ (YYYY-MM)", value="2024-04")

                if st.button("å¤„ç†å¹¶è®¡ç®—ARPU", type="primary", use_container_width=True):
                    try:
                        with st.spinner("æ­£åœ¨å¤„ç†ARPUæ•°æ®..."):
                            result_df, error_msg = process_arpu_data(
                                arpu_df, start_month, end_month, st.session_state.channel_mapping
                            )
                        
                        if result_df is not None:
                            st.session_state.arpu_data = result_df
                            st.success("ARPUæ•°æ®å¤„ç†å®Œæˆï¼")
                            
                            # æ˜¾ç¤ºARPUç»“æœ
                            display_df = result_df[['data_source', 'instl_user_cnt', 'ad_all_rven_1d_m', 'arpu_value']].copy()
                            display_df.columns = ['æ¸ é“åç§°', 'å®‰è£…ç”¨æˆ·æ•°', 'æ€»æ”¶å…¥', 'ARPU']
                            display_df['ARPU'] = display_df['ARPU'].round(4)
                            st.dataframe(display_df, use_container_width=True)
                        else:
                            st.error(f"ARPUæ•°æ®å¤„ç†å¤±è´¥ï¼š{error_msg}")

                    except Exception as e:
                        st.error(f"ARPUæ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")

        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")

    else:
        st.info("è¯·ä¸Šä¼ ARPUæ•°æ®æ–‡ä»¶ï¼Œæˆ–ä½¿ç”¨æ‰‹åŠ¨è®¾ç½®åŠŸèƒ½")

        # æ‰‹åŠ¨è®¾ç½®ARPU
        if st.session_state.lt_results_5y:
            # æ·»åŠ æŒ‰é’®æ§åˆ¶æ‰‹åŠ¨è¾“å…¥é¢æ¿
            if st.button("æ‰‹åŠ¨è®¾ç½®ARPUå€¼", type="secondary", use_container_width=True):
                st.markdown("### æ‰‹åŠ¨è®¾ç½®ARPUå€¼")
                
                # æ‰‹åŠ¨è®¾ç½®è¯´æ˜
                st.markdown("""
                <div class="step-tip">
                    <div class="step-tip-title">ğŸ“‹ æ‰‹åŠ¨è®¾ç½®è¯´æ˜</div>
                    <div class="step-tip-content">
                    ä¸ºæ¯ä¸ªæ¸ é“è®¾ç½®å¯¹åº”çš„ARPUå€¼ï¼Œå»ºè®®åŸºäºå†å²æ•°æ®æˆ–ä¸šåŠ¡é¢„æœŸè¿›è¡Œè®¾ç½®ã€‚
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                arpu_inputs = {}

                col1, col2 = st.columns(2)
                for i, result in enumerate(st.session_state.lt_results_5y):
                    source = result['data_source']
                    with col1 if i % 2 == 0 else col2:
                        arpu_value = st.number_input(
                            f"{source}", min_value=0.0, value=0.04, step=0.001,
                            format="%.4f", key=f"arpu_{source}"
                        )
                        arpu_inputs[source] = arpu_value

                if st.button("ä¿å­˜æ‰‹åŠ¨ARPUè®¾ç½®", type="primary", use_container_width=True):
                    arpu_df = pd.DataFrame([
                        {'data_source': source, 'arpu_value': value, 'instl_user_cnt': 1, 'ad_all_rven_1d_m': value}
                        for source, value in arpu_inputs.items()
                    ])
                    st.session_state.arpu_data = arpu_df
                    st.success("ARPUè®¾ç½®å·²ä¿å­˜ï¼")
                    st.dataframe(arpu_df[['data_source', 'arpu_value']].rename(columns={
                        'data_source': 'æ¸ é“åç§°', 'arpu_value': 'ARPU'
                    }), use_container_width=True)
        else:
            st.info("è¯·å…ˆå®ŒæˆLTæ¨¡å‹æ„å»ºä»¥è·å–æ¸ é“åˆ—è¡¨")

    st.markdown('</div>', unsafe_allow_html=True)

elif current_page == "LTVç»“æœæŠ¥å‘Š":
    # ä¾èµ–æ€§æç¤º
    if st.session_state.lt_results_5y is None:
        show_dependency_tip("LTæ¨¡å‹æ„å»º")
    elif st.session_state.arpu_data is None:
        show_dependency_tip("ARPUè®¡ç®—")
    
    # åŸç†è§£é‡Š
    st.markdown("""
    <div class="principle-box">
        <div class="principle-title">ğŸ“š LTVç»“æœæŠ¥å‘ŠåŸç†</div>
        <div class="principle-content">
        LTVç»“æœæŠ¥å‘Šæ˜¯æ•´ä¸ªåˆ†ææµç¨‹çš„æœ€ç»ˆè¾“å‡ºã€‚ç³»ç»Ÿé€šè¿‡LTV = LT Ã— ARPUçš„å…¬å¼è®¡ç®—æ¯ä¸ªæ¸ é“çš„ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼ï¼ŒåŒæ—¶è®¡ç®—2å¹´å’Œ5å¹´ä¸¤ç§æ—¶é—´å‘¨æœŸçš„LTVï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼Œä¸ºæ¸ é“æŠ•æ”¾å†³ç­–æä¾›æ•°æ®æ”¯æŒã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.lt_results_5y is not None and st.session_state.arpu_data is not None:
        lt_results_5y = st.session_state.lt_results_5y
        lt_results_2y = st.session_state.lt_results_2y if st.session_state.lt_results_2y else []
        arpu_data = st.session_state.arpu_data

        # è®¡ç®—5å¹´LTVç»“æœ
        ltv_results_5y = []
        ltv_results_2y = []

        for lt_result in lt_results_5y:
            source = lt_result['data_source']
            lt_value_5y = lt_result['lt_value']

            arpu_row = arpu_data[arpu_data['data_source'] == source]
            if not arpu_row.empty:
                arpu_value = arpu_row.iloc[0]['arpu_value']
            else:
                arpu_value = 0
                st.warning(f"æ¸ é“ '{source}' æœªæ‰¾åˆ°ARPUæ•°æ®")

            ltv_value_5y = lt_value_5y * arpu_value

            ltv_results_5y.append({
                'data_source': source,
                'lt_value': lt_value_5y,
                'arpu_value': arpu_value,
                'ltv_value': ltv_value_5y,
                'fit_success': lt_result['fit_success'],
                'model_used': lt_result.get('model_used', 'unknown'),
                'fit_params': lt_result.get('fit_params', {})
            })

        # è®¡ç®—2å¹´LTVç»“æœ
        for lt_result in lt_results_2y:
            source = lt_result['data_source']
            lt_value_2y = lt_result['lt_value']

            arpu_row = arpu_data[arpu_data['data_source'] == source]
            if not arpu_row.empty:
                arpu_value = arpu_row.iloc[0]['arpu_value']
            else:
                arpu_value = 0

            ltv_value_2y = lt_value_2y * arpu_value

            ltv_results_2y.append({
                'data_source': source,
                'lt_value': lt_value_2y,
                'arpu_value': arpu_value,
                'ltv_value': ltv_value_2y,
                'fit_success': lt_result['fit_success'],
                'model_used': lt_result.get('model_used', 'unknown')
            })

        st.session_state.ltv_results = ltv_results_5y

        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("LTVç»¼åˆè®¡ç®—ç»“æœ")

        # è®¡ç®—å…¬å¼è¯´æ˜
        st.markdown("""
        <div class="step-tip">
            <div class="step-tip-title">ğŸ“‹ è®¡ç®—å…¬å¼</div>
            <div class="step-tip-content">
            <strong>LTV = LT Ã— ARPU</strong><br>
            LTï¼šç”¨æˆ·ç”Ÿå‘½å‘¨æœŸé•¿åº¦ï¼ˆå¤©æ•°ï¼‰<br>
            ARPUï¼šå•ç”¨æˆ·å¹³å‡æ”¶å…¥<br>
            LTVï¼šç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼
            </div>
        </div>
        """, unsafe_allow_html=True)

        # åˆ›å»ºæŒ‰è¦æ±‚æ ¼å¼çš„è¡¨æ ¼
        if ltv_results_5y and ltv_results_2y:
            # åˆå¹¶5å¹´å’Œ2å¹´æ•°æ®
            combined_data = []
            for result_5y in ltv_results_5y:
                # æŸ¥æ‰¾å¯¹åº”çš„2å¹´æ•°æ®
                result_2y = next((r for r in ltv_results_2y if r['data_source'] == result_5y['data_source']), None)
                
                if result_2y:
                    # è·å–æ‹Ÿåˆå‚æ•°
                    fit_params = result_5y.get('fit_params', {})
                    power_params = fit_params.get('power', {})
                    exp_params = fit_params.get('exponential', {})
                    
                    # æ ¼å¼åŒ–å‡½æ•°è¡¨è¾¾å¼
                    power_func = f"y = {power_params.get('a', 0):.4f} * x^{power_params.get('b', 0):.4f}" if power_params else "N/A"
                    exp_func = f"y = {exp_params.get('c', 0):.4f} * exp({exp_params.get('d', 0):.4f} * x)" if exp_params else "N/A"
                    
                    combined_data.append({
                        'å¤‡æ³¨': '',  # ç©ºå¤‡æ³¨åˆ—
                        'æ¸ é“åç§°': result_5y['data_source'],
                        '5å¹´LT': round(result_5y['lt_value'], 0),
                        '5å¹´ARPU': round(result_5y['arpu_value'], 4),
                        '5å¹´LTV': round(result_5y['ltv_value'], 1),
                        '2å¹´LT': round(result_2y['lt_value'], 0),
                        '2å¹´ARPU': round(result_2y['arpu_value'], 4),
                        '2å¹´LTV': round(result_2y['ltv_value'], 1),
                        'ç¬¬ä¸€æ®µå‡½æ•°(å¹‚å‡½æ•°)': power_func,
                        'ç¬¬ä¸‰æ®µå‡½æ•°(æŒ‡æ•°å‡½æ•°)': exp_func,
                        'ä½¿ç”¨æ¨¡å‹': result_5y['model_used']
                    })

            display_df = pd.DataFrame(combined_data)
            
            # æ˜¾ç¤ºå®Œæ•´ç»“æœè¡¨æ ¼
            st.subheader("5å¹´åŒæ®µLTV vs 2å¹´åŒæ®µLTV å¯¹æ¯”ç»“æœ")
            st.dataframe(display_df, use_container_width=True)

        st.markdown('</div>', unsafe_allow_html=True)

        # æ•°æ®å¯¼å‡º
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.subheader("åˆ†æç»“æœå¯¼å‡º")

        col1, col2 = st.columns(2)

        with col1:
            # åˆ›å»ºæ ‡å‡†æ ¼å¼çš„CSVå¯¼å‡ºæ•°æ®
            if 'display_df' in locals():
                export_df = display_df[['æ¸ é“åç§°', '5å¹´LT', '5å¹´ARPU', '5å¹´LTV', '2å¹´LT', '2å¹´ARPU', '2å¹´LTV']].copy()
                
                # ä¿®å¤CSVå¯¼å‡ºçš„ä¸­æ–‡ç¼–ç é—®é¢˜
                csv_data = export_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ä¸‹è½½LTVåˆ†æç»“æœ (CSV)",
                    data=csv_data.encode('utf-8-sig'),
                    file_name=f"LTV_Analysis_Results_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )

        with col2:
            # ç”Ÿæˆè¯¦ç»†æ•°æ®æ¥æºä¿¡æ¯
            data_source_desc = ""
            if st.session_state.excluded_dates_info and len(st.session_state.excluded_dates_info) > 0:
                excluded_dates_str = ", ".join(st.session_state.excluded_dates_info)
                data_source_desc = f"å·²å‰”é™¤ä»¥ä¸‹æ—¥æœŸæ•°æ®ï¼š{excluded_dates_str}"
            elif st.session_state.cleaned_data is not None:
                data_source_desc = "ä½¿ç”¨æ¸…ç†åæ•°æ®"
            else:
                data_source_desc = "ä½¿ç”¨åŸå§‹æ•°æ®"
            
            if 'display_df' in locals():
                report_text = f"""
LTVç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†ææŠ¥å‘Š
===========================================
ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æ‰§è¡Œæ‘˜è¦
-----------
æœ¬æŠ¥å‘ŠåŸºäºåˆ†é˜¶æ®µæ•°å­¦å»ºæ¨¡æ–¹æ³•ï¼Œå¯¹ {len(display_df)} ä¸ªæ•°æ®æ¥æºè¿›è¡Œäº†ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼åˆ†æã€‚

æ ¸å¿ƒæŒ‡æ ‡æ±‡æ€»
-----------
â€¢ å‚ä¸åˆ†æçš„æ¸ é“æ•°é‡: {len(display_df)}
â€¢ 5å¹´å¹³å‡LTV: {display_df['5å¹´LTV'].mean():.2f}
â€¢ 5å¹´æœ€é«˜LTV: {display_df['5å¹´LTV'].max():.2f}
â€¢ 5å¹´æœ€ä½LTV: {display_df['5å¹´LTV'].min():.2f}
â€¢ 2å¹´å¹³å‡LTV: {display_df['2å¹´LTV'].mean():.2f}
â€¢ 2å¹´æœ€é«˜LTV: {display_df['2å¹´LTV'].max():.2f}
â€¢ 2å¹´æœ€ä½LTV: {display_df['2å¹´LTV'].min():.2f}

è¯¦ç»†ç»“æœ
-----------
{export_df.to_string(index=False) if 'export_df' in locals() else ''}

æ•°æ®æ¥æºè¯´æ˜
-----------
{data_source_desc}

è®¡ç®—æ–¹æ³•
-----------
â€¢ LTæ‹Ÿåˆ: ä¸‰é˜¶æ®µåˆ†å±‚å»ºæ¨¡ï¼ˆå¹‚å‡½æ•°+æŒ‡æ•°å‡½æ•°ï¼‰
â€¢ LTVå…¬å¼: LTV = LT Ã— ARPU
â€¢ æ¸ é“è§„åˆ™: æŒ‰åä¸ºã€å°ç±³ã€oppoã€vivoã€iPhoneåˆ†ç±»è®¾å®šä¸åŒæ‹Ÿåˆå‚æ•°
â€¢ æ–°çš„ç•™å­˜ç‡è®¡ç®—æ–¹æ³•: å¯¹æ–°å¢ç”¨æˆ·æ•°å’Œå„å¤©ç•™å­˜æ•°åˆ†åˆ«æ±‚å‡å€¼åè®¡ç®—ç•™å­˜ç‡

æŠ¥å‘Šç”Ÿæˆ: LTVæ™ºèƒ½åˆ†æå¹³å° v2.0
"""

                st.download_button(
                    label="ä¸‹è½½è¯¦ç»†åˆ†ææŠ¥å‘Š (TXT)",
                    data=report_text.encode('utf-8'),
                    file_name=f"LTV_Detailed_Report_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                    mime="text/plain",
                    use_container_width=True
                )

        st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.info("è¯·å…ˆå®ŒæˆLTæ¨¡å‹æ„å»ºå’ŒARPUè®¡ç®—ä»¥ç”ŸæˆLTVæŠ¥å‘Šã€‚")
        st.markdown('</div>', unsafe_allow_html=True)
